{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "What_is_NLP_Ch8_Deep_Learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdemm4BqUqTx"
      },
      "source": [
        "## 8) 딥러닝\n",
        "### 1) 퍼셉트론\n",
        "* 단층 퍼셉트론은 AND, NAND, OR 게이트 구현 가능하지만 XOR 게이트는 불가능\n",
        "  * XOR 게이트는 직선이 아닌 비선형 영역으로 분리하면 구현 가능해짐\n",
        "* **다층 퍼셉트론MultiLayer Perceptron, MLP**\n",
        "  * 단층과의 차이: 중간에 은닉층이 존재함\n",
        "* **심층 신경망Deep Neural Network, DNN**: 은닉층 2개 이상\n",
        "* 학습Training: 기계가 가중치를 스스로 찾아내도록 자동화해야 됨\n",
        "  * 손실 함수Loss function과 옵티마이저 사용\n",
        "  * 학습 시키는 인공 신경망이 심층 신경망일 경우에는 딥러닝Deep Learning이라고 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfcqkBxCMdW"
      },
      "source": [
        "### 2) 인공 신경망 훑어보기\n",
        "#### 1. Feed-Forward Neural Network, FFNN\n",
        "#### 2. 전결합층 Fully-connected layer, FC, Dense layer\n",
        "* FC: 어떤 층의 모든 뉴런이 이전 층의 모든 뉴런과 연결되어 있는 층. 다층 퍼셉트론의 모든 은닉층과 출력층은 FC\n",
        "* 동일한 의미로 밀집층Dense layer이라고 부르기도 함. 케라스에서는 Dense()\n",
        "\n",
        "#### 3. Activation Function\n",
        "* 은닉층과 출력층의 뉴런에서 출력값을 결정하는 함수\n",
        "  1. Nonlinear function이어야 함\n",
        "    * 선형 함수로는 은닉층을 여러 번 추가하더라도 1회 추가한 것과 차이를 줄 수 없음\n",
        "  2. 계단함수\n",
        "  3. 시그모이드 함수와 기울기 소실\n",
        "    * 입력에 대해 forward propagation 연산을 하고, 순전파 연산을 통해 나온 예측값과 실제값의 오차를 loss function을 통해 계산\n",
        "    * 이 손실loss를 미분을 통해서 gradient를 구하고, 이를 통해 back propagation을 수행함  \n",
        "\n",
        "    * 시그모이드의 문제! **기울기 소실 문제 Vanishing gradient problem** 발생\n",
        "      * 깊은 인공 신경망 학습 시, 역전파 과정에서 입력층으로 갈수록 Gradient가 점차 작아짐\n",
        "      * 입력층에 가까운 층들에서 가중치 업데이트가 제대로 되지 않으면 결국 최적의 모델을 찾을 수 없음\n",
        "  4. Hyperbolic tangent function\n",
        "    * tanh는 입력값을 -1과 0 사이\n",
        "    * -1과 1에 가까운 출력값을 출력할 때, 시그모이드 함수와 같은 문제 발생. 그러나 tanh는 시그모이드와 달리 0을 중심으로 함. 그래서 시그모이드보다는 Vanishing gradient problem이 적은 편\n",
        "  5. ReLU\n",
        "    * 수식: f(x) = max(0, x)\n",
        "    * 음수 입력하면 0, 양수 입력하면 입력값을 그대로 반환\n",
        "    * 특정 양수값에 수렴하지 않아 깊은 신경망에서 시그모이드보다 훨씬 더 작동하고, 단순 임계값이라 연산속도도 빠름\n",
        "    * 하지만 dying ReLU 발생 가능.. 입력값이 음수면 기울기도 0이 됨\n",
        "  6. Leaky ReLU\n",
        "    * 입력값이 음수일 경우에 0이 아니라 0.0001과 같은 매우 작은 수 반환\n",
        "    * 수식: f(x) = max(ax, x)   a는 일반적으로 0.001\n",
        "  7. Softmax function\n",
        "    * 분류 문제를 로지스틱 회귀나 소프트맥스 회귀를 출력층에 적용하여 사용\n",
        "    * 소프트맥스 함수는 시그모이드 함수처럼 *출력층의 뉴런*에서 사용\n",
        "      * 시그모이드는 Binary classification, 소프트맥스는 MultiClass classification  \n",
        "\n",
        "#### 4. 행렬의 곱셈을 이용한 Forward propagation  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-uw5Cy8EVXO"
      },
      "source": [
        "### 3) 딥러닝의 학습 방법\n",
        "#### 1. Forward Propagation\n",
        "#### 2. 손실함수\n",
        "* 실제값과 예측값 차이를 수치화해주는 함수\n",
        "* 회귀에서는 MSE(오차 제곱 평균, 연속형 변수에 사용)\n",
        "* 분류에서는 Cross-Entropy(keras의 model.compile()에서 binary_crossentropy, categorical_crossentropy)\n",
        "* **손실 함수의 값을 최소화하는 두 개의 매개변수인 W와 b를 찾아가는 것이 딥러닝의 핵심 과정이므로 손실 함수의 선정은 매우 중요**\n",
        "\n",
        "#### 3. Optimizer\n",
        "* 손실 함수의 값을 줄여나가면서 학습하는 방법은 어떤 옵티마이저를 사용하느냐에 따라 달라짐\n",
        "* **Batch**: 가중치 등의 매개 변수의 값을 조정하기 위해 사용하는 데이터의 양\n",
        "  1. **배치 경사 하강법 Batch Gradient Descent**\n",
        "    * 기본적인 경사 하강법\n",
        "    * 옵티마이저 중 하나로 오차loss를 구할 때 전체 데이터를 고려\n",
        "    * 머신러닝에서는 1번의 훈련 횟수를 1에포크라고 하는데, 배치 경사 하강법은 한 번의 에포크에 모든 매개변수 업데이트를 단 한 번 수행\n",
        "    * :( 에포크당 시간 오래 걸리고 메모리 크게 요구\n",
        "    * :) 글로벌 미니멈을 찾을 수 있음\n",
        "  2. **확률적 경사 하강법 Stochastic Gradient Descent, SGD**\n",
        "    * 매개변수 값을 조정 시 전체 데이터가 아니라 랜덤으로 선택한 하나의 데이터에 대해서만 계산하는 방법\n",
        "    * :( 매개변수의 변경폭이 불안정하고, 정확도가 낮을 수 있음\n",
        "    * :) 더 적은 데이터를 사용하므로 더 빠르게 계산 가능\n",
        "  3. **미니 배치 경사 하강법 Mini-Batch Gradient Descent**\n",
        "    * 정해진 양에 대해서만 계산하여 매개 변수의 값을 조정\n",
        "    * 전체 데이터 계산보다 빠르고, SGD보다 안정적\n",
        "  4. **모멘텀 Momentum**\n",
        "    * 관성을 응용한 방법\n",
        "    * 경사 하강법Gradient Descent에서 계산된 접선의 기울기에 한 시점 전의 접선의 기울기 값을 일정한 비율만큼 반영\n",
        "      * 언덕에서 공이 내려올 때, 중간에 작은 웅덩이에 빠지더라도 관섬의 힘으로 넘어서는 효과 가능\n",
        "    * **로컬 미니멈에 도달 시, 기존의 경사 하강법은 글로벌 미니멈으로 잘못 인식하여 계산 끝내지만 모멘텀은 값이 조절되어 로컬 미니멈에서 탈출 가능**\n",
        "      > keras.optimizers.SGD(lr = 0.01, momentum= 0.9)\n",
        "  5. **아다그라드 Adagrad**\n",
        "    * 각 매개변수에 서로 다른 학습률을 적용\n",
        "    * 변화가 많은 매개변수는 학습률이 작게 설정되고, 변화가 적은 매개변수는 학습률을 높게 설정\n",
        "      > keras.optimizers.Adagrad(lr=0.01, epsilon=1e-6)\n",
        "  6. **알엠에스프롭 RMSprop**\n",
        "    * 아다그라드는 나중에 학습률이 지나치게 떨어진다는 단점이 있는데 이를 다른 수식으로 대체하여 개선\n",
        "  7. **아담 Adam**\n",
        "    * RMSprop + Momentum\n",
        "    * 방향과 학습률을 다 잡기 위함\n",
        "    > keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "#### 4. 역전파 BackPropagation\n",
        "#### 5. 에포크와 배치 크기와 이터레이션 Epochs and Batch size and Iteration\n",
        "* 기계는 실제값과 예측값의 오차로부터 옵티마이저를 통해서 가중치를 업데이트함(이는 곧 학습)\n",
        "1. 에포크 Epoch\n",
        "  * 인공 신경망에서 전체 데이터에 대해서 순전파와 역전파가 끝난 상태\n",
        "  * ex) 모든 문제를 끝까지 다 풀고, 채점하여 문제지에 대한 공부를 한 번 끝낸 상태. Epoch=50이면 문제지 50번 푼 것\n",
        "  * 과적합, 과소적합 발생 가능\n",
        "2. 배치 크기 Batch size\n",
        "  * **몇 개의 데이터 단위로 매개변수를 업데이트 하는지**\n",
        "  * ex) 몇 개씩 문제를 풀고나서 정답지를 확인하는가\n",
        "  * 배치 크기 != 배치 수\n",
        "    * 전체 데이터가 2,000일 때 배치 크기를 200으로 주면 배치의 수(iteration)는 10\n",
        "3. 이터레이션 Iteration\n",
        "  * 한 번의 에포크를 끝내기 위해서 필요한 배치의 수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn2e2Jr-HyWp"
      },
      "source": [
        "### 4) 과적합 Overfitting\n",
        "1. Data Augmentation\n",
        "2. 모델의 복잡도 줄이기\n",
        "3. 가중치 규제 Regularization 적용하기\n",
        "* 복잡한 모델이 간단한 모델(적은 수의 매개변수 가진 모델)보다 과적합될 가능성이 높음\n",
        "* 간단하게 하는 방법으로 Regularization이 있음\n",
        "  1. L1 규제: 가중치들의 절대값 합계를 비용 함수에 추가. L1 Norm\n",
        "  2. L2 규제: 모든 가중치들의 제곱합을 비용 함수에 추가. L2 Norm. 가중치 감소 weight decay라고도 부름\n",
        "    * 모두 비용 함수를 최소화하기 위해서는 가중치들의 값이 작아져야 한다는 특징이 있음\n",
        "    * L1 규제는 어떤 특성들이 모델에 영향을 주고 있는지를 정확히 판단하고자 할 때 유용. 이런 판단이 필요 없다면 L2 규제 사용하기.\n",
        "4. Dropout\n",
        "* 학습 과정에서 신경망의 일부를 사용하지 않음\n",
        "* ** 학습 시에만 사용하고, 예측 시에는 사용하지 않는 것이 일반적**\n",
        "* 학습 시 인공 신경망이 특정 뉴런/조합에 너무 의존적이게 되는 것을 방지\n",
        "* 매번 랜덤 선택으로 뉴런들을 사용하지 않으므로 서로 다른 신경망들을 앙상블하여 사용하는 것 같은 효과를 냄"
      ]
    }
  ]
}