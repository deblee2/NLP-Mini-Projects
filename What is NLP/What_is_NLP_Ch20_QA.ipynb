{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "What_is_NLP_Ch20_QA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJExLFmhVBCj"
      },
      "source": [
        "## 20. 질의응답 Question Answering, QA\n",
        "* 페이스북의 Babi QA 셋을 메모리 네트워크를 통해 품\n",
        "* BERT를 이용하여 MRC(기계 독해 이해력) 테스트인 스쿼드(SQuAD, Stanford Question Answering Dataset) 풀어보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6arqB2MPVPYJ"
      },
      "source": [
        "### 1) 메모리 네트워크 Memory Network, MemN을 이용한 QA\n",
        "#### 1. Babi 데이터셋\n",
        "* 스토리, 질문, 답으로 이루어짐\n",
        "* 질문이 나왔어도 스토리는 계속 이어지고 질문도 이어짐  \n",
        "\n",
        "#### 2. 메모리 네트워크 구조\n",
        "* 두 개의 입력: 스토리 문장과 질문 문장\n",
        "* 각각의 임베딩 과정을 거쳐야 함  \n",
        "* 이후 내적(dot product)를 통해 각 단어 간 유사도를 구하고, 소프트맥스 함수를 지나서 Embedding A로 임베딩 된 스토리 문장에 더해짐  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7YQ2rHdW32q"
      },
      "source": [
        "* 표현 바꿔서) 스토리 문장: Value와 Key, 질문 문장: Query \n",
        "* Query는 Key와 유사도를 구하고, 소프트맥스 함수를 통해 값을 정규화하여 Value에 더해서 이 유사도값을 반영해줌\n",
        "* 결국 지금까지의 연산 과정은 **어텐션 메커니즘**의 의도를 가지고 있음  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDJHeGlSXPWg"
      },
      "source": [
        "* (1) 어텐션 메커니즘을 통해서 질문 문장과의 유사도를 반영한 **스토리 문장 표현**을 얻기 위한 여정\n",
        "* (2) 이를 질문 문장을 임베딩한 **질문 표현**과 연결(concatenate)\n",
        "* (3) 이 표현을 LSTM과 밀집층(dense layer)의 입력으로 사용하여 정답 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjMwYZ90XTxQ"
      },
      "source": [
        "#### 3. Babi 데이터셋 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHVzhl6iVOXw"
      },
      "source": [
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import tarfile\n",
        "from nltk import FreqDist\n",
        "from functools import reduce\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "recdUIj8Xo_1"
      },
      "source": [
        "# 케라스의 get_file을 통해 데이터셋을 다운로드\n",
        "path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/'\n",
        "                'babi_tasks_1-20_v1-2.tar.gz')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_r-EgE4XwHj"
      },
      "source": [
        "# 압축을 풀고 훈련 데이터와 테스트 데이터를 각각 얻음\n",
        "with tarfile.open(path) as tar:\n",
        "  tar.extractall()\n",
        "  tar.close()\n",
        "\n",
        "DATA_DIR = 'tasks_1-20_v1-2/en-10k'\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
        "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LorWezvqYdIX",
        "outputId": "196a9b5c-c8fc-44e0-e255-e3b53929f2a6"
      },
      "source": [
        "# 훈련 데이터로부터 상위 20개의 라인 읽고 출력\n",
        "i = 0\n",
        "lines = open(TRAIN_FILE, \"rb\")\n",
        "for line in lines:\n",
        "    line = line.decode(\"utf-8\").strip()\n",
        "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
        "    i = i + 1\n",
        "    print(line)\n",
        "    if i == 20:\n",
        "      break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Mary moved to the bathroom.\n",
            "2 John went to the hallway.\n",
            "3 Where is Mary? \tbathroom\t1\n",
            "4 Daniel went back to the hallway.\n",
            "5 Sandra moved to the garden.\n",
            "6 Where is Daniel? \thallway\t4\n",
            "7 John moved to the office.\n",
            "8 Sandra journeyed to the bathroom.\n",
            "9 Where is Daniel? \thallway\t4\n",
            "10 Mary moved to the hallway.\n",
            "11 Daniel travelled to the office.\n",
            "12 Where is Daniel? \toffice\t11\n",
            "13 John went back to the garden.\n",
            "14 John moved to the bedroom.\n",
            "15 Where is Sandra? \tbathroom\t8\n",
            "1 Sandra travelled to the office.\n",
            "2 Sandra went to the bathroom.\n",
            "3 Where is Sandra? \tbathroom\t2\n",
            "4 Mary went to the bedroom.\n",
            "5 Daniel moved to the hallway.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP8m-GF9bFpj"
      },
      "source": [
        "* 숫자 1부터 15까지 한 개의 스토리\n",
        "* 중간 중간에 질문이 나오고 있음\n",
        "* 질문 옆에는 질문에 해당하는 정답이 적혀 있고, 정답 옆의 번호는 해당 정답이 몇 번의 라인에 있엇는지 알려줌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVtudZL7ZdN2"
      },
      "source": [
        "# 전처리를 거쳐 스토리, 질문, 답변을 전부 별도로 저장\n",
        "def read_data(dir):\n",
        "  stories, questions, answers = [], [], []\n",
        "  story_temp = [] #현재 시점의 스토리 임시 저장\n",
        "  lines = open(dir, \"rb\")\n",
        "\n",
        "  for line in lines:\n",
        "    line = line.decode(\"utf-8\") # b' 제거\n",
        "    line = line.strip() #'\\n' 제거\n",
        "    idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
        "    # 여기까지는 모든 줄에 적용되는 전처리\n",
        "\n",
        "    if int(idx) == 1:\n",
        "      story_temp = []\n",
        "\n",
        "    if \"\\t\" in text: #현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
        "      question, answer, _ = text.split(\"\\t\") #질문과 답변을 각각 저장\n",
        "      stories.append([x for x in story_temp if x]) #지금까지의 누적 스토리를 스토리에 저장\n",
        "      questions.append(question)\n",
        "      answers.append(answer)\n",
        "    \n",
        "    else: #현재 읽는 줄이 스토리인 경우\n",
        "      story_temp.append(text)\n",
        "  \n",
        "  lines.close()\n",
        "  return stories, questions, answers\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhPQQADrpaog"
      },
      "source": [
        "train_data = read_data(TRAIN_FILE)\n",
        "test_data = read_data(TEST_FILE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YYiUuF-pgoJ"
      },
      "source": [
        "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
        "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3ViwwsQpp2S",
        "outputId": "688e73b4-983f-475e-887d-3e04aec42abd"
      },
      "source": [
        "print('훈련용 스토리의 개수 :', len(train_stories))\n",
        "print('훈련용 질문의 개수 :',len(train_questions))\n",
        "print('훈련용 답변의 개수 :',len(train_answers))\n",
        "print('테스트용 스토리의 개수 :',len(test_stories))\n",
        "print('테스트용 질문의 개수 :',len(test_questions))\n",
        "print('테스트용 답변의 개수 :',len(test_answers))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 스토리의 개수 : 10000\n",
            "훈련용 질문의 개수 : 10000\n",
            "훈련용 답변의 개수 : 10000\n",
            "테스트용 스토리의 개수 : 1000\n",
            "테스트용 질문의 개수 : 1000\n",
            "테스트용 답변의 개수 : 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuegnHubwGbA",
        "outputId": "d4930f85-f519-45f7-905e-82fd8cfc53a7"
      },
      "source": [
        "train_stories[3576]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John went back to the garden.',\n",
              " 'Mary went to the kitchen.',\n",
              " 'Sandra went back to the bedroom.',\n",
              " 'John travelled to the bedroom.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4InhvSk8wJS3",
        "outputId": "4da9c646-c50f-42e1-c71e-fd9ea6cc1946"
      },
      "source": [
        "train_questions[3576]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Where is John? '"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XG2w50KawMau",
        "outputId": "4c453c85-d619-4339-8f46-3f4ae04b1fcc"
      },
      "source": [
        "train_answers[3576]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bedroom'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvGqlyqlwOuw"
      },
      "source": [
        "def tokenize(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)', sent) if x and x.strip()]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcc5jMF_9zwh"
      },
      "source": [
        "def preprocess_data(train_data, test_data):\n",
        "    counter = FreqDist()\n",
        "\n",
        "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    # 각 샘플의 길이를 저장하는 리스트\n",
        "    story_len = []\n",
        "    question_len = []\n",
        "\n",
        "    for stories, questions, answers in [train_data, test_data]:\n",
        "        for story in stories:\n",
        "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
        "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
        "            for word in stories: # 단어 집합에 단어 추가\n",
        "                counter[word] += 1\n",
        "        for question in questions:\n",
        "            question = tokenize(question)\n",
        "            question_len.append(len(question))\n",
        "            for word in question:\n",
        "                counter[word] += 1\n",
        "        for answer in answers:\n",
        "            answer = tokenize(answer)\n",
        "            for word in answer:\n",
        "                counter[word] += 1\n",
        "\n",
        "    # 단어 집합 생성\n",
        "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
        "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
        "\n",
        "    # 가장 긴 샘플의 길이\n",
        "    story_max_len = np.max(story_len)\n",
        "    question_max_len = np.max(question_len)\n",
        "\n",
        "    return word2idx, idx2word, story_max_len, question_max_len"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3wXuXMq7Jnu"
      },
      "source": [
        "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPC4Lifg7Kw2",
        "outputId": "4dadc4db-d596-4230-bd22-6479b36f9de1"
      },
      "source": [
        "print(word2idx)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'to': 1, 'the': 2, '.': 3, 'went': 4, 'Sandra': 5, 'John': 6, 'Daniel': 7, 'Mary': 8, 'travelled': 9, 'journeyed': 10, 'back': 11, 'bathroom': 12, 'garden': 13, 'hallway': 14, 'moved': 15, 'office': 16, 'kitchen': 17, 'bedroom': 18, 'Where': 19, 'is': 20, '?': 21}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJdHU5JE-Ehr"
      },
      "source": [
        "vocab_size = len(word2idx) + 1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCXUjTbd-HrB",
        "outputId": "37341c43-f0d3-4f65-e706-98c8073a7d0c"
      },
      "source": [
        "print('스토리의 최대 길이 :',story_max_len)\n",
        "print('질문의 최대 길이 :',question_max_len)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "스토리의 최대 길이 : 68\n",
            "질문의 최대 길이 : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OvPp0Z6-JAm"
      },
      "source": [
        "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
        "    Xs, Xq, Y = [], [], []\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    stories, questions, answers = data\n",
        "    for story, question, answer in zip(stories, questions, answers):\n",
        "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
        "        xq = [word2idx[w] for w in tokenize(question)]\n",
        "        Xs.append(xs)\n",
        "        Xq.append(xq)\n",
        "        Y.append(word2idx[answer])\n",
        "\n",
        "        # 스토리와 질문은 각각의 최대 길이로 패딩\n",
        "        # 정답은 원-핫 인코딩\n",
        "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
        "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
        "           to_categorical(Y, num_classes=len(word2idx) + 1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmQ023xR-yIT"
      },
      "source": [
        "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
        "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ixlX9tO-9Io",
        "outputId": "eb28b72e-85e1-4933-ae65-118a0048389e"
      },
      "source": [
        "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 68) (10000, 4) (10000, 22) (1000, 68) (1000, 4) (1000, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DmeDaVE_R3y"
      },
      "source": [
        "#### 4. 메모리 네트워크로 QA 테스크 풀기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnxvIicW_H_O"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ujiK-X4_ZKg"
      },
      "source": [
        "# 에포크 횟수\n",
        "train_epochs = 120\n",
        "# 배치 크기\n",
        "batch_size = 32\n",
        "# 임베딩 크기\n",
        "embed_size = 50\n",
        "# LSTM의 크기\n",
        "lstm_size = 64\n",
        "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
        "dropout_rate = 0.30"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGy1nb-D_oxF",
        "outputId": "dc6b02ef-2a95-4fd9-835f-b4ae451e38dd"
      },
      "source": [
        "# 플레이스 홀더. 입력을 담는 변수\n",
        "input_sequence = Input((story_max_len,))\n",
        "question = Input((question_max_len,))\n",
        "\n",
        "print('Stories :', input_sequence)\n",
        "print('Question:', question)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stories : KerasTensor(type_spec=TensorSpec(shape=(None, 68), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RleCosIJ_8Q-"
      },
      "source": [
        "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size, \n",
        "                              output_dim=embed_size))\n",
        "input_encoder_m.add(Dropout(dropout_rate))\n",
        "\n",
        "# 결과: (samples, story_max_len, embedding_dim) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
        "\n",
        "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
        "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size, \n",
        "                              output_dim=question_max_len))\n",
        "input_encoder_c.add(Dropout(dropout_rate))\n",
        "# 결과: (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCQAV3XiAvtD"
      },
      "source": [
        "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size, \n",
        "                               output_dim=embed_size, \n",
        "                               input_length=question_max_len))\n",
        "question_encoder.add(Dropout(dropout_rate))\n",
        "# 결과: (samples, question_max_len, embedding_dim) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FueUDw-gBDd_",
        "outputId": "c713d334-3097-42fc-d946-46c993250b12"
      },
      "source": [
        "# 실질적인 임베딩 과정\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "print('Input encoded m', input_encoded_m)\n",
        "print('Input encoded c', input_encoded_c)\n",
        "print('Question encoded', question_encoded)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input encoded m KerasTensor(type_spec=TensorSpec(shape=(None, 68, 50), dtype=tf.float32, name=None), name='sequential/dropout/Identity:0', description=\"created by layer 'sequential'\")\n",
            "Input encoded c KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='sequential_1/dropout_1/Identity:0', description=\"created by layer 'sequential_1'\")\n",
            "Question encoded KerasTensor(type_spec=TensorSpec(shape=(None, 4, 50), dtype=tf.float32, name=None), name='sequential_2/dropout_2/Identity:0', description=\"created by layer 'sequential_2'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLK12cArBYO_",
        "outputId": "296b0bd2-b10f-4345-cc49-b6560a593786"
      },
      "source": [
        "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
        "# 유사도는 내적을 사용한다.\n",
        "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
        "match = Activation('softmax')(match)\n",
        "print('Match shape', match)\n",
        "# 결과 : (samples, story_maxlen, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match shape KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='activation/Softmax:0', description=\"created by layer 'activation'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW8gqKoJFZNE",
        "outputId": "abda0c56-e5cf-4699-dbe9-ce9597d376a4"
      },
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_max_len, question_max_len)\n",
        "response = Permute((2, 1))(response)  # (samples, question_max_len, story_max_len)\n",
        "print('Response shape', response)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response shape KerasTensor(type_spec=TensorSpec(shape=(None, 4, 68), dtype=tf.float32, name=None), name='permute/transpose:0', description=\"created by layer 'permute'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzjTcPU2Fjgq",
        "outputId": "0077973d-7b28-41aa-8bc0-cd2b18081fab"
      },
      "source": [
        "\n",
        "# concatenate the response vector with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])\n",
        "print('Answer shape', answer)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer shape KerasTensor(type_spec=TensorSpec(shape=(None, 4, 118), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_kuqN2TFtBF"
      },
      "source": [
        "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
        "answer = Dropout(dropout_rate)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqdkQ9DyC_lb",
        "outputId": "901da23b-50ac-472c-f2a5-2c7387d93355"
      },
      "source": [
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# start training the model\n",
        "history = model.fit([Xstrain, Xqtrain],\n",
        "         Ytrain, batch_size, train_epochs,\n",
        "         validation_data=([Xstest, Xqtest], Ytest))\n",
        "\n",
        "# save model\n",
        "model.save('model.h5')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 68)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, None, 50)     1100        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 4, 50)        1100        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 68, 4)        0           sequential[0][0]                 \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 68, 4)        0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, None, 4)      88          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 68, 4)        0           activation[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 4, 68)        0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4, 118)       0           permute[0][0]                    \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           46848       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64)           0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 22)           1430        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 22)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 50,566\n",
            "Trainable params: 50,566\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/120\n",
            "313/313 [==============================] - 6s 11ms/step - loss: 1.8828 - acc: 0.1656 - val_loss: 1.7752 - val_acc: 0.2690\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.7075 - acc: 0.2549 - val_loss: 1.6668 - val_acc: 0.2760\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.6003 - acc: 0.3552 - val_loss: 1.4900 - val_acc: 0.4450\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.5083 - acc: 0.4144 - val_loss: 1.4821 - val_acc: 0.4160\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.4469 - acc: 0.4451 - val_loss: 1.3573 - val_acc: 0.5050\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3878 - acc: 0.4625 - val_loss: 1.3300 - val_acc: 0.5000\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.3760 - acc: 0.4678 - val_loss: 1.3108 - val_acc: 0.4980\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3382 - acc: 0.4844 - val_loss: 1.2944 - val_acc: 0.5180\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3324 - acc: 0.4843 - val_loss: 1.2799 - val_acc: 0.5230\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.3139 - acc: 0.4917 - val_loss: 1.2601 - val_acc: 0.5250\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.2801 - acc: 0.5078 - val_loss: 1.2595 - val_acc: 0.5120\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2593 - acc: 0.5122 - val_loss: 1.2295 - val_acc: 0.5310\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2432 - acc: 0.5153 - val_loss: 1.2099 - val_acc: 0.5330\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.2166 - acc: 0.5226 - val_loss: 1.1982 - val_acc: 0.5120\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.2071 - acc: 0.5147 - val_loss: 1.1957 - val_acc: 0.5170\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1915 - acc: 0.5226 - val_loss: 1.1831 - val_acc: 0.5190\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1861 - acc: 0.5151 - val_loss: 1.1858 - val_acc: 0.5170\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1724 - acc: 0.5278 - val_loss: 1.1735 - val_acc: 0.5210\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1619 - acc: 0.5224 - val_loss: 1.1711 - val_acc: 0.5200\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1570 - acc: 0.5256 - val_loss: 1.1879 - val_acc: 0.5000\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1418 - acc: 0.5269 - val_loss: 1.1630 - val_acc: 0.5240\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1387 - acc: 0.5328 - val_loss: 1.1579 - val_acc: 0.5230\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1335 - acc: 0.5279 - val_loss: 1.1405 - val_acc: 0.5330\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1257 - acc: 0.5310 - val_loss: 1.1459 - val_acc: 0.5170\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1143 - acc: 0.5307 - val_loss: 1.1583 - val_acc: 0.5170\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1059 - acc: 0.5437 - val_loss: 1.1601 - val_acc: 0.5080\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1035 - acc: 0.5411 - val_loss: 1.1311 - val_acc: 0.5260\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0980 - acc: 0.5394 - val_loss: 1.1463 - val_acc: 0.5230\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0835 - acc: 0.5507 - val_loss: 1.1542 - val_acc: 0.5210\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0618 - acc: 0.5632 - val_loss: 1.1206 - val_acc: 0.5480\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0445 - acc: 0.5757 - val_loss: 1.1004 - val_acc: 0.5610\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0168 - acc: 0.5935 - val_loss: 1.0745 - val_acc: 0.5850\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.9625 - acc: 0.6260 - val_loss: 1.0018 - val_acc: 0.6210\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.9211 - acc: 0.6500 - val_loss: 0.9560 - val_acc: 0.6520\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8580 - acc: 0.6818 - val_loss: 0.8617 - val_acc: 0.7060\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.8052 - acc: 0.7089 - val_loss: 0.8149 - val_acc: 0.7030\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7563 - acc: 0.7276 - val_loss: 0.7928 - val_acc: 0.7330\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.7108 - acc: 0.7409 - val_loss: 0.8142 - val_acc: 0.7130\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6746 - acc: 0.7550 - val_loss: 0.7149 - val_acc: 0.7380\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6443 - acc: 0.7646 - val_loss: 0.6962 - val_acc: 0.7440\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6175 - acc: 0.7730 - val_loss: 0.6723 - val_acc: 0.7360\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5993 - acc: 0.7782 - val_loss: 0.6613 - val_acc: 0.7400\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5738 - acc: 0.7869 - val_loss: 0.6521 - val_acc: 0.7600\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5633 - acc: 0.7963 - val_loss: 0.6379 - val_acc: 0.7590\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5362 - acc: 0.8012 - val_loss: 0.6260 - val_acc: 0.7570\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5128 - acc: 0.8095 - val_loss: 0.6123 - val_acc: 0.7600\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.5054 - acc: 0.8116 - val_loss: 0.6367 - val_acc: 0.7610\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4789 - acc: 0.8226 - val_loss: 0.5918 - val_acc: 0.7700\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4713 - acc: 0.8258 - val_loss: 0.5632 - val_acc: 0.7780\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4599 - acc: 0.8302 - val_loss: 0.5619 - val_acc: 0.7880\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4374 - acc: 0.8403 - val_loss: 0.5454 - val_acc: 0.7830\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4275 - acc: 0.8440 - val_loss: 0.5469 - val_acc: 0.7990\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4075 - acc: 0.8475 - val_loss: 0.5204 - val_acc: 0.7990\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3914 - acc: 0.8561 - val_loss: 0.5212 - val_acc: 0.7950\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3790 - acc: 0.8602 - val_loss: 0.5405 - val_acc: 0.7930\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3638 - acc: 0.8639 - val_loss: 0.4867 - val_acc: 0.8120\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3610 - acc: 0.8654 - val_loss: 0.4996 - val_acc: 0.8010\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3455 - acc: 0.8737 - val_loss: 0.4756 - val_acc: 0.8180\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3342 - acc: 0.8764 - val_loss: 0.4803 - val_acc: 0.8160\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3294 - acc: 0.8790 - val_loss: 0.4537 - val_acc: 0.8250\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3170 - acc: 0.8840 - val_loss: 0.4741 - val_acc: 0.8220\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3041 - acc: 0.8887 - val_loss: 0.4484 - val_acc: 0.8330\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3003 - acc: 0.8906 - val_loss: 0.4571 - val_acc: 0.8240\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2909 - acc: 0.8931 - val_loss: 0.4617 - val_acc: 0.8250\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2821 - acc: 0.8953 - val_loss: 0.4488 - val_acc: 0.8270\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2738 - acc: 0.8991 - val_loss: 0.4461 - val_acc: 0.8380\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2650 - acc: 0.9025 - val_loss: 0.4313 - val_acc: 0.8410\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2587 - acc: 0.9059 - val_loss: 0.4664 - val_acc: 0.8320\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2554 - acc: 0.9052 - val_loss: 0.4697 - val_acc: 0.8330\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2505 - acc: 0.9097 - val_loss: 0.4838 - val_acc: 0.8330\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2414 - acc: 0.9131 - val_loss: 0.4594 - val_acc: 0.8370\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2364 - acc: 0.9161 - val_loss: 0.4631 - val_acc: 0.8410\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2362 - acc: 0.9145 - val_loss: 0.4775 - val_acc: 0.8290\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2215 - acc: 0.9209 - val_loss: 0.4549 - val_acc: 0.8460\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2146 - acc: 0.9235 - val_loss: 0.4460 - val_acc: 0.8470\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2132 - acc: 0.9220 - val_loss: 0.4477 - val_acc: 0.8420\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2061 - acc: 0.9246 - val_loss: 0.4589 - val_acc: 0.8500\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2060 - acc: 0.9239 - val_loss: 0.4553 - val_acc: 0.8490\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2032 - acc: 0.9254 - val_loss: 0.4651 - val_acc: 0.8370\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1912 - acc: 0.9309 - val_loss: 0.4521 - val_acc: 0.8430\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1923 - acc: 0.9295 - val_loss: 0.4689 - val_acc: 0.8500\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1800 - acc: 0.9371 - val_loss: 0.4712 - val_acc: 0.8520\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1798 - acc: 0.9360 - val_loss: 0.4547 - val_acc: 0.8560\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1850 - acc: 0.9332 - val_loss: 0.4586 - val_acc: 0.8510\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1721 - acc: 0.9374 - val_loss: 0.5035 - val_acc: 0.8380\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1723 - acc: 0.9365 - val_loss: 0.4774 - val_acc: 0.8450\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1618 - acc: 0.9402 - val_loss: 0.4689 - val_acc: 0.8510\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1641 - acc: 0.9425 - val_loss: 0.4842 - val_acc: 0.8430\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1527 - acc: 0.9444 - val_loss: 0.5012 - val_acc: 0.8400\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1510 - acc: 0.9467 - val_loss: 0.4883 - val_acc: 0.8390\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1533 - acc: 0.9451 - val_loss: 0.4710 - val_acc: 0.8550\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1538 - acc: 0.9462 - val_loss: 0.4474 - val_acc: 0.8620\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1428 - acc: 0.9491 - val_loss: 0.4611 - val_acc: 0.8590\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1360 - acc: 0.9536 - val_loss: 0.5342 - val_acc: 0.8430\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1378 - acc: 0.9511 - val_loss: 0.5105 - val_acc: 0.8520\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1288 - acc: 0.9522 - val_loss: 0.5021 - val_acc: 0.8490\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1312 - acc: 0.9543 - val_loss: 0.4706 - val_acc: 0.8680\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1315 - acc: 0.9519 - val_loss: 0.4782 - val_acc: 0.8640\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1275 - acc: 0.9547 - val_loss: 0.5250 - val_acc: 0.8420\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1285 - acc: 0.9549 - val_loss: 0.5154 - val_acc: 0.8570\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1224 - acc: 0.9575 - val_loss: 0.5176 - val_acc: 0.8490\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1189 - acc: 0.9594 - val_loss: 0.5078 - val_acc: 0.8570\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1165 - acc: 0.9583 - val_loss: 0.5108 - val_acc: 0.8590\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1167 - acc: 0.9579 - val_loss: 0.4969 - val_acc: 0.8590\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.1122 - acc: 0.9616 - val_loss: 0.4843 - val_acc: 0.8600\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1131 - acc: 0.9596 - val_loss: 0.5026 - val_acc: 0.8700\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1025 - acc: 0.9650 - val_loss: 0.4941 - val_acc: 0.8640\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1031 - acc: 0.9646 - val_loss: 0.5060 - val_acc: 0.8570\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0983 - acc: 0.9661 - val_loss: 0.5017 - val_acc: 0.8660\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1049 - acc: 0.9628 - val_loss: 0.4881 - val_acc: 0.8640\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0980 - acc: 0.9687 - val_loss: 0.5393 - val_acc: 0.8520\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0976 - acc: 0.9683 - val_loss: 0.5089 - val_acc: 0.8570\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1048 - acc: 0.9621 - val_loss: 0.5001 - val_acc: 0.8650\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0937 - acc: 0.9679 - val_loss: 0.5282 - val_acc: 0.8730\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0928 - acc: 0.9666 - val_loss: 0.5589 - val_acc: 0.8550\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0939 - acc: 0.9695 - val_loss: 0.5168 - val_acc: 0.8560\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0910 - acc: 0.9692 - val_loss: 0.5069 - val_acc: 0.8720\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0941 - acc: 0.9688 - val_loss: 0.5204 - val_acc: 0.8600\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0845 - acc: 0.9747 - val_loss: 0.5108 - val_acc: 0.8660\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0849 - acc: 0.9714 - val_loss: 0.5234 - val_acc: 0.8740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9ZDeFVxDdn9",
        "outputId": "e0d4effa-b5d1-4c6a-ab9a-85f8a0e7a0c5"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5234 - acc: 0.8740\n",
            "\n",
            " 테스트 정확도: 0.8740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "_na2ImM6H0vd",
        "outputId": "4f56201b-8dbf-4839-8869-11c360e8ecf9"
      },
      "source": [
        "# Plot accuracy and loss plot\n",
        "plt.subplot(211)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# labels\n",
        "ytest = np.argmax(Ytest, axis=1)\n",
        "\n",
        "# get predictions\n",
        "Ytest_ = model.predict([Xstest, Xqtest])\n",
        "ytest_ = np.argmax(Ytest_, axis=1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkM956CgIDsN"
      },
      "source": [
        "### 2) MemN으로 한국어 QA\n",
        "* 한국어 Babi 데이터셋에 대해서 이전 챕터에서 구현한 메모리 네트워크 \n",
        "테스트\n",
        "\n",
        "#### 1. 커스터마이즈드 KoNLPy 사용하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydf29KdDH_G2",
        "outputId": "3b9e442f-da19-43df-ddd9-685daf348a0a"
      },
      "source": [
        "# 사용자 사전 추가가 매우 쉬운 패키지\n",
        "!pip install customized_konlpy"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting customized_konlpy\n",
            "  Downloading customized_konlpy-0.0.64-py3-none-any.whl (881 kB)\n",
            "\u001b[K     |████████████████████████████████| 881 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting Jpype1>=0.6.1\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 56.5 MB/s \n",
            "\u001b[?25hCollecting konlpy>=0.4.4\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from Jpype1>=0.6.1->customized_konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy>=0.4.4->customized_konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy>=0.4.4->customized_konlpy) (3.10.0)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy>=0.4.4->customized_konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (1.7.1)\n",
            "Installing collected packages: Jpype1, colorama, beautifulsoup4, konlpy, customized-konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed Jpype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 customized-konlpy-0.0.64 konlpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BQzydDNITJP",
        "outputId": "3cce5219-8440-4914-bffd-ac92de6aeff7"
      },
      "source": [
        "from ckonlpy.tag import Twitter\n",
        "\n",
        "twitter = Twitter()\n",
        "twitter.morphs('은경이는 사무실로 갔습니다.')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['은', '경이', '는', '사무실', '로', '갔습니다', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcOt7_egIeQk"
      },
      "source": [
        "twitter.add_dictionary('은경이', 'Noun')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avQi5qPZIkQ9",
        "outputId": "7d4261ce-a91a-4315-a024-5a77ee0143fc"
      },
      "source": [
        "twitter.morphs('은경이는 사무실로 갔습니다.')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['은경이', '는', '사무실', '로', '갔습니다', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-ilZE5OIoXg"
      },
      "source": [
        "#### 2. 한국어 Babi 데이터셋 로드와 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jht-ouNrImkV"
      },
      "source": [
        "from ckonlpy.tag import Twitter\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from nltk import FreqDist\n",
        "from functools import reduce\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "mdFL6f8UI1aJ",
        "outputId": "e4eacddc-f278-4e2d-e6ea-d1ad916f9959"
      },
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0df0040a-ef13-4a7f-bf47-af3af86d31e0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0df0040a-ef13-4a7f-bf47-af3af86d31e0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving qa1_single-supporting-fact_test_kor.txt to qa1_single-supporting-fact_test_kor.txt\n",
            "Saving qa1_single-supporting-fact_train_kor.txt to qa1_single-supporting-fact_train_kor.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iFWJFNkJAFW"
      },
      "source": [
        "TRAIN_FILE = os.path.join(\"/content/qa1_single-supporting-fact_train_kor.txt\")\n",
        "TEST_FILE = os.path.join(\"/content/qa1_single-supporting-fact_test_kor.txt\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBWjvj46JKJm",
        "outputId": "caa3fa8b-dd94-4cfd-e3b0-0849ece74393"
      },
      "source": [
        "# 훈련 데이터로부터 상위 20개의 문장 출력\n",
        "i = 0\n",
        "lines = open(TRAIN_FILE,  \"rb\")\n",
        "for line in lines:\n",
        "  line = line.decode(\"utf-8\").strip()\n",
        "  i = i + 1\n",
        "  print(line)\n",
        "  if i == 20:\n",
        "    break"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 필웅이는 화장실로 갔습니다.\n",
            "2 은경이는 복도로 이동했습니다.\n",
            "3 필웅이는 어디야? \t화장실\t1\n",
            "4 수종이는 복도로 복귀했습니다.\n",
            "5 경임이는 정원으로 갔습니다.\n",
            "6 수종이는 어디야? \t복도\t4\n",
            "7 은경이는 사무실로 갔습니다.\n",
            "8 경임이는 화장실로 뛰어갔습니다.\n",
            "9 수종이는 어디야? \t복도\t4\n",
            "10 필웅이는 복도로 갔습니다.\n",
            "11 수종이는 사무실로 가버렸습니다.\n",
            "12 수종이는 어디야? \t사무실\t11\n",
            "13 은경이는 정원으로 복귀했습니다.\n",
            "14 은경이는 침실로 갔습니다.\n",
            "15 경임이는 어디야? \t화장실\t8\n",
            "1 경임이는 사무실로 가버렸습니다.\n",
            "2 경임이는 화장실로 이동했습니다.\n",
            "3 경임이는 어디야? \t화장실\t2\n",
            "4 필웅이는 침실로 이동했습니다.\n",
            "5 수종이는 복도로 갔습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86DR_FgWJVWR"
      },
      "source": [
        "# 전처리를 거쳐 스토리, 질문, 답변을 전부 별도로 저장\n",
        "def read_data(dir):\n",
        "  stories, questions, answers = [], [], []\n",
        "  story_temp = [] #현재 시점의 스토리 임시 저장\n",
        "  lines = open(dir, \"rb\")\n",
        "\n",
        "  for line in lines:\n",
        "    line = line.decode(\"utf-8\") # b' 제거\n",
        "    line = line.strip() #'\\n' 제거\n",
        "    idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
        "    # 여기까지는 모든 줄에 적용되는 전처리\n",
        "\n",
        "    if int(idx) == 1:\n",
        "      story_temp = []\n",
        "\n",
        "    if \"\\t\" in text: #현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
        "      question, answer, _ = text.split(\"\\t\") #질문과 답변을 각각 저장\n",
        "      stories.append([x for x in story_temp if x]) #지금까지의 누적 스토리를 스토리에 저장\n",
        "      questions.append(question)\n",
        "      answers.append(answer)\n",
        "    \n",
        "    else: #현재 읽는 줄이 스토리인 경우\n",
        "      story_temp.append(text)\n",
        "  \n",
        "  lines.close()\n",
        "  return stories, questions, answers\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkSdx2s5Jdxs"
      },
      "source": [
        "train_data = read_data(TRAIN_FILE)\n",
        "test_data = read_data(TEST_FILE)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_BuBRq3JfLF"
      },
      "source": [
        "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
        "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1X4udciJg4j",
        "outputId": "328ebd1e-f7d4-4ccf-e9fc-03c5f1417dff"
      },
      "source": [
        "print('훈련용 스토리의 개수 :', len(train_stories))\n",
        "print('훈련용 질문의 개수 :',len(train_questions))\n",
        "print('훈련용 답변의 개수 :',len(train_answers))\n",
        "print('테스트용 스토리의 개수 :',len(test_stories))\n",
        "print('테스트용 질문의 개수 :',len(test_questions))\n",
        "print('테스트용 답변의 개수 :',len(test_answers))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 스토리의 개수 : 10000\n",
            "훈련용 질문의 개수 : 10000\n",
            "훈련용 답변의 개수 : 10000\n",
            "테스트용 스토리의 개수 : 1000\n",
            "테스트용 질문의 개수 : 1000\n",
            "테스트용 답변의 개수 : 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1QI5d8gJijI",
        "outputId": "d61dc58e-c095-4df2-ac3e-ccd387cb1fb7"
      },
      "source": [
        "train_stories[3572]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['은경이는 부엌으로 가버렸습니다.',\n",
              " '필웅이는 사무실로 가버렸습니다.',\n",
              " '수종이는 복도로 뛰어갔습니다.',\n",
              " '은경이는 사무실로 복귀했습니다.',\n",
              " '경임이는 사무실로 이동했습니다.',\n",
              " '경임이는 침실로 갔습니다.']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "n2Fuqz9PJkLG",
        "outputId": "d45d99c5-81cb-485f-8b8f-8cfc2c686395"
      },
      "source": [
        "train_questions[3572]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'은경이는 어디야? '"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ha9CcwL-J-NV",
        "outputId": "919016bd-95df-443b-f3d8-924b965a8b66"
      },
      "source": [
        "train_answers[3572]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'사무실'"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmzgV94cOm1I"
      },
      "source": [
        "def tokenize(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)', sent) if x and x.strip()]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ltUgqeEOm1J"
      },
      "source": [
        "def preprocess_data(train_data, test_data):\n",
        "    counter = FreqDist()\n",
        "\n",
        "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    # 각 샘플의 길이를 저장하는 리스트\n",
        "    story_len = []\n",
        "    question_len = []\n",
        "\n",
        "    for stories, questions, answers in [train_data, test_data]:\n",
        "        for story in stories:\n",
        "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
        "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
        "            for word in stories: # 단어 집합에 단어 추가\n",
        "                counter[word] += 1\n",
        "        for question in questions:\n",
        "            question = tokenize(question)\n",
        "            question_len.append(len(question))\n",
        "            for word in question:\n",
        "                counter[word] += 1\n",
        "        for answer in answers:\n",
        "            answer = tokenize(answer)\n",
        "            for word in answer:\n",
        "                counter[word] += 1\n",
        "\n",
        "    # 단어 집합 생성\n",
        "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
        "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
        "\n",
        "    # 가장 긴 샘플의 길이\n",
        "    story_max_len = np.max(story_len)\n",
        "    question_max_len = np.max(question_len)\n",
        "\n",
        "    return word2idx, idx2word, story_max_len, question_max_len"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF37JxNdOm1K"
      },
      "source": [
        "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4NZIZzVOm1K",
        "outputId": "1b6afc06-fb17-4250-a455-c01fbff0fff4"
      },
      "source": [
        "print(word2idx)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'.': 1, '경임이는': 2, '은경이는': 3, '수종이는': 4, '필웅이는': 5, '이동했습니다': 6, '가버렸습니다': 7, '뛰어갔습니다': 8, '복귀했습니다': 9, '갔습니다': 10, '화장실로': 11, '정원으로': 12, '복도로': 13, '어디야': 14, '?': 15, '부엌으로': 16, '사무실로': 17, '침실로': 18, '화장실': 19, '정원': 20, '사무실': 21, '침실': 22, '복도': 23, '부엌': 24}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h04j-OPWPAxE",
        "outputId": "c985c5a4-6b4d-4dfe-b4a6-edac6029a764"
      },
      "source": [
        "# 형태소 분석기를 사용해서 이름이 분리되지 않도록 함\n",
        "twitter = Twitter()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZovEpxSPGpe",
        "outputId": "4717a9b2-6f80-43e4-c95b-4035628d6a3d"
      },
      "source": [
        "print(twitter.morphs('은경이는 화장실로 이동했습니다.'))\n",
        "print(twitter.morphs('경임이는 정원으로 가버렸습니다.'))\n",
        "print(twitter.morphs('수종이는 복도로 뛰어갔습니다.'))\n",
        "print(twitter.morphs('필웅이는 부엌으로 복귀했습니다.'))\n",
        "print(twitter.morphs('수종이는 사무실로 갔습니다.'))\n",
        "print(twitter.morphs('은경이는 침실로 갔습니다.'))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['은', '경이', '는', '화장실', '로', '이동', '했습니다', '.']\n",
            "['경', '임', '이', '는', '정원', '으로', '가버렸습니다', '.']\n",
            "['수종', '이', '는', '복도', '로', '뛰어갔습니다', '.']\n",
            "['필웅이', '는', '부엌', '으로', '복귀', '했습니다', '.']\n",
            "['수종', '이', '는', '사무실', '로', '갔습니다', '.']\n",
            "['은', '경이', '는', '침실', '로', '갔습니다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atJS6RyMPMAA"
      },
      "source": [
        "twitter.add_dictionary('은경이', 'Noun')\n",
        "twitter.add_dictionary('경임이', 'Noun')\n",
        "twitter.add_dictionary('수종이', 'Noun')"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KxeVzkcPOaN",
        "outputId": "5dd64572-1ff1-4454-c51f-dc53587a5e91"
      },
      "source": [
        "print(twitter.morphs('은경이는 화장실로 이동했습니다.'))\n",
        "print(twitter.morphs('경임이는 정원으로 가버렸습니다.'))\n",
        "print(twitter.morphs('수종이는 복도로 뛰어갔습니다.'))\n",
        "print(twitter.morphs('필웅이는 부엌으로 복귀했습니다.'))\n",
        "print(twitter.morphs('수종이는 사무실로 갔습니다.'))\n",
        "print(twitter.morphs('은경이는 침실로 갔습니다.'))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['은경이', '는', '화장실', '로', '이동', '했습니다', '.']\n",
            "['경임이', '는', '정원', '으로', '가버렸습니다', '.']\n",
            "['수종이', '는', '복도', '로', '뛰어갔습니다', '.']\n",
            "['필웅이', '는', '부엌', '으로', '복귀', '했습니다', '.']\n",
            "['수종이', '는', '사무실', '로', '갔습니다', '.']\n",
            "['은경이', '는', '침실', '로', '갔습니다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaGmtNwrPRav"
      },
      "source": [
        "# 이를 새로운 토큰화 함수로 정의"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJjTzQpvPa3D"
      },
      "source": [
        "def tokenize(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)', sent) if x and x.strip()]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6njZDeCPa3E"
      },
      "source": [
        "def preprocess_data(train_data, test_data):\n",
        "    counter = FreqDist()\n",
        "\n",
        "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    # 각 샘플의 길이를 저장하는 리스트\n",
        "    story_len = []\n",
        "    question_len = []\n",
        "\n",
        "    for stories, questions, answers in [train_data, test_data]:\n",
        "        for story in stories:\n",
        "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
        "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
        "            for word in stories: # 단어 집합에 단어 추가\n",
        "                counter[word] += 1\n",
        "        for question in questions:\n",
        "            question = tokenize(question)\n",
        "            question_len.append(len(question))\n",
        "            for word in question:\n",
        "                counter[word] += 1\n",
        "        for answer in answers:\n",
        "            answer = tokenize(answer)\n",
        "            for word in answer:\n",
        "                counter[word] += 1\n",
        "\n",
        "    # 단어 집합 생성\n",
        "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
        "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
        "\n",
        "    # 가장 긴 샘플의 길이\n",
        "    story_max_len = np.max(story_len)\n",
        "    question_max_len = np.max(question_len)\n",
        "\n",
        "    return word2idx, idx2word, story_max_len, question_max_len"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5bfX6RQPa3F"
      },
      "source": [
        "# 형태소 분석기를 토큰화 함수를 번경하였기 때문에 이전보다 시간이 더 소요됨\n",
        "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0mtmM9lPa3G",
        "outputId": "5ad03a17-ff49-4234-d29b-5bdbed9f6ec7"
      },
      "source": [
        "print(word2idx)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'.': 1, '경임이는': 2, '은경이는': 3, '수종이는': 4, '필웅이는': 5, '이동했습니다': 6, '가버렸습니다': 7, '뛰어갔습니다': 8, '복귀했습니다': 9, '갔습니다': 10, '화장실로': 11, '정원으로': 12, '복도로': 13, '어디야': 14, '?': 15, '부엌으로': 16, '사무실로': 17, '침실로': 18, '화장실': 19, '정원': 20, '사무실': 21, '침실': 22, '복도': 23, '부엌': 24}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtLcI5EYK0oH",
        "outputId": "ca22eb17-df4a-43ca-e68e-75dd7cf50f89"
      },
      "source": [
        "# 단어 집합의 크기 정의\n",
        "vocab_size = len(word2idx) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FnHPHa2O2Re",
        "outputId": "647329e0-451f-4159-d0e8-c3fbfaebba4a"
      },
      "source": [
        "print('스토리의 최대 길이 :',story_max_len)\n",
        "print('질문의 최대 길이 :',question_max_len)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "스토리의 최대 길이 : 40\n",
            "질문의 최대 길이 : 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS7Uxd3yO3iC"
      },
      "source": [
        "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
        "    Xs, Xq, Y = [], [], []\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    stories, questions, answers = data\n",
        "    for story, question, answer in zip(stories, questions, answers):\n",
        "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
        "        xq = [word2idx[w] for w in tokenize(question)]\n",
        "        Xs.append(xs)\n",
        "        Xq.append(xq)\n",
        "        Y.append(word2idx[answer])\n",
        "\n",
        "        # 스토리와 질문은 각각의 최대 길이로 패딩\n",
        "        # 정답은 원-핫 인코딩\n",
        "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
        "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
        "           to_categorical(Y, num_classes=len(word2idx) + 1)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyij8VM2Pw8d"
      },
      "source": [
        "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
        "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-yzdjYDPyo3",
        "outputId": "7baf985c-5aaf-40b3-9915-7c6cc757bae9"
      },
      "source": [
        "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 40) (10000, 3) (10000, 25) (1000, 40) (1000, 3) (1000, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHa4Q6KTP1bB"
      },
      "source": [
        "#### 3. 메모리 네트워크로 QA 테스크 풀기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H_OAcdwPzkn"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XViff2feP4-A"
      },
      "source": [
        "# 에포크 횟수\n",
        "train_epochs = 120\n",
        "# 배치 크기\n",
        "batch_size = 32\n",
        "# 임베딩 크기\n",
        "embed_size = 50\n",
        "# LSTM의 크기\n",
        "lstm_size = 64\n",
        "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
        "dropout_rate = 0.30"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxmOYY7kP6xH",
        "outputId": "86a89cd8-a0e9-40f4-f55a-ed2653720e0b"
      },
      "source": [
        "# 플레이스 홀더. 입력을 담는 변수\n",
        "input_sequence = Input((story_max_len,))\n",
        "question = Input((question_max_len,))\n",
        "\n",
        "print('Stories :', input_sequence)\n",
        "print('Question:', question)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stories : KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\")\n",
            "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtFK6x2iP-9H"
      },
      "source": [
        "  # 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=embed_size))\n",
        "input_encoder_m.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, embedding_dim) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
        "\n",
        "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
        "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=question_max_len))\n",
        "input_encoder_c.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH6_0prDQzox"
      },
      "source": [
        "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=embed_size,\n",
        "                               input_length=question_max_len))\n",
        "question_encoder.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, question_max_len, embedding_dim) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqWsX-_1Q0_c",
        "outputId": "6a7af841-e58d-4d8f-d2cb-d6a5ac8d75df"
      },
      "source": [
        "# 실질적인 임베딩 과정\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "print('Input encoded m', input_encoded_m)\n",
        "print('Input encoded c', input_encoded_c)\n",
        "print('Question encoded', question_encoded)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input encoded m KerasTensor(type_spec=TensorSpec(shape=(None, 40, 50), dtype=tf.float32, name=None), name='sequential_3/dropout_4/Identity:0', description=\"created by layer 'sequential_3'\")\n",
            "Input encoded c KerasTensor(type_spec=TensorSpec(shape=(None, 40, 3), dtype=tf.float32, name=None), name='sequential_4/dropout_5/Identity:0', description=\"created by layer 'sequential_4'\")\n",
            "Question encoded KerasTensor(type_spec=TensorSpec(shape=(None, 3, 50), dtype=tf.float32, name=None), name='sequential_5/dropout_6/Identity:0', description=\"created by layer 'sequential_5'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egUMYaGdRCVa",
        "outputId": "5d4b0ac1-6bc5-4e4a-86f2-aaec553434cb"
      },
      "source": [
        "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
        "# 유사도는 내적을 사용한다.\n",
        "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
        "match = Activation('softmax')(match)\n",
        "print('Match shape', match)\n",
        "# 결과 : (samples, story_maxlen, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match shape KerasTensor(type_spec=TensorSpec(shape=(None, 40, 3), dtype=tf.float32, name=None), name='activation_2/Softmax:0', description=\"created by layer 'activation_2'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mey7yDWRCVa",
        "outputId": "98703a53-3dee-4967-db5b-d03977179aa8"
      },
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_max_len, question_max_len)\n",
        "response = Permute((2, 1))(response)  # (samples, question_max_len, story_max_len)\n",
        "print('Response shape', response)\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response shape KerasTensor(type_spec=TensorSpec(shape=(None, 3, 40), dtype=tf.float32, name=None), name='permute_1/transpose:0', description=\"created by layer 'permute_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BmfF_ZZRCVb",
        "outputId": "47ba51df-b9d0-40d7-cb46-a9a954d94b0c"
      },
      "source": [
        "\n",
        "# concatenate the response vector with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])\n",
        "print('Answer shape', answer)\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer shape KerasTensor(type_spec=TensorSpec(shape=(None, 3, 90), dtype=tf.float32, name=None), name='concatenate_1/concat:0', description=\"created by layer 'concatenate_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHRW-zEnRCVb"
      },
      "source": [
        "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
        "answer = Dropout(dropout_rate)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kcOVNBRRCVb",
        "outputId": "a66856be-9a91-4c41-b8ea-30104c6ed90d"
      },
      "source": [
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# start training the model\n",
        "history = model.fit([Xstrain, Xqtrain],\n",
        "         Ytrain, batch_size, train_epochs,\n",
        "         validation_data=([Xstest, Xqtest], Ytest))\n",
        "\n",
        "# save model\n",
        "model.save('model.h5')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 40)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, None, 50)     1250        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       (None, 3, 50)        1250        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 40, 3)        0           sequential_3[0][0]               \n",
            "                                                                 sequential_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 40, 3)        0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, None, 3)      75          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 40, 3)        0           activation_2[0][0]               \n",
            "                                                                 sequential_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 3, 40)        0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 90)        0           permute_1[0][0]                  \n",
            "                                                                 sequential_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 64)           39680       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 64)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 25)           1625        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 25)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 43,880\n",
            "Trainable params: 43,880\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/120\n",
            "313/313 [==============================] - 5s 10ms/step - loss: 1.8883 - acc: 0.1727 - val_loss: 1.7811 - val_acc: 0.1990\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.7204 - acc: 0.2536 - val_loss: 1.6295 - val_acc: 0.3240\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.5493 - acc: 0.3742 - val_loss: 1.4797 - val_acc: 0.3810\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.4962 - acc: 0.3927 - val_loss: 1.5428 - val_acc: 0.3770\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.4510 - acc: 0.4362 - val_loss: 1.3915 - val_acc: 0.4330\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.4118 - acc: 0.4508 - val_loss: 1.3647 - val_acc: 0.4520\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.3913 - acc: 0.4532 - val_loss: 1.3476 - val_acc: 0.4560\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.3748 - acc: 0.4583 - val_loss: 1.3602 - val_acc: 0.4620\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.3622 - acc: 0.4663 - val_loss: 1.3309 - val_acc: 0.4650\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.3485 - acc: 0.4690 - val_loss: 1.3228 - val_acc: 0.4870\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.3318 - acc: 0.4723 - val_loss: 1.2954 - val_acc: 0.4960\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.3233 - acc: 0.4908 - val_loss: 1.2809 - val_acc: 0.5020\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.2977 - acc: 0.4941 - val_loss: 1.2592 - val_acc: 0.5210\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.2783 - acc: 0.5041 - val_loss: 1.2491 - val_acc: 0.5130\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.2510 - acc: 0.5133 - val_loss: 1.2374 - val_acc: 0.5090\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.2572 - acc: 0.5123 - val_loss: 1.2325 - val_acc: 0.5230\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.2367 - acc: 0.5187 - val_loss: 1.2257 - val_acc: 0.5340\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2338 - acc: 0.5191 - val_loss: 1.2167 - val_acc: 0.5220\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2206 - acc: 0.5294 - val_loss: 1.2437 - val_acc: 0.4980\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.2166 - acc: 0.5238 - val_loss: 1.2066 - val_acc: 0.5230\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.2025 - acc: 0.5231 - val_loss: 1.1882 - val_acc: 0.5390\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.1232 - acc: 0.5633 - val_loss: 0.9779 - val_acc: 0.6510\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.8695 - acc: 0.6929 - val_loss: 0.7432 - val_acc: 0.7350\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.7131 - acc: 0.7428 - val_loss: 0.6615 - val_acc: 0.7390\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6320 - acc: 0.7666 - val_loss: 0.5727 - val_acc: 0.7750\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.5422 - acc: 0.7930 - val_loss: 0.4955 - val_acc: 0.8030\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4713 - acc: 0.8212 - val_loss: 0.4538 - val_acc: 0.8160\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.4365 - acc: 0.8302 - val_loss: 0.4209 - val_acc: 0.8410\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.4037 - acc: 0.8465 - val_loss: 0.4064 - val_acc: 0.8510\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.3865 - acc: 0.8511 - val_loss: 0.3896 - val_acc: 0.8550\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3651 - acc: 0.8609 - val_loss: 0.3900 - val_acc: 0.8460\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.3574 - acc: 0.8617 - val_loss: 0.3724 - val_acc: 0.8500\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.3398 - acc: 0.8669 - val_loss: 0.3525 - val_acc: 0.8600\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.3248 - acc: 0.8737 - val_loss: 0.3177 - val_acc: 0.8660\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3067 - acc: 0.8805 - val_loss: 0.2927 - val_acc: 0.8890\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.2874 - acc: 0.8900 - val_loss: 0.2587 - val_acc: 0.9040\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.2591 - acc: 0.9006 - val_loss: 0.2276 - val_acc: 0.9230\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.2404 - acc: 0.9111 - val_loss: 0.2090 - val_acc: 0.9230\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.2245 - acc: 0.9193 - val_loss: 0.1877 - val_acc: 0.9330\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.2027 - acc: 0.9275 - val_loss: 0.1933 - val_acc: 0.9380\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1905 - acc: 0.9320 - val_loss: 0.1687 - val_acc: 0.9330\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1774 - acc: 0.9373 - val_loss: 0.1720 - val_acc: 0.9440\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1699 - acc: 0.9425 - val_loss: 0.1623 - val_acc: 0.9400\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1628 - acc: 0.9417 - val_loss: 0.1423 - val_acc: 0.9420\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1580 - acc: 0.9453 - val_loss: 0.1423 - val_acc: 0.9420\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1453 - acc: 0.9481 - val_loss: 0.1299 - val_acc: 0.9500\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1426 - acc: 0.9478 - val_loss: 0.1244 - val_acc: 0.9510\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1396 - acc: 0.9513 - val_loss: 0.1184 - val_acc: 0.9620\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1258 - acc: 0.9556 - val_loss: 0.1211 - val_acc: 0.9530\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1241 - acc: 0.9561 - val_loss: 0.1153 - val_acc: 0.9580\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1239 - acc: 0.9542 - val_loss: 0.1117 - val_acc: 0.9560\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1104 - acc: 0.9586 - val_loss: 0.1019 - val_acc: 0.9660\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1041 - acc: 0.9618 - val_loss: 0.1241 - val_acc: 0.9510\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1023 - acc: 0.9633 - val_loss: 0.0879 - val_acc: 0.9720\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0907 - acc: 0.9687 - val_loss: 0.0850 - val_acc: 0.9660\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0912 - acc: 0.9677 - val_loss: 0.0728 - val_acc: 0.9730\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0838 - acc: 0.9716 - val_loss: 0.0602 - val_acc: 0.9810\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0746 - acc: 0.9736 - val_loss: 0.0614 - val_acc: 0.9790\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0680 - acc: 0.9766 - val_loss: 0.0597 - val_acc: 0.9790\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0658 - acc: 0.9772 - val_loss: 0.0454 - val_acc: 0.9810\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0610 - acc: 0.9776 - val_loss: 0.0404 - val_acc: 0.9870\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0555 - acc: 0.9816 - val_loss: 0.0357 - val_acc: 0.9920\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0533 - acc: 0.9818 - val_loss: 0.0340 - val_acc: 0.9890\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0508 - acc: 0.9837 - val_loss: 0.0326 - val_acc: 0.9880\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0426 - acc: 0.9851 - val_loss: 0.0243 - val_acc: 0.9950\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0406 - acc: 0.9853 - val_loss: 0.0342 - val_acc: 0.9860\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0370 - acc: 0.9887 - val_loss: 0.0191 - val_acc: 0.9970\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0358 - acc: 0.9889 - val_loss: 0.0188 - val_acc: 0.9940\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0320 - acc: 0.9909 - val_loss: 0.0126 - val_acc: 0.9990\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0307 - acc: 0.9906 - val_loss: 0.0125 - val_acc: 0.9990\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0278 - acc: 0.9915 - val_loss: 0.0190 - val_acc: 0.9920\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0254 - acc: 0.9918 - val_loss: 0.0131 - val_acc: 0.9970\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0204 - acc: 0.9932 - val_loss: 0.0077 - val_acc: 0.9960\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0223 - acc: 0.9936 - val_loss: 0.0076 - val_acc: 0.9990\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0234 - acc: 0.9932 - val_loss: 0.0121 - val_acc: 0.9970\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0283 - acc: 0.9924 - val_loss: 0.0113 - val_acc: 0.9960\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0226 - acc: 0.9941 - val_loss: 0.0057 - val_acc: 0.9980\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0173 - acc: 0.9953 - val_loss: 0.0049 - val_acc: 0.9990\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0144 - acc: 0.9951 - val_loss: 0.0038 - val_acc: 0.9990\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0178 - acc: 0.9947 - val_loss: 0.0063 - val_acc: 0.9980\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0223 - acc: 0.9938 - val_loss: 0.0077 - val_acc: 0.9990\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0148 - acc: 0.9959 - val_loss: 0.0158 - val_acc: 0.9980\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0164 - acc: 0.9962 - val_loss: 0.0029 - val_acc: 0.9990\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0200 - acc: 0.9951 - val_loss: 0.0025 - val_acc: 0.9990\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0196 - acc: 0.9952 - val_loss: 0.0051 - val_acc: 0.9980\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0158 - acc: 0.9960 - val_loss: 0.0041 - val_acc: 0.9990\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0110 - acc: 0.9966 - val_loss: 0.0030 - val_acc: 0.9990\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0230 - acc: 0.9951 - val_loss: 9.9406e-04 - val_acc: 1.0000\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0160 - acc: 0.9946 - val_loss: 0.0041 - val_acc: 0.9980\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0163 - acc: 0.9954 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0162 - acc: 0.9962 - val_loss: 0.0047 - val_acc: 0.9990\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0143 - acc: 0.9964 - val_loss: 0.0020 - val_acc: 0.9990\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0175 - acc: 0.9948 - val_loss: 0.0026 - val_acc: 0.9990\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0158 - acc: 0.9965 - val_loss: 3.7407e-04 - val_acc: 1.0000\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0128 - acc: 0.9967 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0133 - acc: 0.9966 - val_loss: 0.0025 - val_acc: 0.9990\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0148 - acc: 0.9962 - val_loss: 0.0037 - val_acc: 0.9980\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0160 - acc: 0.9957 - val_loss: 0.0015 - val_acc: 0.9990\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0015 - val_acc: 0.9990\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0139 - acc: 0.9971 - val_loss: 0.0020 - val_acc: 0.9980\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0159 - acc: 0.9964 - val_loss: 2.4793e-04 - val_acc: 1.0000\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.0016 - val_acc: 0.9990\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0155 - acc: 0.9967 - val_loss: 6.5248e-04 - val_acc: 1.0000\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0131 - acc: 0.9963 - val_loss: 6.4210e-04 - val_acc: 1.0000\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0119 - acc: 0.9967 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0134 - acc: 0.9971 - val_loss: 0.0018 - val_acc: 0.9990\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0138 - acc: 0.9971 - val_loss: 2.1926e-04 - val_acc: 1.0000\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0095 - acc: 0.9975 - val_loss: 7.8593e-04 - val_acc: 1.0000\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0114 - acc: 0.9971 - val_loss: 0.0127 - val_acc: 0.9970\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0136 - acc: 0.9960 - val_loss: 1.8800e-04 - val_acc: 1.0000\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0090 - acc: 0.9975 - val_loss: 6.9424e-04 - val_acc: 1.0000\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0098 - acc: 0.9968 - val_loss: 9.3058e-04 - val_acc: 1.0000\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0126 - acc: 0.9968 - val_loss: 6.1358e-04 - val_acc: 1.0000\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0097 - acc: 0.9962 - val_loss: 0.0015 - val_acc: 0.9990\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0146 - acc: 0.9963 - val_loss: 3.6481e-04 - val_acc: 1.0000\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0144 - acc: 0.9971 - val_loss: 2.6663e-04 - val_acc: 1.0000\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 1.3274e-04 - val_acc: 1.0000\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0100 - acc: 0.9977 - val_loss: 2.7853e-04 - val_acc: 1.0000\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0156 - acc: 0.9964 - val_loss: 1.9395e-04 - val_acc: 1.0000\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0158 - acc: 0.9965 - val_loss: 1.8590e-04 - val_acc: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tYpFJmxRCVb",
        "outputId": "5ce5dd52-37d0-400b-d546-240540a63002"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step - loss: 1.8590e-04 - acc: 1.0000\n",
            "\n",
            " 테스트 정확도: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "8ECMWGKPRCVc",
        "outputId": "4e2abb05-734f-46a7-fa20-0b375ec1d76f"
      },
      "source": [
        "# Plot accuracy and loss plot\n",
        "plt.subplot(211)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# labels\n",
        "ytest = np.argmax(Ytest, axis=1)\n",
        "\n",
        "# get predictions\n",
        "Ytest_ = model.predict([Xstest, Xqtest])\n",
        "ytest_ = np.argmax(Ytest_, axis=1)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1Vdv6cAQ2k6",
        "outputId": "4b226dd3-f064-4be4-f694-f5737442b842"
      },
      "source": [
        "NUM_DISPLAY = 30\n",
        "\n",
        "print(\"{:18}|{:5}|{}\".format(\"질문\", \"실제값\", \"예측값\"))\n",
        "print(39 * \"-\")\n",
        "\n",
        "for i in range(NUM_DISPLAY):\n",
        "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
        "    label = idx2word[ytest[i]]\n",
        "    prediction = idx2word[ytest_[i]]\n",
        "    print(\"{:20}: {:7} {}\".format(question, label, prediction))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문                |실제값  |예측값\n",
            "---------------------------------------\n",
            "은경이는 어디야 ?          : 복도      복도\n",
            "필웅이는 어디야 ?          : 화장실     화장실\n",
            "경임이는 어디야 ?          : 부엌      부엌\n",
            "경임이는 어디야 ?          : 복도      복도\n",
            "경임이는 어디야 ?          : 부엌      부엌\n",
            "경임이는 어디야 ?          : 복도      복도\n",
            "경임이는 어디야 ?          : 정원      정원\n",
            "수종이는 어디야 ?          : 복도      복도\n",
            "경임이는 어디야 ?          : 사무실     사무실\n",
            "수종이는 어디야 ?          : 사무실     사무실\n",
            "필웅이는 어디야 ?          : 부엌      부엌\n",
            "필웅이는 어디야 ?          : 정원      정원\n",
            "수종이는 어디야 ?          : 사무실     사무실\n",
            "필웅이는 어디야 ?          : 침실      침실\n",
            "필웅이는 어디야 ?          : 침실      침실\n",
            "은경이는 어디야 ?          : 부엌      부엌\n",
            "은경이는 어디야 ?          : 정원      정원\n",
            "은경이는 어디야 ?          : 부엌      부엌\n",
            "수종이는 어디야 ?          : 사무실     사무실\n",
            "은경이는 어디야 ?          : 부엌      부엌\n",
            "필웅이는 어디야 ?          : 복도      복도\n",
            "은경이는 어디야 ?          : 사무실     사무실\n",
            "은경이는 어디야 ?          : 사무실     사무실\n",
            "경임이는 어디야 ?          : 복도      복도\n",
            "수종이는 어디야 ?          : 침실      침실\n",
            "경임이는 어디야 ?          : 침실      침실\n",
            "필웅이는 어디야 ?          : 침실      침실\n",
            "수종이는 어디야 ?          : 부엌      부엌\n",
            "수종이는 어디야 ?          : 부엌      부엌\n",
            "수종이는 어디야 ?          : 부엌      부엌\n"
          ]
        }
      ]
    }
  ]
}