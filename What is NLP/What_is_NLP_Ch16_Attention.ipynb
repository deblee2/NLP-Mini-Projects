{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "What_is_NLP_Ch16_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVnHHepAJXCa"
      },
      "source": [
        "# 16. Attention Mechanism\n",
        "## 1. Attention Mechanism\n",
        "* **seq2seq 모델**: 인코더에서 입력 시퀀스를 **컨텍스트 벡터**라는 하나의 고정된 크기의 벡터 표현으로 압축하고, 디코더는 이 컨텍스트 벡터를 통해서 출력 시퀀스를 만들어냄\n",
        "* 하지만, 이러한 RNN 기반 seq2seq 모델은 크게 두 가지 문제가 있음\n",
        "  1. 하나의 **고정**된 크기의 벡터에 **모든 정보를 압축**하려고 하니까 정보 손실 발생\n",
        "  2. RNN의 고질적인 문제인 **기울기 소실(Vanishing Gratient) 문제**가 존재\n",
        "* 결국 이는 기계 번역 분야에서 입력 문장이 길면 번역 품질이 떨어지는 현상으로 나타남\n",
        "* 이를 위한 대안으로 입력 시퀀스가 길어지면 출력 시퀀스의 정혹도가 떨어지는 것을 보정해주기 위해 등장한 기법인 **어텐션(attention)** 소갸\n",
        "\n",
        "### 1. The Idea of Attention\n",
        "* 어텐션의 기본 아이디어: **디코더에서 출력 단어를 예측하는 매 시점(timestep)마다, 인코더에서의 전체 입력 문장을 다시 한 번 참고**한다는 점\n",
        "* 단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, **해당 시점에서 예측해야 할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중(attention)**해서 보게 됨\n",
        "\n",
        "### 2. Attention Function\n",
        "* 우선 Key-Value로 구성되는 자료형에 대해서 잠깐 언급\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixYHAJBvJRDy"
      },
      "source": [
        "# 파이썬의 딕셔너리 자료형을 선언\n",
        "# 키(Key): 값(Value)의 형식으로 키와 값의 쌍(Pair)를 선언\n",
        "dict = {\"2017\": \"Transformer\", \"2018\":\"BERT\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu2hmQOwK09i",
        "outputId": "bab70984-3012-4898-a693-77113e1e413e"
      },
      "source": [
        "print(dict[\"2017\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY7KAnQbK3HU",
        "outputId": "07c1a93f-27c2-47b8-9954-ec15020bbc76"
      },
      "source": [
        "print(dict[\"2018\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkeiaFo4LTLK"
      },
      "source": [
        "* 어텐션을 함수로 표현하면 주로 다음과 같이 표현됨\n",
        "> Attention(Q, K, V) = Attention Value\n",
        "* 어텐션 함수는 주어진 '쿼리(Query)'에 대해서 모든 '키(Key)'와의 유사도를 각각 구함\n",
        "* 그리고 구해낸 이 유사도를 키와 맵핑되어 있는 각각의 '값(Value)'에 반영해줌\n",
        "* 유사도가 반영된 '값(Value)'를 모두 더해서 리턴\n",
        "* 이를 **어텐션 값(Attention Value)**라고 함\n",
        "  1. Q = Query : t 시점의 디코더 셀에서의 은닉 상태 \n",
        "  2. K = Keys : 모든 시점의 인코더 셀의 은닉 상태들 \n",
        "  3. V = Values: 모든 시점의 인코더 셀의 은닉 상태들\n",
        "\n",
        "### 3. Dot-Product Attention\n",
        "* 소프트맥스 함수를 통해 나온 결과 값은 I, am, a, student 단어 각각이 출력 단어를 예측할 때 얼마나 도움이 되는지의 정도를 수치화한 값\n",
        "####1) 어텐션 스코어(Attention score)를 구한다\n",
        "* 인코더의 시점(time step)을 1, 2, ..., N이라고 하였을 때 인코더의 은닉 상태를 각각 h1, h2, .., hn이라고 하자\n",
        "* 디코더의 현재 시점 t에서의 디코더의 은닉 상태를 st라고 하자\n",
        "* 인코더의 은닉 상태와 디코더의 은닉 상태의 차원이 같다고 가정\n",
        "\n",
        "* 먼저 이전 챕터에서 배웠던 **디코더의 현재 시점 t에서 필요한 입력값을 다시 상기**\n",
        "  * 시점 t에서 출력 단어를 예측하기 위해서 디코더의 셀은 두 개의 입력값 필요로 하는데, 바로 이전 시점인 t-1의 은닉 상태와 이전 시점 t-1에 나온 출력 단어\n",
        "* 그런데 어텐션 메커니즘에서는 출력 단어 예측에 또 다른 값을 필요로 하는데 바로 어텐션 값(Attention Value)라는 새로운 값\n",
        "* t번째 단어를 예측하기 위한 어텐션 값을 at라고 정의\n",
        "\n",
        "* 어텐션 값이 현재 시점 t에서의 출력 예측에 구체적으로 어떻게 반영되는지는 뒤에서 설명\n",
        "* 지금까지 배우는 모든 과정은 at를 구하기 위한 여정\n",
        "* 그 여정의 첫 걸음은 바로 **어텐션 스코어(Attention Score)**를 구하는 일\n",
        "  * 정의: 현재 디코더의 시점 t에서 단어를 예측하기 위해, 인코더의 모든 은닉 상태 각각이 디코더의 현 시점의 은닉 상태 st와 얼마나 유사한지를 판단하는 스코어 값\n",
        "\n",
        "* 닷-프로덕트 어텐션에서는 이 스코어 값을 구하기 위해 st를 전치(transpose)하고 각 은닉 상태와 내적(dot product)를 수행. 즉, 모든 어텐션 스코어 값은 스칼라\n",
        "> score(st, hi) = siT hi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N23GJV9exrKI"
      },
      "source": [
        "#### 2) Softmax function을 통해 Attention distribution을 구함\n",
        "* e^t에 소프트맥스 함수를 적용하여, 모든 값을 합하면 1이 되는 확률 분포를 얻어냄\n",
        "* 이를 어텐션 분포(Attention Distribution)이라고 하며, 각각의 값은 어텐션 가중치(Attention Weight)라고 함\n",
        "* 디코더의 시점 t에서의 어텐션 가중치의 모음값인 어텐션 분포를 a^t라고 할 때, a^t를 식으로 정의하면 다음과 같음\n",
        "> a^t = softmax(e^t)\n",
        "\n",
        "#### 3) 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값(Attention Value)를 구한다.\n",
        "* 어텐션의 최종 결과값을 얻기 위해서 각 인코더의 은닉 상태와 어텐션 가중치값들을 곱하고, 최종적으로 모두 더함.\n",
        "* 요약하자면 가중합(Weighted Sum)을 한다고도 말할 수 있음\n",
        "* 이러한 어텐션 값 at는 종종 인코더의 문맥을 포함하고 있다고 하여 **컨텍스트 벡터(context vector)**라고도 불림\n",
        "* 앞서 배운 가장 기본적인 seq2seq에서는 인코더의 마지막 은닉 상태를 컨텍스트 벡터라고 부르는 것과 대조됨\n",
        "\n",
        "#### 4) 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결(Concatenate)\n",
        "* 어텐션 값이 구해지면 어텐션 메커니즘은 at를 st와 concatenate하여 하나의 벡터로 만드는 작업 수행\n",
        "  * 이를 vt라고 정의\n",
        "  * 그리고 이 vt를 y hat 예측 연산의 입력으로 사용하므로서 인코더로부터 얻은 정보를 활용하여 y hat을 좀 더 잘 예측할 수 있게 됨. 이것이 어텐션 메커니즘의 핵심.\n",
        "\n",
        "#### 5) 출력층 연산의 입력이 되는 s 물결 t를 계싼\n",
        "* 논문에서는 vt를 바로 출력층으로 보내기 전에 신경망 연산을 한 번 더 추가함\n",
        "  * 가중치 행렬과 곱한 후에 하이퍼볼릭탄젠트 함수를 지나도록 하여 출력층 연산을 위한 새로운 벡터인 s 물결 t를 얻음\n",
        "  * seq2seq에서는 출력층의 입력이 t 시점의 은닉 상태인 st였던 반면, 어텐션 메커니즘에서는 출력층의 입력이 s 물결 t가 되는 셈\n",
        "\n",
        "#### 6) s 물결 t를 출력층의 입력으로 사용\n",
        "\n",
        "### 4. 다양한 종류의 어텐션\n",
        "* 어텐션 스코어 구하는 방법에 따라 여러 종류가 존재\n",
        "  * dot, scaled dot, general, concat, location - base\n",
        "* 이름이 dot이라고 붙여진 스코어 함수가 이번 챕터에서 배운 닷 프로덕트 어텐션. 이 어텐션을 제안한 사람의 이름을 따서 루옹 어텐션이라고도 함. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDP_OaHZLpdX"
      },
      "source": [
        "## 2) 바다나우 어텐션 (Bahdanau Attention)\n",
        "### 1. 바다나우 어텐션 함수 (Bahdanau Attention Function)\n",
        "> Attention(Q, K, V) = Attention value\n",
        "* t = 어텐션 메커니즘이 수행되는 디코더 셀의 현재 시점 의미\n",
        "1. Q = Query : **t-1 시점**의 디코더 셀에서의 은닉 상태 \n",
        "2. K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
        "3. V = Values: 모든 시점의 인코더 셀의 은닉 상태들"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xTRDwHTAKZy"
      },
      "source": [
        "### 2. Bahdanau Attention\n",
        "* 연산 순서 이해\n",
        "#### 1) 어텐션 스코어 구하기\n",
        "#### 2) 소프트맥스 함수를 통해 어텐션 분포를 구하기\n",
        "#### 3) 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값 구하기\n",
        "#### 4) 컨텍스트 벡터로부터 st를 구하기\n",
        "* 기존의 LSTM: 이전 시점의 셀로부터 전달 받은 은닉 상태 s t-1와 현재 시점의 입력 x t(임베딩된 단어 벡터)를 가지고 연산\n",
        "* 어텐션 메커니즘: 컨텍스트 벡터와 현재 시점의 입력 단어인 임베딩 벡터를 concatenate하고, 현재 시점의 새로운 입력으로 사용하는 모습\n",
        "  * 그리고 이전 시점의 셀로부터 전달 받은 은닉 상태 s t-1와 현재 시점의 새로운 입력으로부터 s t를 구함\n",
        "* 정리: 기존의 LSTM이 **임베딩된 단어 벡터를 입력**으로 하는 것에서 **컨텍스트 벡터와 임베딩된 단어 벡터를 concatenate하여 입력으로 사용**하는 것이 달라짐\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFIsflmAG1Xt"
      },
      "source": [
        "## 3. 양방향 LSTM과 어텐션 메커니즘\n",
        "### 1. IMDB 리뷰 데이터 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH2SEIwWK4Lp"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYXUmKxcHLG4",
        "outputId": "4c5cf33d-4b2a-43d6-ea77-773d48dcf700"
      },
      "source": [
        "vocab_size = 10000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnxa2xZejdNx",
        "outputId": "61624519-06ba-4ffb-85b2-2a2db46985b7"
      },
      "source": [
        "# 이미 정수 인코딩이 된 상태로 남은 전처리는 패딩뿐\n",
        "print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in X_train)))\n",
        "print('리뷰의 평균 길이 : {}'.format(sum(map(len, X_train))/len(X_train)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰의 최대 길이 : 2494\n",
            "리뷰의 평균 길이 : 238.71364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvqS-wbijxo5"
      },
      "source": [
        "# 평균 길이보다 조금 더 크게 데이터 패딩\n",
        "max_len = 500\n",
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPdo1Vq9j72Y"
      },
      "source": [
        "### 2. 바다나우 어텐션\n",
        "* 어텐션 스코어 함수: 주어진 query와 모든 key에 대해서 유사도를 측정\n",
        "* 닷 프로덕트 어텐션: query와 key의 유사도를 구하는 방법이 내적(dot product)\n",
        "  > score(query, key) = queryTkey\n",
        "* 바다나우 어텐션은 아래와 같은 어텐션 스코어 함수 사용\n",
        "  > score(query, key) = VTtanh(W1key + W2query(\n",
        "* 텍스트 분류에서 어텐션 메커니즘 사용 이유?\n",
        "  * **RNN의 마지막 은닉 상태는 예측을 위해서 사용됨**\n",
        "  * **그런데 이 RNN의 마지막 은닉 상태는 몇 가지 유용한 정보들을 손실한 상태**. 그래서 RNN이 time step을 지나며 손실했던 정보들을 다시 참고하고자 함(**RNN의 모든 은닉 상태를 다시 한 번 참고**)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdbhUNZwj6mO"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOiNldVlkncZ"
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "  \n",
        "  def call(self, values, query): #단, key와 value는 같음\n",
        "    # query shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원 변경\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "    \n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQU8PPz_lqKx"
      },
      "source": [
        "### 3. 양방향 LSTM + 어텐션 메커니즘(BiLSTM with Attention Mechanism)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm1OrvVLle4N"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers\n",
        "import os"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxhmTyd4lvkv"
      },
      "source": [
        "# 모델 설계. 케라스 함수형 API 사용.\n",
        "# 입력층과 임베딩층 설계\n",
        "\n",
        "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)\n",
        "\n",
        "# 10000개의 단어들을 128 차원의 벡터로 임베딩하도록 설계"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VyoxyzbmBEh"
      },
      "source": [
        "# 이제 양방향 LSTM 설계\n",
        "# 여기에서는 양방향 LSTM을 두 층을 사용\n",
        "# 첫번째 층. 두번째 층을 위에 쌓을 예정으로 return_sequences = True로 해줌\n",
        "lstm = Bidirectional(LSTM(64, dropout = 0.5, return_sequences = True))(embedded_sequences)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78r8qkcKmO_O"
      },
      "source": [
        "# 두번째 층 설계\n",
        "# 상태를 리턴받아야 하여 return_state = True\n",
        "\n",
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqgf0hb2maJ0",
        "outputId": "4098d3d0-cf0e-42b4-bb01-bf0a0c9a28d3"
      },
      "source": [
        "# 각 상태의 크기(shape)를 출력\n",
        "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)\n",
        "\n",
        "# 순방향 LSTM의 은닉 상태와 셀 상태를 forward_h, forward_c에 저장하고\n",
        "# 역방향 LSTM의 은닉 상태와 셀 상태를 backward_h, backward_c에 저장\n",
        "\n",
        "# 각 은닉 상태나 셀 상태의 경우에는 128차원을 가지는데, lstm의 경우에는 (500x128) 크기를 가짐\n",
        "# forward 방향과 backward 방향이 연결된 hidden state 벡터가 모든 시점에 대해서 존재함을 의미"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vd-Bcl_mmtj"
      },
      "source": [
        "# 양방향 LSTM을 사용할 경우에는 순방향 LSTM과 역방향 LSTM 각각 은닉 상태와 셀 상태를 가지므로\n",
        "# 양방향 LSTM의 은닉 상태와 셀 상태를 사용하려면 두 방향의 LSTM의 상태들을 concatenate해야 함\n",
        "\n",
        "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
        "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK1hPMMPqz33"
      },
      "source": [
        "# 어텐션 메커니즘에서는 은닉 상태 사용\n",
        "# 이를 입력으로 컨텍스트 벡터를 얻음\n",
        "\n",
        "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
        "context_vector, attention_weights = attention(lstm, state_h)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5lERylzq9Nk"
      },
      "source": [
        "# 컨텍스트 벡터를 밀집층(dense layer)에 통과시키고, \n",
        "# 이진 분류이므로 최종 출력층에 1개의 뉴런을 배치하고, 활성화 함수로 시그모이드 함수 사용\n",
        "\n",
        "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output = Dense(1, activation=\"sigmoid\")(dropout)\n",
        "model = Model(inputs=sequence_input, outputs=output)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0KLpJS8rU3M"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5WB5MUYsAl2",
        "outputId": "1d0afa5a-f913-4055-f10b-5a0823d69348"
      },
      "source": [
        "# 모델 훈련\n",
        "history = model.fit(X_train, y_train, epochs = 3, batch_size = 256, validation_data=(X_test, y_test), verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "98/98 [==============================] - 1442s 15s/step - loss: 0.4596 - accuracy: 0.7775 - val_loss: 0.3049 - val_accuracy: 0.8721\n",
            "Epoch 2/3\n",
            "98/98 [==============================] - 1462s 15s/step - loss: 0.2471 - accuracy: 0.9116 - val_loss: 0.2877 - val_accuracy: 0.8814\n",
            "Epoch 3/3\n",
            "98/98 [==============================] - 1437s 15s/step - loss: 0.1946 - accuracy: 0.9338 - val_loss: 0.3135 - val_accuracy: 0.8772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llYyhkLcsKXv",
        "outputId": "c7b0e327-da34-4ca7-f0f0-b08353e8cde8"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 307s 392ms/step - loss: 0.3135 - accuracy: 0.8772\n",
            "\n",
            " 테스트 정확도: 0.8772\n"
          ]
        }
      ]
    }
  ]
}