{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "What_is_NLP_Ch13_TaggingTask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI4ghtcwX-dL"
      },
      "source": [
        "## 13. Tagging Task\n",
        "* Tagging task: 자연어처리 분야에서 각 단어가 어떤 유형에 속해있는지를 알아냄\n",
        "* 크게 2가지\n",
        "1. 개체명 인식(Named Entity Recognition): 각 단어의 유형이 사람, 장소, 단체 등 어떤 유형인지를 알아냄\n",
        "2. 품사 태깅(Part of Speech Tagging): 각 단어의 품사가 명사, 동사, 형용사인지를 알아냄\n",
        "* Keras를 이용해서 인공 신경망을 이용한 개체명 인식기와 품사 태거를 만드는 미니 프로젝트 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wqq-0p54YYba"
      },
      "source": [
        "### 1) 케라스를 이용한 태깅 작업 개요(Tagging Task using Keras)\n",
        "* 이번 챕터에서는 케라스(Keras)로 인공 신경망을 이용하여 태깅 작업을 하는 모델을 만듦\n",
        "* 개체명 인식기와 품사 태거. 두 작업의 공통점은 **RNN의 다-대-다(Many-to-Many)** 작업이면서 또한 앞, 뒤 시점의 입력을 모두 참고하는 **양방향 RNN(Bidirectional RNN)**을 사용한다는 점"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhIFjIzJY08a"
      },
      "source": [
        "#### 1. 훈련 데이터에 대한 이해\n",
        "* 텍스트 분류 작업과 동일하게 지도 학습(Supervised learning)에 속함\n",
        "* 태깅을 해야 하는 단어 데이터 X, 레이블에 해당되는 태깅 정보 데이터는 y \n",
        "\n",
        "\n",
        "* X와 y 데이터의 쌍(pair)는 병렬 구조를 가진다는 특성. X와 y의 각 데이터의 길이는 같음\n",
        "* 각 데이터는 정수 인코딩 과정을 거친 후, 모든 데이터의 길이를 동일하게 맞춰주기 위한 패딩(Padding) 작업을 거침"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sT8djJ4Y1CP"
      },
      "source": [
        "#### 2. 시퀀스 레이블링(Sequence Labeling)\n",
        "* 입력 시퀀스에 대하여 레이블 시퀀스를 각각 부여하는 작업을 Sequence Labeling Task라고 함\n",
        "\n",
        "#### 3. 양방향 LSTM(Bidirectional LSTM)\n",
        "> model.add(Bidirectional(LSTM(hidden_size, return_sequences=True)))\n",
        "\n",
        "* 이전 시점의 단어 정보 뿐만 아니라 다음 시점의 단어 정보도 참고하기 위하여 bidirectional LSTM\n",
        "* 인자 정보: 인자값을 하나 줄 경우에는 이는 hidden_size, 결과적으로 output_dim이 됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m2MxlwUY1Fj"
      },
      "source": [
        "#### 4. RNN의 다-대-다(Many-to-Many) 문제\n",
        "* RNN의 은닉층은 모든 시점에 대해서 은닉 상태값을 출력할 수 있고, 마지막 시점에 대해서만 은닉 상태값을 출력할 수 있음\n",
        "  * 이는 인자로 **return_sequences=True**를 넣을 것인지, 넣지 않을 것인지로 설정\n",
        "  * 태깅 작업은 Many-to-Many로 True로 설정\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku53mbS1aJrN"
      },
      "source": [
        "## 2). 양방향 LSTM을 이용한 품사 태깅(Part-of-speech Tagging using Bi-LSTM)\n",
        "* 2챕터 토큰화 챕터에서는 NLTK와 KoNLPy를 이용해서 이미 기존에 있는 모델로 품사 태깅을 수행했지만, 여기에서는 직접 양방향 LSTM을 이용한 품사 태깅을 수행하는 모델\n",
        "### 1. 품사 태깅 데이터에 대한 이해와 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWBo3dx2bSZJ",
        "outputId": "b34679bb-a184-4b95-f833-796e662badd7"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPLz9yHAbY9z",
        "outputId": "28e5f585-ed34-4fea-ab91-fc052aaf9166"
      },
      "source": [
        "import nltk\n",
        "nltk.download('treebank')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6uuB4H1YpYi"
      },
      "source": [
        "# 양방향 LSTM을 이용해서 품사 태깅을 하는 모델\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzwBrcUCa_mS"
      },
      "source": [
        "* NLTK를 이용하면 영어 코퍼스에서 투큰화와 품사 태깅 전처리를 진행한 문장 데이터를 받아올 수 있음\n",
        "* 여기서는 해당 데이터를 훈련시켜 품사 태깅을 수행하는 모델을 만듦"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgpjIkYVXt9y",
        "outputId": "1dc4addb-7248-463f-da1d-f4f9abe6818e"
      },
      "source": [
        "# 전체 문장 샘플의 개수 확인\n",
        "tagged_sentences = nltk.corpus.treebank.tagged_sents() # 토큰화에 품사 태깅이 된 데이터 받아오기\n",
        "print(\"품사 태깅이 된 문장 개수: \", len(tagged_sentences)) # 문장 샘플의 개수 출력"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "품사 태깅이 된 문장 개수:  3914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzJKRGwYbMbT",
        "outputId": "036fc711-dd25-42d6-fd1d-dd8cdfe4b0f2"
      },
      "source": [
        "# 첫번째 샘플만 출력\n",
        "print(tagged_sentences[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwDdJp1Jbf0_"
      },
      "source": [
        "* 훈련을 시키려면 훈련 데이터에서 단어에 해당되는 부분과 품사 태깅 정보에 해당되는 부분은 분리시켜야 함. \n",
        "  * 즉, Pierre, Vinken 같이, NNP와 NNP 같이\n",
        "  * 이런 경우, **zip()** 함수가 유용한 역할. **zip() 함수는 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소끼리 묶어주는 역할**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5i4PVYdbdL1"
      },
      "source": [
        "sentences, pos_tags = [], []\n",
        "for tagged_sentence in tagged_sentences: #3914개의 문장 샘플을 1개씩 불러옴\n",
        "  sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 품사 태깅 정보들은 tag_info에 저장\n",
        "  sentences.append(list(sentence)) #각 샘플에서 단어 정보만 저장\n",
        "  pos_tags.append(list(tag_info)) #각 샘플에서 품사 태깅 정보만 저장\n",
        "\n",
        "  #sentences.append(list(sentence))에서 list 없으면 ()로 묶임"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC2HHnlVcaux",
        "outputId": "ed1d4ab8-e0a8-499b-fb05-027351e9d76e"
      },
      "source": [
        "print(sentences[0])\n",
        "print(pos_tags[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
            "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "czf3NZGlcced",
        "outputId": "74588415-7e50-41d2-c265-45ae0b1aa003"
      },
      "source": [
        "# 전체 데이터의 길이 분포\n",
        "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
        "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 271\n",
            "샘플의 평균 길이 : 25.722024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XdVk6vmcsxH"
      },
      "source": [
        "# 케라스 토크나이저를 다음과 같이 함수로 구현\n",
        "def tokenize(samples):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(samples)\n",
        "  return tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-acp-lvQc7XU"
      },
      "source": [
        "# 문장 데이터에 대해서는 src_tokenizer, 레이블에 해당되는 품사 태깅 정보에 대해서는 tar_tokenizer 사용\n",
        "src_tokenizer = tokenize(sentences)\n",
        "tar_tokenizer = tokenize(pos_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gkfsAJ-c-ji",
        "outputId": "c7935fcf-76b9-4508-eb78-4e8cba280d89"
      },
      "source": [
        "# 단어 집합과 품사 태깅 정보 집합의 크기 확인\n",
        "vocab_size = len(src_tokenizer.word_index) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
        "print('태깅 정보 집합의 크기 : {}'.format(tag_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 11388\n",
            "태깅 정보 집합의 크기 : 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG0pQOpsdRZX"
      },
      "source": [
        "# 정수 인코딩\n",
        "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_train = tar_tokenizer.texts_to_sequences(pos_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "contEKJ-deyW",
        "outputId": "1ad2d80b-4056-4b72-c415-a19fc393079d"
      },
      "source": [
        "print(X_train[:2])\n",
        "print(y_train[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5601, 3746, 1, 2024, 86, 331, 1, 46, 2405, 2, 131, 27, 6, 2025, 332, 459, 2026, 3], [31, 3746, 20, 177, 4, 5602, 2915, 1, 2, 2916, 637, 147, 3]]\n",
            "[[3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9], [3, 3, 17, 1, 2, 3, 3, 8, 4, 3, 19, 1, 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX4tPlzcjnMp"
      },
      "source": [
        "# 샘플의 모든 길이를 임의로 150으로 맞춤\n",
        "# 케라스의 pad_sequences()\n",
        "max_len = 150\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
        "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAUNSot4dr0R"
      },
      "source": [
        "# 모든 샘플의 길이가 150\n",
        "# 이제 훈련 데이터 비율로 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Iot9SQUdzb9"
      },
      "source": [
        "# 레이블에 해당되는 태깅 정보에 대해서 원-핫 인코딩 수행\n",
        "y_train = to_categorical(y_train, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs7yuyvjd7Xu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec389f7-bd88-4263-b53b-3cecb8fa292c"
      },
      "source": [
        "# 각 데이터에 대한 크기 확인\n",
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플 문장의 크기 : (3131, 150)\n",
            "훈련 샘플 레이블의 크기 : (3131, 150, 47)\n",
            "테스트 샘플 문장의 크기 : (783, 150)\n",
            "테스트 샘플 레이블의 크기 : (783, 150, 47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FggM8FtTerfZ"
      },
      "source": [
        "### 2. 양방향 LSTM(Bi-directional LSTM)으로 POS Tagger 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am5wqjXYeq_x"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a31VrxEie_cc"
      },
      "source": [
        "embedding_dim = 128\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyexIWq1f-O0"
      },
      "source": [
        "TimeDistributed는 many 출력을 가진 모델에 사용\n",
        "* 각 시간별로 출력되는 모든 출력값에 대해서 cost를 구해서 gradient를 구함\n",
        "\n",
        "* one 출력 모델은 최종 출력 하나에서 gradient를 계산해 앞으로 보내고,\n",
        "many의 경우는 중간 출력 결과에 대해서도 gradient 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9rzn54sfTxO",
        "outputId": "77248d45-2b5e-47de-bcf6-e15e0fcc0b80"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=6, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "25/25 [==============================] - 46s 2s/step - loss: 0.5942 - accuracy: 0.1348 - val_loss: 0.5160 - val_accuracy: 0.1870\n",
            "Epoch 2/6\n",
            "25/25 [==============================] - 36s 1s/step - loss: 0.5036 - accuracy: 0.1915 - val_loss: 0.4810 - val_accuracy: 0.2184\n",
            "Epoch 3/6\n",
            "25/25 [==============================] - 36s 1s/step - loss: 0.4524 - accuracy: 0.3604 - val_loss: 0.4014 - val_accuracy: 0.4558\n",
            "Epoch 4/6\n",
            "25/25 [==============================] - 37s 1s/step - loss: 0.3407 - accuracy: 0.5173 - val_loss: 0.2744 - val_accuracy: 0.6004\n",
            "Epoch 5/6\n",
            "25/25 [==============================] - 36s 1s/step - loss: 0.2207 - accuracy: 0.6991 - val_loss: 0.1719 - val_accuracy: 0.7793\n",
            "Epoch 6/6\n",
            "25/25 [==============================] - 36s 1s/step - loss: 0.1277 - accuracy: 0.8526 - val_loss: 0.1044 - val_accuracy: 0.8709\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa0b7e83450>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12hrlCvmgEOF",
        "outputId": "d88a284e-97f9-4c7c-e462-b17336164208"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 3s 106ms/step - loss: 0.1044 - accuracy: 0.8709\n",
            "\n",
            " 테스트 정확도: 0.8709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55tcyVYzhHl9"
      },
      "source": [
        "* 실제 맞추고 있는지를 특정 테스트 데이터를 주고 직접 출력해서 확인\n",
        "* 인덱스로부터 단어와 품사 태깅 정보를 리턴하는 index_to_word와 index_to_tag를 만들고 이를 이용하여 실제값과 예측값을 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jRqTFU8hSMV",
        "outputId": "ea2d3e92-dda2-4d99-f0d4-0cc21e1da687"
      },
      "source": [
        "index_to_word = src_tokenizer.index_word\n",
        "index_to_tag = tar_tokenizer.index_word\n",
        "\n",
        "i = 10 # 확인하고 싶은 테스트용 샘플 인덱스\n",
        "y_predicted = model.predict(np.array([X_test[i]])) #입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "y_predicted = np.argmax(y_predicted, axis=-1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함\n",
        "true = np.argmax(y_test[i], -1) # 원핫 인코딩을 다시 정수 인코딩으로 변경\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if w != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_tag[t].upper(), index_to_tag[pred].upper()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "in               : IN      IN\n",
            "addition         : NN      NN\n",
            ",                : ,       ,\n",
            "buick            : NNP     NNP\n",
            "is               : VBZ     VBZ\n",
            "a                : DT      DT\n",
            "relatively       : RB      JJ\n",
            "respected        : VBN     VBN\n",
            "nameplate        : NN      NN\n",
            "among            : IN      IN\n",
            "american         : NNP     NNP\n",
            "express          : NNP     NNP\n",
            "card             : NN      NN\n",
            "holders          : NNS     NNS\n",
            ",                : ,       ,\n",
            "says             : VBZ     VBZ\n",
            "0                : -NONE-  -NONE-\n",
            "*t*-1            : -NONE-  -NONE-\n",
            "an               : DT      DT\n",
            "american         : NNP     NNP\n",
            "express          : NNP     NNP\n",
            "spokeswoman      : NN      NN\n",
            ".                : .       .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7t1aOnorRWY"
      },
      "source": [
        "### 3. 양방향 LSTM + CRF(Bidirectional LSTM + CRF)로 POS Tagger 만들기\n",
        "* 양방향 LSTM에 추가적으로 사용하면 성능을 높일 수 있다고 알려진 CRF layer를 추가하여 실습 진행\n",
        "* tf2crf라는 패키지 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO0M10N5hrYz",
        "outputId": "4d416aeb-db47-49b5-9034-c6f31a62ee2d"
      },
      "source": [
        "!pip install tf2crf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf2crf\n",
            "  Downloading tf2crf-0.1.33-py2.py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tf2crf) (2.6.0)\n",
            "Collecting tensorflow-addons>=0.8.2\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.41.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.6.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.12.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.37.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.6.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (5.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.1.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.4.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.2.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.17.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.19.5)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.12.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.1.0->tf2crf) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (1.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (3.1.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons>=0.8.2->tf2crf) (2.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->tf2crf) (3.6.0)\n",
            "Installing collected packages: tensorflow-addons, tf2crf\n",
            "Successfully installed tensorflow-addons-0.14.0 tf2crf-0.1.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMgnpur2reJA"
      },
      "source": [
        "# 이전 모델에 CRF layer를 추가한 새로운 모델 만들기\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense, Input\n",
        "from tf2crf import CRF, ModelWithCRFLoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qGBL7YAr2pR",
        "outputId": "1cc6574f-10e6-4875-f10b-6129e3c72c90"
      },
      "source": [
        "inputs = Input(shape=(None, ), dtype='int32')\n",
        "output = Embedding(vocab_size, 128, mask_zero=True)(inputs)\n",
        "output = Bidirectional(LSTM(128, return_sequences=True))(output)\n",
        "crf = CRF(tag_size) ##\n",
        "output = crf(output) ##\n",
        "base_model = Model(inputs, output)\n",
        "\n",
        "model = ModelWithCRFLoss(base_model, sparse_target = False) ##\n",
        "model.build(input_shape=(None, 22))\n",
        "model.compile(optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:376: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\n",
            "  return py_builtins.overload_of(f)(*args)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLtV_OZbsQ2O",
        "outputId": "5ed8d281-0797-486f-e7a2-c8e1728a1cf0"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 32, epochs = 5, validation_split = 0.2, verbose = 1)\n",
        "\n",
        "'''\n",
        "함수 인자로 verbose가 있으면 함수 수행시 발생하는 상세한 정보들을 표준 출력으로 자세히 내보낼 것인가를 나타냅니다. \n",
        "보통 0 은 출력하지 않고, 1은 자세히, 2는 함축적인 정보만 출력하는 형태\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:376: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\n",
            "  return py_builtins.overload_of(f)(*args)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 71s 763ms/step - loss: 76.7682 - accuracy: 0.2125 - val_loss_val: 57.4945 - val_val_accuracy: 0.4231\n",
            "Epoch 2/5\n",
            "79/79 [==============================] - 57s 726ms/step - loss: 37.5177 - accuracy: 0.6161 - val_loss_val: 21.0109 - val_val_accuracy: 0.8043\n",
            "Epoch 3/5\n",
            "79/79 [==============================] - 57s 728ms/step - loss: 12.3420 - accuracy: 0.8963 - val_loss_val: 9.6588 - val_val_accuracy: 0.9020\n",
            "Epoch 4/5\n",
            "79/79 [==============================] - 58s 730ms/step - loss: 5.1287 - accuracy: 0.9570 - val_loss_val: 7.1016 - val_val_accuracy: 0.9222\n",
            "Epoch 5/5\n",
            "79/79 [==============================] - 57s 726ms/step - loss: 2.9149 - accuracy: 0.9740 - val_loss_val: 6.3677 - val_val_accuracy: 0.9240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bd-l67CsX4I"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmfs8EnUsqX7"
      },
      "source": [
        "## 3) 개체명 인식 Named Entity Recognition\n",
        "* 코퍼스로부터 각 개체 entity의 유형을 인식하는 개체명 인식\n",
        "* 개체명 인식을 사용하면 코퍼스로부터 어떤 단어가 사람, 장소, 조직 등을 의미하는 단어인지 찾을 수 있음\n",
        "\n",
        "### 1. 개체명 인식 Named Entity Recognition이란?\n",
        "* 개체명 인식이란, 말 그대로 이름을 가진 개체 named entity를 인식하겠다는 것을 의미\n",
        "* 좀 더 쉽게 설명하면, 어떤 이름을 의미하는 단어를 보고는 그 단어가 어떤 유형인지 인식하는 것\n",
        "* ex) 유정이는 2018년에 골드만삭스에 입사했다. \n",
        "  > person, organization, time에 대해서 개체명 인식을 수행하는 모델이라면 다음과 같은 결과를 보여줌. 유정 - 사람, 2018년 - 시간, 골드만삭스 - 조직\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgsW8x30tRuS"
      },
      "source": [
        "* 개체명 인식 모델이 개체명을 인식하기 위해서는 보통 **전처리 과정**이 필요. 개체명 모델에 따라서는 품사 정보(POS Tagging, Part-Of-Speech Tagging)를 입력으로 요구하기도 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vMOe_QTtdAg"
      },
      "source": [
        "## 2. NLTK를 이용한 개체명 인식(Named Entity Recognition using NLTK)\n",
        "* NLTK에서는 개체명 인식기 (NER Chunker)를 지원하고 있으므로, 별도 개체명 인식기를 구현할 필요 없이 NLTK를 사용해서 개체명 인식을 수행 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgMpZezVtQ27",
        "outputId": "5f4b4f65-9b5d-4678-a847-11973308796b"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5bZ-Ilhtpw3",
        "outputId": "78dc163b-f967-473e-e62d-ff2af15d0d8f"
      },
      "source": [
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "sentence = \"James is working at Disney in London\"\n",
        "sentence = pos_tag(word_tokenize(sentence))\n",
        "print(sentence) #토큰화와 품사 태깅을 동시 수행"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('James', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('at', 'IN'), ('Disney', 'NNP'), ('in', 'IN'), ('London', 'NNP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3dBSXXrt2O1",
        "outputId": "0720e101-9749-4ec6-ec7c-2a07aeb8b3c2"
      },
      "source": [
        "# 개체명 인식\n",
        "sentence = ne_chunk(sentence)\n",
        "print(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON James/NNP)\n",
            "  is/VBZ\n",
            "  working/VBG\n",
            "  at/IN\n",
            "  (ORGANIZATION Disney/NNP)\n",
            "  in/IN\n",
            "  (GPE London/NNP))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p7KKc_9uLyJ"
      },
      "source": [
        "* **ne_chunk는 개체명을 태깅하기 위해서 앞서 품사 태깅(pos_tag)이 수행되어야 함**\n",
        "* James는 PERSON, Disney는 ORGANIZATION, London은 위치GPE라고 정상적으로 개체명 인식이 수행된 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0zM4RoPuemv"
      },
      "source": [
        "## 4) 개체명 인식의 BIO 표현 이해하기\n",
        "* 개체명 인식은 챗봇 등에서 필요로 하는 주요 전처리 작업이지만, 그 자체로도 까다로운 작업\n",
        "* 도메인 또는 목적에 특화되도록 개체명 인식을 정확하게 하는 방법 중 하나는 기존에 공개된 개체명 인식기를 사용하는 것이 아니라, ** 직접 목적에 맞는 데이터를 준비하여 기계를 훈련시켜 모델을 만드는 방법**\n",
        "* 여기서는 **양방향 LSTM을 이용해서 개체명 인식기를 만들어 봄**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x0tS7oYux4r"
      },
      "source": [
        "### 1. BIO 표현\n",
        "* 개체명 인식에서 코퍼스로부터 개체명을 인식하기 위한 방법으로는 여러 방법이 있지만, 가장 보편적인 방법은 IOB(또는 BIO) 방법\n",
        "* B: 개체명이 begin, I: 개체명의 inside(내부 부분), O: 개체명이 outside(아닌 부분)\n",
        "\n",
        "```\n",
        "# 해리포터, 메가박스\n",
        "\n",
        "해 B-movie\n",
        "리 I-movie\n",
        "포 I-movie\n",
        "터 I-movie\n",
        "보 O\n",
        "러 O\n",
        "메 B-theater\n",
        "가 I-theater\n",
        "박 I-theater\n",
        "스 I-theater\n",
        "가 O\n",
        "자 O\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J52O7x2NuyXS"
      },
      "source": [
        "### 2. 개체명 인식 데이터 이해하기\n",
        "* 실습을 통한 양방향 LSTM을 이용한 개체명 인식에 대해서 더 자세히 알아보기\n",
        "* CONLL2003은 개체명 인식을 위한 전통적인 영어 데이터셋. 해당 데이터를 가지고 훈련하여 개체명 인식 모델 만들기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WuP-SG5v3ig",
        "outputId": "7e67efd9-ecbf-4b20-e9b5-84ea9b80ef06"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/NeuroNER.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NeuroNER'...\n",
            "remote: Enumerating objects: 675, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 675 (delta 0), reused 0 (delta 0), pack-reused 672\u001b[K\n",
            "Receiving objects: 100% (675/675), 123.78 MiB | 33.13 MiB/s, done.\n",
            "Resolving deltas: 100% (394/394), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZghnZKwDv3sK",
        "outputId": "af689883-bb4a-41e6-bb0d-c7dbdb931b4f"
      },
      "source": [
        "!ls -ltr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Nov  1 13:35 sample_data\n",
            "drwxr-xr-x 5 root root 4096 Nov  9 03:34 NeuroNER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NClo2uGzU-3"
      },
      "source": [
        "import re\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NZVFcI3ytWn"
      },
      "source": [
        "# 위에서 설명한 개체명 인식 데이터를 읽어 전처리 수행\n",
        "files = 'NeuroNER/neuroner/data/conll2003/en/train.txt'\n",
        "\n",
        "f = open(files, 'r')\n",
        "tagged_sentences = []\n",
        "sentence = []\n",
        "\n",
        "for line in f:\n",
        "  if len(line) == 0 or line.startswith('-DOCSTART') or line[0]=='\\n':\n",
        "    if len(sentence) > 0:\n",
        "      tagged_sentences.append(sentence)\n",
        "      sentence = []\n",
        "    continue\n",
        "  splits = line.split(' ') #공백 기준으로 속성 구분\n",
        "  splits[-1] = re.sub(r'\\n', '', splits[-1]) #줄바꿈 표시 \\n을 제거\n",
        "  word = splits[0].lower() # 단어들은 소문자로 바꿔서 저장\n",
        "  sentence.append([word, splits[-1]]) #단어와 개체명 태깅만 기록"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m6xQzowuJUX",
        "outputId": "84b1dec3-995a-47b9-bc1c-5526515eab07"
      },
      "source": [
        "print(\"전체 샘플 개수: \", len(tagged_sentences)) # 전체 샘플의 개수 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 개수:  14041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71gEQaFyze11",
        "outputId": "58799cd9-dbff-40dd-d756-0392c34819f4"
      },
      "source": [
        "print(tagged_sentences[0]) # 첫번째 샘플 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['eu', 'B-ORG'], ['rejects', 'O'], ['german', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['british', 'B-MISC'], ['lamb', 'O'], ['.', 'O']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmW7a9zqzjHE"
      },
      "source": [
        "* 그런데 훈련을 시키려면 훈련 데이터에서 단어에 해당되는 부분과 개체명 태깅 정보에 해당되는 부분을 분리시켜야 함\n",
        "* ex) eu와 rejects는 같이, B-ORG와 O를 같이 저장\n",
        "  * zip() 함수 활용. 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSA5irPXzfdj"
      },
      "source": [
        "sentences, ner_tags = [], []\n",
        "for tagged_sentence in tagged_sentences: #14,041개의 문장 샘플을 1개씩 불러옴\n",
        "  sentence, tag_info = zip(*tagged_sentence) #각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장\n",
        "  sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장\n",
        "  ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장\n",
        "\n",
        "# 각 문장 샘플에 대해서 단어는 sentences에 태깅 정보는 ner_tags에 저장\n",
        "# 임의로 첫번재 문장 샘플 출력"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de-ceAKLzfgW",
        "outputId": "c9ba3d4b-f21f-4f01-f6a9-0022f1e1795e"
      },
      "source": [
        "print(sentences[0])\n",
        "print(ner_tags[0])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
            "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCsAKWIwzfjl",
        "outputId": "7e5278aa-872a-480f-9b20-ac3c3d0e9ffc"
      },
      "source": [
        "# sentences는 예측을 위한 X, ner_tags는 예측 대상인 y\n",
        "print(sentences[12])\n",
        "print(ner_tags[12])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dr.', 'Talcott', 'led', 'a', 'team', 'of', 'researchers', 'from', 'the', 'National', 'Cancer', 'Institute', 'and', 'the', 'medical', 'schools', 'of', 'Harvard', 'University', 'and', 'Boston', 'University', '.']\n",
            "['NNP', 'NNP', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'CC', 'DT', 'JJ', 'NNS', 'IN', 'NNP', 'NNP', 'CC', 'NNP', 'NNP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "OkKmAryh0VCb",
        "outputId": "5a558073-cd9a-44be-e068-6aece85013e1"
      },
      "source": [
        "# 전체 데이터의 길이 분포\n",
        "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
        "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 271\n",
            "샘플의 평균 길이 : 25.722024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l92V74Y0oUE"
      },
      "source": [
        "# 케라스 토크나이저를 통해서 토큰화와 정수 인코딩 진행\n",
        "# 문장 데이터에 있는 모든 단어를 사용하지 않고 높은 빈도수를 가진 상위 약 4000개의 단어만을 사용\n",
        "\n",
        "# 토큰화\n",
        "max_words = 4000\n",
        "src_tokenizer = Tokenizer(num_words=max_words, oov_token='OOV') #문장 데이터\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "tar_tokenizer = Tokenizer() #레이블에 해당되는 개체명 태깅 정보\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43R5U06V09Qi",
        "outputId": "2ce6c7fc-b776-4199-e567-dbbc63ac1bf2"
      },
      "source": [
        "vocab_size = max_words\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
        "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 4000\n",
            "개체명 태깅 정보 집합의 크기 : 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i04PHuL51HvQ"
      },
      "source": [
        "# 정수 인코딩\n",
        "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_train = tar_tokenizer.texts_to_sequences(ner_tags)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hWmcMeY1USH",
        "outputId": "3f66af0f-0499-48b3-e108-d950ac9e2dbc"
      },
      "source": [
        "print(X_train[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3747, 2, 2025, 87, 332, 2, 47, 2406, 3, 132, 28, 7, 2026, 333, 460, 2027, 4]\n",
            "[3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYUIA25Z1Vin"
      },
      "source": [
        "# 문장 데이터에 대해서는 일부 단어가 'OOV'로 대체된 상황\n",
        "# 확인 위해 다시 디코딩(정수->텍스트 데이터) 작업을 함\n",
        "# 이를 위해 인덱스로부터 단어를 리턴하는 index_to_word를 만듦\n",
        "\n",
        "index_to_word = src_tokenizer.index_word\n",
        "index_to_ner = tar_tokenizer.index_word"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAsOdxdg1kWZ",
        "outputId": "e39348b6-40fe-4054-9233-e153ff240d93"
      },
      "source": [
        "# 정수 인코딩 된 첫번째 문장 다시 디코딩\n",
        "decoded = []\n",
        "for index in X_train[0]: #첫번째 샘플 안의 인덱스들에 대해서\n",
        "  decoded.append(index_to_word[index]) #다시 단어로 변환\n",
        "\n",
        "print('기존 문장 : {}'.format(sentences[0]))\n",
        "print('빈도수가 낮은 단어가 OOV 처리된 문장 : {}'.format(decoded))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기존 문장 : ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
            "빈도수가 낮은 단어가 OOV 처리된 문장 : ['OOV', 'vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', '29', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R45n7zYI1s8Y"
      },
      "source": [
        "# 샘플들의 모든 길이를 임의 70으로 맞추기\n",
        "# 케라스의 pad_sequences()\n",
        "\n",
        "max_len = 70\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
        "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEmISAxd19Uz"
      },
      "source": [
        "# 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2, random_state=777)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aizyh8iy2EaA"
      },
      "source": [
        "# 레이블에 해당하는 태깅 정보에 대해서 원-핫 인코딩 수행\n",
        "y_train = to_categorical(y_train, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKPFgwQ92O-2",
        "outputId": "31a63417-4993-4b6e-e1cb-09ad6e16032f"
      },
      "source": [
        "# 각 데이터에 대한 크기\n",
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플 문장의 크기 : (3131, 70)\n",
            "훈련 샘플 레이블의 크기 : (3131, 70, 47)\n",
            "테스트 샘플 문장의 크기 : (783, 70)\n",
            "테스트 샘플 레이블의 크기 : (783, 70, 47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PGyqyf92UsS"
      },
      "source": [
        "#### 4. 양방향 LSTM(Bi-directional LSTM)으로 개체명 인식기 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYsomp2n2R6W"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pD2rIaU2sEt"
      },
      "source": [
        "# 모델\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
        "\n",
        "# 패딩을 하느라 숫자 0이 많아질 경우, Embedding()에 mask_zero=Trueㄹ르 설정하여\n",
        "# 데이터에서 숫자 0은 패딩을 의미하므로 연산에서 제외시킨다는 옵션 줌"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBpXmzoE2sPX"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr73i_q13Pjt",
        "outputId": "d9083944-1b3e-4483-8fda-82ba76ec56f9"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=8, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "88/88 [==============================] - 134s 1s/step - loss: 0.1833 - accuracy: 0.8266 - val_loss: 0.1214 - val_accuracy: 0.8334\n",
            "Epoch 2/8\n",
            "88/88 [==============================] - 124s 1s/step - loss: 0.0968 - accuracy: 0.8598 - val_loss: 0.0760 - val_accuracy: 0.8848\n",
            "Epoch 3/8\n",
            "88/88 [==============================] - 123s 1s/step - loss: 0.0658 - accuracy: 0.9054 - val_loss: 0.0541 - val_accuracy: 0.9231\n",
            "Epoch 4/8\n",
            "88/88 [==============================] - 121s 1s/step - loss: 0.0470 - accuracy: 0.9335 - val_loss: 0.0419 - val_accuracy: 0.9418\n",
            "Epoch 5/8\n",
            "88/88 [==============================] - 115s 1s/step - loss: 0.0360 - accuracy: 0.9492 - val_loss: 0.0363 - val_accuracy: 0.9496\n",
            "Epoch 6/8\n",
            "88/88 [==============================] - 112s 1s/step - loss: 0.0297 - accuracy: 0.9577 - val_loss: 0.0339 - val_accuracy: 0.9539\n",
            "Epoch 7/8\n",
            "88/88 [==============================] - 113s 1s/step - loss: 0.0253 - accuracy: 0.9637 - val_loss: 0.0332 - val_accuracy: 0.9543\n",
            "Epoch 8/8\n",
            "88/88 [==============================] - 113s 1s/step - loss: 0.0223 - accuracy: 0.9677 - val_loss: 0.0325 - val_accuracy: 0.9564\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa0b8d73e10>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT0vf3CO3XBM",
        "outputId": "77c4dc20-1008-4161-9219-0306483a34f3"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 13s 148ms/step - loss: 0.0325 - accuracy: 0.9564\n",
            "\n",
            " 테스트 정확도: 0.9564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-B9O_QD3_PR",
        "outputId": "1b90a5de-446b-498e-dc36-62e2b50e745e"
      },
      "source": [
        "# 실제로 맞추고 있는지를 테스트 데이터를 주고 직접 실제값과 비교\n",
        "# 앞서 만들어 둔 인덱스로부터 단어와 개체명 태깅 정보를 리턴하는 index_to_word와 index_to_ner을 사용하여\n",
        "# 테스트 데이터에 대한 예측값과 실제값을 비교 출력\n",
        "\n",
        "i=10 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "y_predicted = np.argmax(y_predicted, axis=-1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
        "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if w != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t].upper(), index_to_ner[pred].upper()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "sarah            : B-PER   B-PER\n",
            "brady            : I-PER   I-PER\n",
            ",                : O       O\n",
            "whose            : O       O\n",
            "republican       : B-MISC  B-MISC\n",
            "husband          : O       O\n",
            "was              : O       O\n",
            "OOV              : O       B-PER\n",
            "OOV              : O       O\n",
            "in               : O       O\n",
            "an               : O       O\n",
            "OOV              : O       O\n",
            "attempt          : O       O\n",
            "on               : O       O\n",
            "president        : O       O\n",
            "ronald           : B-PER   B-PER\n",
            "reagan           : I-PER   I-PER\n",
            ",                : O       O\n",
            "took             : O       O\n",
            "centre           : O       O\n",
            "stage            : O       O\n",
            "at               : O       O\n",
            "the              : O       O\n",
            "democratic       : B-MISC  B-MISC\n",
            "national         : I-MISC  I-MISC\n",
            "convention       : I-MISC  I-MISC\n",
            "on               : O       O\n",
            "monday           : O       O\n",
            "night            : O       O\n",
            "to               : O       O\n",
            "OOV              : O       O\n",
            "president        : O       O\n",
            "bill             : B-PER   B-PER\n",
            "clinton          : I-PER   I-PER\n",
            "'s               : O       O\n",
            "gun              : O       O\n",
            "control          : O       O\n",
            "efforts          : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHlT6eJbTl4v"
      },
      "source": [
        "## 5) BiLSTM을 이용한 개체명 인식 (Named Entity Recognition, NER)\n",
        "* 개체명 인식 데이터에 대한 전처리 진행, 양방향 LSTM을 이용하여 개체명 인식기 만들고 F1-Score를 사용하여 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4Alz4lwUXA4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II_cJcBFWq7c"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6i0JDn64C17"
      },
      "source": [
        "import io\n",
        "\n",
        "#data = pd.read_csv(io.BytesIO(uploaded['ner_dataset.csv'].encode('latin1')))\n",
        "#data[:5]\n",
        "\n",
        "data = pd.read_csv('/content/ner_dataset.csv', encoding='latin1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "e8gPuE-XUZsh",
        "outputId": "8084c2e4-f40a-4c52-d296-c3dc304c5478"
      },
      "source": [
        "data[:5]\n",
        "\n",
        "'''\n",
        "Sentence: 1이 있고, Null값이 이어지다가 다시 Sentence: 2가 나오고 Null값이 이어지다가...\n",
        "이는 하나의 문장을 여러 행으로 나눠놓은 것\n",
        "숫자값을 t라고 함\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ma6NUA5XNEU",
        "outputId": "392b13bc-7a32-479e-f422-68e093ef15dc"
      },
      "source": [
        "print('데이터프레임 행의 개수 : {}'.format(len(data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터프레임 행의 개수 : 226685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bnoYTilXihf",
        "outputId": "e017d861-f22a-47af-f612-dc85c4eddb53"
      },
      "source": [
        "print('데이터에 Null값이 있는지 유무 : ' + str(data.isnull().values.any()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터에 Null값이 있는지 유무 : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2M9w-7DXpfd",
        "outputId": "974fa51b-e6a2-48c4-a243-483ae5ce8c28"
      },
      "source": [
        "print('어떤 열에 Null값이 있는지 출력')\n",
        "print('==============================')\n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어떤 열에 Null값이 있는지 출력\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    216308\n",
              "Word               0\n",
              "POS                0\n",
              "Tag                1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ncmSRQwXsqe",
        "outputId": "1be1d3a8-2947-4b99-b071-4b85342ab056"
      },
      "source": [
        "print('sentence # 열의 중복을 제거한 값의 개수 : {}'.format(data['Sentence #'].nunique()))\n",
        "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))\n",
        "print('Tag 열의 중복을 제거한 값의 개수 : {}'.format(data.Tag.nunique()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence # 열의 중복을 제거한 값의 개수 : 10377\n",
            "Word 열의 중복을 제거한 값의 개수 : 16647\n",
            "Tag 열의 중복을 제거한 값의 개수 : 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgq2bsfAX6dv",
        "outputId": "82e94993-e844-4eed-988e-2b895e3d8625"
      },
      "source": [
        "# 개체명 태깅이 전체 데이터에서 몇 개가 있는지, 개체명 태깅 개수의 분포를 확인\n",
        "\n",
        "print('Tag 열의 각각의 값의 개수 카운트')\n",
        "print('================================')\n",
        "print(data.groupby('Tag').size().reset_index(name='count'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag 열의 각각의 값의 개수 카운트\n",
            "================================\n",
            "      Tag   count\n",
            "0   B-art     120\n",
            "1   B-eve      90\n",
            "2   B-geo    7934\n",
            "3   B-gpe    3731\n",
            "4   B-nat      56\n",
            "5   B-org    4215\n",
            "6   B-per    3710\n",
            "7   B-tim    4265\n",
            "8   I-art      68\n",
            "9   I-eve      72\n",
            "10  I-geo    1625\n",
            "11  I-gpe      72\n",
            "12  I-nat      26\n",
            "13  I-org    3407\n",
            "14  I-per    3880\n",
            "15  I-tim    1295\n",
            "16      O  192118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PjHNuAeYC5s"
      },
      "source": [
        "data = data.fillna(method=\"ffill\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0GxJUIOYFs1",
        "outputId": "a91469af-8127-467a-e9e9-77d5dd94e6c3"
      },
      "source": [
        "print(data.tail())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Sentence #     Word  POS    Tag\n",
            "226680  Sentence: 10377      and   CC      O\n",
            "226681  Sentence: 10377      The   DT  B-org\n",
            "226682  Sentence: 10377  Raiders  NNS  I-org\n",
            "226683  Sentence: 10377      and   CC      O\n",
            "226684  Sentence: 10377   singer   NN      O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-3mH9HyYH4L",
        "outputId": "90f661dd-5a38-43bc-8200-eeea85d1035d"
      },
      "source": [
        "# 전체 데이터에 Null 값이 존재하는지 확인\n",
        "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터에 Null 값이 있는지 유무 : False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR0Lzd7UYpyB",
        "outputId": "39c6b417-f53d-4d01-ccf2-54b255b1e4db"
      },
      "source": [
        "# 모든 단어를 소문자화\n",
        "data['Word'] = data['Word'].str.lower()\n",
        "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 열의 중복을 제거한 값의 개수 : 15340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHaQFoayYzN2",
        "outputId": "ec5c7a59-63de-48bd-f78e-0b7b3b6e6dc0"
      },
      "source": [
        "print(data[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Sentence #           Word  POS Tag\n",
            "0  Sentence: 1      thousands  NNS   O\n",
            "1  Sentence: 1             of   IN   O\n",
            "2  Sentence: 1  demonstrators  NNS   O\n",
            "3  Sentence: 1           have  VBP   O\n",
            "4  Sentence: 1        marched  VBN   O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcbKVTymY17S",
        "outputId": "066f42b7-af85-4984-ff96-b730c7a76301"
      },
      "source": [
        "# 하나의 문장에 등장한 단어와 개체명 태깅 정보끼리 쌍(pair)으로 묶는 작업\n",
        "func = lambda temp: [(w, t) for w, t in zip(temp['Word'].values.tolist(), temp[\"Tag\"].values.tolist())]\n",
        "tagged_sentences = [t for t in data.groupby('Sentence #').apply(func)]\n",
        "print('전체 샘플 개수: {}'.format(len(tagged_sentences)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 개수: 10377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr9rB-9HaQZR",
        "outputId": "78242c75-876c-4bd3-92c5-ba7904eab452"
      },
      "source": [
        "print(tagged_sentences[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8HgN2rFaZVV"
      },
      "source": [
        "sentences, ner_tags = [], [] \n",
        "for tagged_sentence in tagged_sentences:\n",
        "  sentence, tag_info = zip(*tagged_sentence)\n",
        "  sentences.append(list(sentence))\n",
        "  ner_tags.append(list(tag_info))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PDjM4rpauYH",
        "outputId": "42b7c544-efce-4cfd-8c47-c55a57fb9695"
      },
      "source": [
        "print(sentences[0])\n",
        "print(ner_tags[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KG1_cNTawCK",
        "outputId": "f48cbe98-93e4-4766-fd87-0989d832361d"
      },
      "source": [
        "print(sentences[98])\n",
        "print(ner_tags[98])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['she', 'had', 'once', 'received', 'a', 'kidney', 'transplant', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "GSAG0iMZa0ay",
        "outputId": "a0751358-493b-4ee1-fb9f-ba04e4b4a9b9"
      },
      "source": [
        "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
        "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 271\n",
            "샘플의 평균 길이 : 25.722024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXK6t23ma4QR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "2f6b4613-e3fc-4700-ebdc-d25bcffbd3f7"
      },
      "source": [
        "# 케라스 토크나이저 통해서 정수 인코딩\n",
        "src_tokenizer = Tokenizer(oov_token='OOV')\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "tar_tokenizer = Tokenizer(lower=False)\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-32b2a9ec221f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtar_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtar_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ner_tags' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT1AwTHMbNq0",
        "outputId": "d5930091-1ce1-4397-a3c9-5e1ad80be42a"
      },
      "source": [
        "vocab_size = len(src_tokenizer.word_index) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
        "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 11389\n",
            "개체명 태깅 정보 집합의 크기 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCCgEVPtbXoP",
        "outputId": "3d370caf-241d-4a85-80e6-d41db55c88c0"
      },
      "source": [
        "print('단어 OOV의 인덱스 : {}'.format(src_tokenizer.word_index['OOV']))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 OOV의 인덱스 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDGV50HFbZl9"
      },
      "source": [
        "# 정수 인코딩\n",
        "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_data = tar_tokenizer.texts_to_sequences(ner_tags)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aTV9x4ybeB_"
      },
      "source": [
        "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_data = tar_tokenizer.texts_to_sequences(ner_tags)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amW_irupbhYu"
      },
      "source": [
        "# 모델 훈련 후 결과 확인을 위해 인덱스로부터 단어를 리턴하는 index_to_word\n",
        "# 뒤에서 사용할 index_to_ner\n",
        "word_to_index = src_tokenizer.word_index\n",
        "index_to_word = src_tokenizer.index_word\n",
        "ner_to_index = tar_tokenizer.word_index\n",
        "index_to_ner = tar_tokenizer.index_word\n",
        "index_to_ner[0] = 'PAD'"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1FXw6o8b5gz",
        "outputId": "cee50e1d-7b4e-4fc0-a720-879681e2600b"
      },
      "source": [
        "print(index_to_ner)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'O', 2: 'B-geo', 3: 'B-tim', 4: 'B-org', 5: 'I-per', 6: 'B-gpe', 7: 'B-per', 8: 'I-org', 9: 'I-geo', 10: 'I-tim', 11: 'B-art', 12: 'B-eve', 13: 'I-gpe', 14: 'I-eve', 15: 'I-art', 16: 'B-nat', 17: 'I-nat', 0: 'PAD'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54MXy3P_cIg8",
        "outputId": "192a0e25-fef9-4511-d026-549fe7ec2bb4"
      },
      "source": [
        "# 첫번째 샘플에 대해서 다시 디코딩\n",
        "# 정수에서 다시 텍스트 데이터로 변환\n",
        "decoded = []\n",
        "for index in X_data[0]:\n",
        "  decoded.append(index_to_word[index])\n",
        "\n",
        "print('기존의 문장 : {}'.format(sentences[0]))\n",
        "print('디코딩 문장 : {}'.format(decoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기존의 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "디코딩 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmNuwSWWcabb"
      },
      "source": [
        "max_len = 70\n",
        "X_data = pad_sequences(X_data, padding='post', maxlen=max_len)\n",
        "y_data = pad_sequences(y_data, padding='post', maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHzdsUPWcpYY"
      },
      "source": [
        "X_train, X_test, y_train_int, y_test_int = train_test_split(X_data, y_data, test_size=.2, random_state=777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5WgfdVLcwnj"
      },
      "source": [
        "# 레이블에 해당하는 태깅 정보에 대해서 원-핫 인코딩 수행\n",
        "y_train = to_categorical(y_train_int, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test_int, num_classes=tag_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts3CSfF9c1dx",
        "outputId": "472d12db-dd6b-4ad8-ff9e-d45ff4b0ac3e"
      },
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_train_int.shape))\n",
        "print('훈련 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_test_int.shape))\n",
        "print('테스트 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플 문장의 크기 : (8301, 70)\n",
            "훈련 샘플 레이블(정수 인코딩)의 크기 : (8301, 70)\n",
            "훈련 샘플 레이블(원-핫 인코딩)의 크기 : (8301, 70, 18)\n",
            "테스트 샘플 문장의 크기 : (2076, 70)\n",
            "테스트 샘플 레이블(정수 인코딩)의 크기 : (2076, 70)\n",
            "테스트 샘플 레이블(원-핫 인코딩)의 크기 : (2076, 70, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTyFGLZIc6zV"
      },
      "source": [
        "### 2. 양방향 LSTM을 이용한 개체명 인식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pit4YmJc4YL"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3C8HzTrdHuA"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 128, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(Dense(tag_size, activation=('softmax')))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVvUr1r8dhE5",
        "outputId": "d132aeb2-54fb-42d8-a6eb-e08c99092c75"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 128, epochs=6, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "59/59 [==============================] - 93s 1s/step - loss: 0.3444 - accuracy: 0.8336 - val_loss: 0.2274 - val_accuracy: 0.8472\n",
            "Epoch 2/6\n",
            "59/59 [==============================] - 82s 1s/step - loss: 0.1881 - accuracy: 0.8494 - val_loss: 0.1478 - val_accuracy: 0.8653\n",
            "Epoch 3/6\n",
            "59/59 [==============================] - 82s 1s/step - loss: 0.1229 - accuracy: 0.8808 - val_loss: 0.1159 - val_accuracy: 0.8918\n",
            "Epoch 4/6\n",
            "59/59 [==============================] - 83s 1s/step - loss: 0.0935 - accuracy: 0.9144 - val_loss: 0.0930 - val_accuracy: 0.9236\n",
            "Epoch 5/6\n",
            "59/59 [==============================] - 83s 1s/step - loss: 0.0684 - accuracy: 0.9425 - val_loss: 0.0753 - val_accuracy: 0.9342\n",
            "Epoch 6/6\n",
            "59/59 [==============================] - 84s 1s/step - loss: 0.0516 - accuracy: 0.9543 - val_loss: 0.0677 - val_accuracy: 0.9405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWZSY-nEd0io",
        "outputId": "506cbbbd-15f5-4406-8c2b-57c1fafbb391"
      },
      "source": [
        "# 확인하고 싶은 테스트용 샘플의 인덱스\n",
        "i = 13\n",
        "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "y_predicted = np.argmax(y_predicted, axis=-1) # 원핫 인코딩을 다시 정수인코딩으로 변경함\n",
        "true = np.argmax(y_test[i], -1) # 원핫 인코딩을 다시 정수 인코딩으로 변경\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "  if w != 0: #PAD값은 제외\n",
        "    print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t], index_to_ner[pred]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "\"                : O       O\n",
            "if               : O       O\n",
            "these            : O       O\n",
            "are              : O       O\n",
            "not              : O       O\n",
            "good             : O       O\n",
            "qualities        : O       O\n",
            ",                : O       O\n",
            "\"                : O       O\n",
            "he               : O       O\n",
            "reasoned         : O       O\n",
            ",                : O       O\n",
            "\"                : O       O\n",
            "it               : O       O\n",
            "is               : O       O\n",
            "folly            : O       O\n",
            "to               : O       O\n",
            "claim            : O       O\n",
            "them             : O       O\n",
            ".                : O       O\n",
            "\"                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrTzjM-welte"
      },
      "source": [
        "### 3. F1-Score\n",
        "* 시퀀스 레이블링 모델 평가할 때 주의할 점\n",
        "  * 모델의 경우에는 보통 큰 의미를 갖지 않는 레이블 정보가 존재\n",
        "    * 개체명 인식에서는 그 어떤 개체도 아니라는 의미의 'O' 태깅 존재\n",
        "      * 이런 정보는 보통 대다수의 레이블을 차지하기 때문에 기존에 사용했던 정확도 평가 방법을 사용하는 것이 적절하지 않을 수 있음\n",
        "      * 모델이 단 1개의 개체도 맞추지 못하고 전부 'O'으로 예상했을 경우"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL_DSAW2fWcS",
        "outputId": "d90abe8e-d81a-4d0d-b7d4-835a254e9c24"
      },
      "source": [
        "true=['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','B-MISC','I-MISC','I-MISC','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O']\n",
        "predicted=['O'] * len(true)\n",
        "print(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmdko-YFeZqj",
        "outputId": "400fd96d-0ef7-4390-f446-5af2609147e2"
      },
      "source": [
        "'''\n",
        "PER, MISC, PER, MISC, PER이라는 총 5개의 개체가 존재함에도 불구하고 \n",
        "예측값인 predicted는 단 1개의 개체도 맞추지 못한 상황을 시뮬레이션\n",
        "'''\n",
        "\n",
        "hit = 0\n",
        "for t, p in zip(true, predicted):\n",
        "  if t == p:\n",
        "    hit += 1 #정답인 경우에만 +1\n",
        "\n",
        "accuracy = hit/len(true) #정답 개수를 총 개수로 나눈다\n",
        "print(\"정확도: {:.1%}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 74.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSOutoqVfzBJ",
        "outputId": "7a95b34a-4332-45ff-8eae-743f4182b4e7"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=457e0ab3425062985d831bdbf7cc82bd86c5c41907f279d8c296e3849bd7cc0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4hY8xXMgE8H",
        "outputId": "06e5ca00-c9b0-461f-e31c-9ca655d583c6"
      },
      "source": [
        "from seqeval.metrics import classification_report\n",
        "print(classification_report([true], [predicted]))\n",
        "\n",
        "'''\n",
        "이러한 측정 방법을 사용하면 PER과 MISC 두 특정 개체 중에서 \n",
        "실제 predicted가 맞춘 것은 단 1개도 없는 것을 확인할 수 있음\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        MISC       0.00      0.00      0.00         2\n",
            "         PER       0.00      0.00      0.00         3\n",
            "\n",
            "   micro avg       0.00      0.00      0.00         5\n",
            "   macro avg       0.00      0.00      0.00         5\n",
            "weighted avg       0.00      0.00      0.00         5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozePVObCgh-T",
        "outputId": "c3a0fbe1-191a-4d17-b347-c5da21654d27"
      },
      "source": [
        "true=['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','B-MISC','I-MISC','I-MISC','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O']\n",
        "predicted=['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O','O','O','O','O','O','O','O','O','O','B-PER','I-PER','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O']\n",
        "print(classification_report([true], [predicted]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        MISC       1.00      0.50      0.67         2\n",
            "         PER       1.00      0.67      0.80         3\n",
            "\n",
            "   micro avg       1.00      0.60      0.75         5\n",
            "   macro avg       1.00      0.58      0.73         5\n",
            "weighted avg       1.00      0.60      0.75         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6atXdyCgysO"
      },
      "source": [
        "### 4. F1-score로 성능 측정하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5BUQNmVgvqF"
      },
      "source": [
        "def sequences_to_tag(sequences): # 예측값을 index_to_ner를 사용하여 태깅 정보로 변경하는 함수\n",
        "  result = []\n",
        "  for sequence in sequences: # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다\n",
        "    word_sequence = []\n",
        "    for pred in sequence: # 시퀀스로부터 예측값을 하나씩 꺼낸다\n",
        "      pred_index = np.argmax(pred) # 예를 들어 [0, 0, 1, 0, 0]라면 1의 인덱스인 2를 리턴\n",
        "      word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\")) #PAD는 O으로 변경\n",
        "      result.append(word_sequence)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KAA2ltJiwet"
      },
      "source": [
        "y_predicted = model.predict([X_test])\n",
        "pred_tags = sequences_to_tag(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxZ0cyLVjVoh",
        "outputId": "727543c1-a214-4951-9e1d-3bf6cdf0052b"
      },
      "source": [
        "from seqeval.metrics import f1_score, classification_report\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00      1050\n",
            "         eve       0.00      0.00      0.00      1470\n",
            "         geo       0.77      0.79      0.78    108850\n",
            "         gpe       0.92      0.84      0.88     48440\n",
            "         nat       0.00      0.00      0.00       630\n",
            "         org       0.42      0.50      0.46     59990\n",
            "         per       0.61      0.62      0.61     49070\n",
            "         tim       0.75      0.77      0.76     59710\n",
            "\n",
            "   micro avg       0.69      0.71      0.70    329210\n",
            "   macro avg       0.43      0.44      0.44    329210\n",
            "weighted avg       0.69      0.71      0.70    329210\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foMyf9dqjXRK",
        "outputId": "6df5d08e-1a1e-4643-a116-001a73e68c3f"
      },
      "source": [
        "from seqeval.metrics import f1_score, classification_report\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00      1050\n",
            "         eve       0.00      0.00      0.00      1470\n",
            "         geo       0.77      0.79      0.78    108850\n",
            "         gpe       0.92      0.84      0.88     48440\n",
            "         nat       0.00      0.00      0.00       630\n",
            "         org       0.42      0.50      0.46     59990\n",
            "         per       0.61      0.62      0.61     49070\n",
            "         tim       0.75      0.77      0.76     59710\n",
            "\n",
            "   micro avg       0.69      0.71      0.70    329210\n",
            "   macro avg       0.43      0.44      0.44    329210\n",
            "weighted avg       0.69      0.71      0.70    329210\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F43oFLvKjbPW"
      },
      "source": [
        "## 6) BiLSTM-CRF를 이용한 개체명 인식\n",
        "* 기존의 양방향 LSTM 모델에 CRF(Conditional Random Field)라는 새로운 층을 추가하여 보다 모델을 개선시킨 **양방향 LSTM + CRF 모델**을 사용하여 개체명 인식(Named Entity Recognition)을 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yniebAB9joJK"
      },
      "source": [
        "### 1. CRF(Conditional Random Field)\n",
        "* 양방향 LSTM 모델 위에 하나의 층으로 추가\n",
        "* 기존의 양방향 LSTM 개체명 인식 모델\n",
        "  * 각 단어를 **벡터**로 입력받고, **모델의 출력층에서 활성화 함수**를 통해 개체명을 예측\n",
        "* **양방향 LSTM 위에 CRF 층을 추가하여 얻을 수 있는 이점**\n",
        "  * CRF 층을 추가하면 모델은 예측 개체명, 다시 말해 **레이블 사이의 의존성**을 고려할 수 있음\n",
        "    * 기존에는 활성화 함수를 지난 시점에서 개체명 결정, CRF 층을 추가한 모델에서는 **활성화 함수의 결과들이 CRF 층의 입력으로 전달**됨\n",
        "      * word1에 대한 BiLSTM 셀과 활성화 함수를 지난 출력값은 CRF층의 입력이 됨\n",
        "      * 마찬가지로 모든 단어에 대한 활성화 함수를 지난 출력값은 CRF층의 입력이 되고, CRF 층은 레이블 시퀀스에 대해서 가장 높은 점수를 가지는 시퀀스를 예측\n",
        "    * 요약: **양방향 LSTM은 입력 단어에 대한 양방향 문맥을 반영하며, CRF는 출력 레이블에 대한 양방향 문맥을 반영**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRhlrxIydkKz",
        "outputId": "94ea0756-69f0-47f5-d702-4601e0b0b072"
      },
      "source": [
        "!pip install keras-crf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-crf\n",
            "  Downloading keras_crf-0.3.0-py3-none-any.whl (8.3 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-crf) (2.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.41.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (2.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (3.17.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (12.0.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (0.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (0.37.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (3.10.0.2)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (0.21.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-crf) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-crf) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-crf) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-crf) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-crf) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-crf) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-crf) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-crf) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-crf) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-crf) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-crf) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-crf) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->keras-crf) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->keras-crf) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-crf) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-crf) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-crf) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-crf) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-crf) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->keras-crf) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow->keras-crf) (3.6.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->keras-crf) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons, keras-crf\n",
            "Successfully installed keras-crf-0.3.0 tensorflow-addons-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhuy3KpPjsi-"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2ZbeZVhjZh_"
      },
      "source": [
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, TimeDistributed, Embedding, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras_crf import CRFModel"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmI11e_BjT9D"
      },
      "source": [
        "# 케라스의 함수형 API를 사용하여 마지막 층에 CRF층 추가\n",
        "sequence_input = Input(shape=(max_len,),dtype=tf.int32, name='sequence_input')\n",
        "model_embedding = Embedding(input_dim=vocab_size, output_dim=128, input_len=max_len)(sequence_input)\n",
        "model_bilstm = Bidirectional(LSTM(units=64, return_sequences=True))(model_embedding)\n",
        "model_dropout = TimeDistributed(Dropout(0.3))(model_bilstm)\n",
        "model_Dense = TimeDistributed(Dense(tag_size, activation='relut'))(model_dropout)\n",
        "base = Model(inputs=sequence_input, outputs=model_dense)\n",
        "model = CRFModel(base, tag_size)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlv3guK-j1MS"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModlCheckpoint('bilstm_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1,\n",
        "                    save_best_only=True, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2_ZnodGj1Uv"
      },
      "source": [
        "# 해당 패키지가 원핫 인코딩 된 레이블은 지원하지 않으므로 y_train이 아니라 y_train_int를 사용함을 주의\n",
        "history = model.fit(X_train, y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ERNJmqkQyC"
      },
      "source": [
        "model.load_weights('bilstm_crf/cp.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apejgB3fkQ6O"
      },
      "source": [
        "# 테스트 데이터의 13번 인덱스의 샘플에 대해서 예측\n",
        "i = 13\n",
        "y_predicted = model.predict(np.array([X_test[i]]))[0] #입력학 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "true = np.argmax(y_test[i], -1) #원핫 인코딩을 다시 정수 인코딩으로 변경\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "  if w != 0: #PAD값은 제외\n",
        "    print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t], index_to_ner[pred]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7euVLm3aktZs"
      },
      "source": [
        "# 테스트 데이터에 대해서 성능 측정. 테스트 데이터에 대한 예측 시쿠너스인 y_predicted 얻음\n",
        "y_predicted = model.predict(X_test)[0]\n",
        "print(y_predicted[:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLfDlRmok4k6"
      },
      "source": [
        "# 정수 시퀀스로 출력되므로 이전에 BiLSTM을 위해 사용했던 함수인 sequences_to_tag를 바로 사용 못해서 변형해야 함\n",
        "# CRF 층을 사용할 때를 위한 함수로 sequences_to_tag_for_crf를 만듦\n",
        "\n",
        "def sequences_to_tag_for_crf(sequences): #예측값을 index_to_nef를 사용하여 태깅 정보로 변경하는 함수\n",
        "  result = []\n",
        "  for sequence in sequences: #전체 시퀀스로부터 시퀀스를 하나씩 꺼냄\n",
        "    word_sequence = []\n",
        "    for pred_index in sequence: #시퀀스로부터 예측값 정수를 하나씩 꺼냄\n",
        "      word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\")) #PAD는 O로 변경\n",
        "    result.append(word_sequence)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPFQq0LilbWW"
      },
      "source": [
        "# 예측값과 실제값에 대한 태깅 시퀀스\n",
        "\n",
        "pred_tags = sequences_to_tag_for_crf(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_xTzyrFlbcl"
      },
      "source": [
        "# F1-score\n",
        "\n",
        "from seqeval.metrics import f1_score, classification_report\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnmnpx9ak4q4"
      },
      "source": [
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDu9OKqflymG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lrVynS8ly0u"
      },
      "source": [
        "## 7) 글자 임베딩(Character Embedding) 활용하기\n",
        "* 개체명 인식기의 성능을 높이는 방법으로 12챕터에서 배운 글자 임베딩을 워드 임베딩과 함께 입력으로 사용하는 방법이 있음\n",
        "* 워드 임베딩에 글자 임베딩을 연결(concatenate)하여 성능을 높임\n",
        "\n",
        "\n",
        "### 1. 글자 임베딩(Char Embedding)을 위한 전처리\n",
        "* 글자 임베딩을 위해서 하고자 하는 전처리는 글자 단위 정수 인코딩\n",
        "```\n",
        "'good book의 정수 인코딩 결과'\n",
        "[[12 7 7 17]\n",
        "[21 7 7 11]]\n",
        "```\n",
        "\n",
        "* 이 각 정수를 각각 임베딩 층을 거치도록 하여, 글자 단위 임베딩을 얻게 됨\n",
        "* 임베딩 층은 모델을 설계할 때 추가하게 되므로, 여기서는 정수 인코딩까지만 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj4VXhkCm9na"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpMFCqfpmysY"
      },
      "source": [
        "#import io\n",
        "#data = pd.read_csv(io.BytesIO(uploaded['ner_dataset.csv'].encode('latin1')))\n",
        "#data[:5]\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/ner_dataset.csv', encoding='latin1')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAmtu5LG4m-2",
        "outputId": "15423020-3ea9-4f6a-8054-8a5ba6f51222"
      },
      "source": [
        "# char_vocab 만들기\n",
        "words = list(set(data[\"Word\"].values))\n",
        "chars = set([w_i for w in words for w_i in w])\n",
        "chars = sorted(list(chars))\n",
        "print(chars)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['!', '\"', '$', '%', '&', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x85', '\\x92', '\\x94', '\\x96', '\\x97', '°', 'é', 'ë', 'ö']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjahDonE5Zyn"
      },
      "source": [
        "char_to_index = {c: i + 2 for i, c in enumerate(chars)}\n",
        "char_to_index[\"OOV\"] = 1\n",
        "char_to_index[\"PAD\"] = 0"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3_Mf9HlB_p4"
      },
      "source": [
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "    index_to_char[value] = key"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbQYSZAl-uWQ",
        "outputId": "f053b31c-a993-4bca-bc43-842922d36fd3"
      },
      "source": [
        "print(sentences[0])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNZZqDN99_lU"
      },
      "source": [
        "  max_len_char = 15\n",
        "\n",
        "  def padding_char_indice(char_indice, max_len_char):\n",
        "      return pad_sequences(\n",
        "        char_indice, maxlen=max_len_char, padding='post', \n",
        "        value = 0)\n",
        "    \n",
        "  def integer_coding(sentences):\n",
        "      char_data = []\n",
        "      for ts in sentences:\n",
        "        word_indice = [word_to_index[t] for t in ts]\n",
        "        char_indice = [[char_to_index[char] for char in t]  \n",
        "                                                     for t in ts]\n",
        "        char_indice = padding_char_indice(char_indice, max_len_char)\n",
        "    \n",
        "        for chars_of_token in char_indice:\n",
        "            if len(chars_of_token) > max_len_char:\n",
        "                print(\"최대 단어 길이 초과!\")\n",
        "                continue\n",
        "        char_data.append(char_indice)\n",
        "      return char_data"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE7aX8UFC7MT"
      },
      "source": [
        "X_char_data = integer_coding(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW2u8AkfoE2o"
      },
      "source": [
        "# 정수 인코딩 이전의 기존 문장\n",
        "print(sentences[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNursZZoqaeI"
      },
      "source": [
        "# 단어 단위 정수 인코딩 + 패딩\n",
        "print(X_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gz1ITFlrVFx"
      },
      "source": [
        "# 글자 단위 정수 인코딩\n",
        "print(X_char_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3MboEkArYUO"
      },
      "source": [
        "# 문장 길이 방향으로도 패딩을 해줌\n",
        "X_char_data = pad_sequences(X_char_data, maxlen=max_len, padding='post', value=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slMavtJmrfL4"
      },
      "source": [
        "X_char_train, X_char_test, _, _ = train_test_split(X_char_data, y_data, test_size=0.2, random_state=777)\n",
        "X_char_train = np.array(X_char_train)\n",
        "X_char_test = np.array(X_char_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk57DHdDrseo"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od8B0xngrsh-"
      },
      "source": [
        "print(index_to_word[150])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS2mntwyruOU"
      },
      "source": [
        "# 그렇다면 X_char_train의 첫번째 훈련 샘플의 첫번째 단어의 글자 정수 인코딩 결과로부터\n",
        "# soldiers라는 단어와 일치하는지 확인\n",
        "print(' '.join([index_to_char[index] for index in X_char_train[0][0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFR0zTYtr5Ty"
      },
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('훈련 샘플 char 데이터의 크기 : {}'.format(X_char_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQLfYO8sr6b2"
      },
      "source": [
        "### 2. BiLSTM-CNN을 이용한 개체명 인식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04tZRRfer_29"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, TimeDistributed, Dropout, concatenate, Bidirectional, LSTM, Conv1D, Dense, MaxPooling1D, Flatten\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.initializers import RandomUniform\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmjInDfvsAx3"
      },
      "source": [
        "# 단어 임베딩\n",
        "words_input = Input(shape=(None, ), dtype='int32', name='words_input')\n",
        "words = Embedding(input_dim = vocab_size, output_dim=128)(words_input)\n",
        "\n",
        "# char 임베딩\n",
        "character_input = Input(shape=(None, max_len_char, ), name='char_input')\n",
        "embed_char_out = TimeDistributed(Embedding(len(char_to_index), 64, embeddings_initializer = RAndomUniform(minival=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
        "dropout = Dropout(0.5)(embed_char_out)\n",
        "\n",
        "# char 임베딩에 대해서는 Conv1D 수행\n",
        "conv1d_out = TimeDistributed(Conv1D(kernel_size=3, filters=30, paddings='same', activation='tanh', strides=1))(dropout)\n",
        "maxpool_out = TimeDistributed(MaxPooling1D(max_len_char))(conv1d_out)\n",
        "char = TimeDistributed(Flatten())(maxpool_out)\n",
        "char = Dropout(0.5)(char)\n",
        "\n",
        "# char 임베딩을 Conv1D 수행한 뒤에 단어 임베딩과 연결\n",
        "output = concatenate([words, char])\n",
        "\n",
        "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM 수행\n",
        "output = Bidirectional(LSTM(256, return_sequences=True, dropout=0.5))(output)\n",
        "\n",
        "# 출력층\n",
        "output = TimeDistributed(Dense(tag_size, activation='sortmax'))(output)\n",
        "\n",
        "model = Model(inputs=[words_input, character_input], outputs=[output])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3BXywQpteky"
      },
      "source": [
        "# 조기 종료를 위해서 콜백 정의\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('bilstm_cnn.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f53HD__ctq43"
      },
      "source": [
        "history = model.fit([X_train, X_char_train], y_train, batch_size = 128, epochs = 15, validation_split = 0.1, verbose = 1, callbacks=[es, mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYCXwYxPteoS"
      },
      "source": [
        "# 조기 종료로 학습 끝날 시 검증 데이터에 대해서 정확도가 가장 높았을 당시를 저장해둔 가중치 불러오기\n",
        "model = load_model('bilstm_cnn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHf6hqMAtstx"
      },
      "source": [
        "# 테스트 데이터의 13번 인덱스의 샘플에 대해서 예측\n",
        "\n",
        "i=13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])]) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "\n",
        "y_predicted = np.argmax(y_predicted, axis=-1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
        "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if w != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t], index_to_ner[pred]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdb8Bsrmtsx8"
      },
      "source": [
        "# 테스트 데이터에 대해서 성능 측정\n",
        "y_predicted = model.predict([X_test, X_char_test])\n",
        "pred_tags = sequences_to_tag(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R291Xx7Qt324"
      },
      "source": [
        "# F1 score를 계산\n",
        "from seqeval.metrics import f1_score, classification_report\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0mAqq-it7X3"
      },
      "source": [
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOPsyY-At_Y6"
      },
      "source": [
        "### 3. BiLSTM-CNN-CRF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuh18ILot90l"
      },
      "source": [
        "# 단어 임베딩\n",
        "words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
        "words = Embedding(input_dim = vocab_size, output_dim = 128)(words_input)\n",
        "\n",
        "# char 임베딩\n",
        "character_input = Input(shape=(None, max_len_char,),name='char_input')\n",
        "embed_char_out = TimeDistributed(Embedding(len(char_to_index), 64, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
        "dropout = Dropout(0.5)(embed_char_out)\n",
        "\n",
        "# char 임베딩에 대해서는 Conv1D 수행\n",
        "conv1d_out= TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='same',activation='tanh', strides=1))(dropout)\n",
        "maxpool_out=TimeDistributed(MaxPooling1D(max_len_char))(conv1d_out)\n",
        "char = TimeDistributed(Flatten())(maxpool_out)\n",
        "char = Dropout(0.5)(char)\n",
        "\n",
        "# char 임베딩을 Conv1D 수행한 뒤에 단어 임베딩과 연결\n",
        "output = concatenate([words, char])\n",
        "\n",
        "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM을 수행\n",
        "output = Bidirectional(LSTM(256, return_sequences=True, dropout=0.50))(output)\n",
        "\n",
        "# 출력층\n",
        "output = TimeDistributed(Dense(tag_size, activation='relu'))(output)\n",
        "\n",
        "base = Model(inputs=[words_input, character_input], outputs=[output])\n",
        "\n",
        "model = CRFModel(base, tag_size)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8IxT9YZuEdw"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('bilstm_cnn_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtqYAZ8QuGRG"
      },
      "source": [
        "# CRF층은 원핫 인코딩 된 레이블은 지원하지 않으므로 y_train_int를 사용해야 함\n",
        "history = model.fit([X_train, X_char_train], y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp_73Y6guGZs"
      },
      "source": [
        "# 검증 데이터에 대해서 정확도가 가장 높았을 당시를 저장해둔 가중치 불러오기\n",
        "model.load_weights('bilstm_cnn_crf/cp.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imwtYDaRuVX3"
      },
      "source": [
        "# 테스트 데이터의 13번 인덱스의 샘플에 대해서 예측\n",
        "i=13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
        "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])[0] # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
        "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(35 * \"-\")\n",
        "\n",
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "    if w != 0: # PAD값은 제외함.\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t], index_to_ner[pred]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_EKqFTFuX4j"
      },
      "source": [
        "# 테스트 데이터에 대해서 성능 측정\n",
        "y_predicted = model.predict([X_test, X_char_test])[0]\n",
        "pred_tags = sequences_to_tag_for_crf(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKj0eesTucyL"
      },
      "source": [
        "# F1-score\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXE7004guffM"
      },
      "source": [
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsL7JB6Zugqd"
      },
      "source": [
        "### 4. BiLSTM-BiLSTM-CRF\n",
        "* 1D CNN이 아니라 양방향 LSTM을 통해서 얻을 수 있음\n",
        "* 양방향 LSTM을 이용해 얻은 글자 임베딩을 워드 임베딩과 연결(concatenate)하여 양방향 LSTM의 입력으로 사용하고, 마지막으로 CRF 층을 추가하여 모델을 만듭\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfKrDdjiuYAX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}