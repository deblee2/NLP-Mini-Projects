{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "What_is_NLP_Ch17_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQpOACm6svem"
      },
      "source": [
        "seq2seq의 단점을 개선하면서도 인코더-디코더 구조를 유지하는 트랜스포머 모델을 통해 챗봇 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqTgJGmEuosF"
      },
      "source": [
        "## 1) 트랜스포머\n",
        "* 2017년 구글의 \"Attention is all you need\" 논문에 나온 모델\n",
        "* seq2seq 구조인 인코더-디코더를 따르면서도, 논문의 이름처럼 어텐션만으로 구현한 모델\n",
        "  * RNN을 사용하지 않고 인코더-디코더 구조를 설계하였음에도 성능도 RNN보다 우수하다는 특징"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApWMQqlMu5Qr"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwEIcfUWuo0T"
      },
      "source": [
        "### 1. 기존 seq2seq 모델의 한계\n",
        "* 인코더가 입력 시퀀스를 **하나의 벡터로 압축**하는 과정에서 **입력 시퀀스의 정보가 일부 손실**된다는 단점. 이를 보정하기 위해서 어텐션 사용\n",
        "* 그런데 어텐션을 RNN의 보정을 위한 용도가 아니라, **아예 어텐션으로 인코더와 디코더 만들기**\n",
        "\n",
        "### 2. 트랜스포머의 주요 하이퍼파라미터\n",
        "* **d model** : 트랜스포머의 인코더와 디코더에서의 정해진 입력과 출력의 크기 의미. 임베딩 벡터의 차원 또한 d model이며, 각 인코더와 디코더가 다음 층의 인코더와 디코더로 값을 보낼 때도 이 차원 유지. \n",
        "* **num_layers** : 트랜스포머에서 하나의 인코더와 디코더를 층으로 생각하였을 때, 트랜스포머 모델에서 인코더와 디코더가 총 몇 층으로 구성되었는지를 의미. 논문에서는 각각 총 6개씩 싸음\n",
        "* **num_heads** : 트랜스포머에서는 어텐션을 사용할 때, 1번 하는 것보다 여러 개로 분할해서 병렬로 어텐션을 수행하고 결과값을 다시 하나로 합치는 방식 선택. 이때 이 병렬의 개수 의미.\n",
        "* **d ff**: 트랜스포머 내부에는 피드 포워드 신경망이 존재. 이때 은닉층의 크기 의미. 피드 포워드 신경망의 입력층과 출력층의 크기는 d model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH-v1mAAzIVw"
      },
      "source": [
        "### 3. 트랜스포머\n",
        "* RNN 사용하지 않지만 기존의 seq2seq처럼 인코더에서 입력 시퀀스를 입력받고, 디코더에서 출력 시퀀스를 출력하는 인코더-디코더 구조 유지\n",
        "* 다른 점은 인코더와 디코더라는 단위가 **N개 존재**할 수 있다는 점\n",
        "* 이전 seq2seq 구조에서는 인코더와 디코더에서 각각 하나의 RNN이 t개의 시점(time-step)을 가지는 구조였다면, 이번에는 인코더와 디코더라는 단위가 N개로 구성되는 구조. 트랜스포머를 제안한 논문에서는 인코더와 디코더의 개수를 각각 6개 사용\n",
        "* 트랜스포머의 인코더와 디코더는 단순히 각 단어의 임베딩 벡터들을 입력받는 것이 아니라 임베딩 벡터에서 조정된 값을 입력받는데 이에 대해서 알아보기 위해 입력 부분 확대\n",
        "\n",
        "### 4. 포지셔널 인코딩\n",
        "* 트랜스포머의 내부를 이해하기 전에 우선 트랜스포머의 입력에 대해서 알아봄\n",
        "* RNN이 자연어처리에서 유용했던 이유는 **단어의 위치에 따라 단어를 순차적으로 입력**받아서 처리하는 RNN의 특성으로 인해 각 단어의 **위치 정보(positional information)**를 가질 수 있다는 점\n",
        "\n",
        "* **하지만** 트랜스포머는 단어 입력을 순차적으로 받는 방식이 아니므로 단어의 위치 정보를 다른 방식으로 알려줄 필요가 있음\n",
        "  * 트랜스포머는 단어의 위치 정보를 얻기 위해서 **각 단어의 임베딩 벡터에 위치 정보들을 더하여 모델의 입력으로 사용**. 이를 **포지셔녈 인코딩(positional encoding)**이라고 함\n",
        "    * 임베딩 벡터가 인코더의 입력으로 사용되기 전에 인코딩 값이 더해지는 과정\n",
        "    * 트랜스포머는 **사인 함수와 코사인 함수의 값**을 임베딩 벡터에 더해주므로서 단어의 순서 정보를 더하여 줌\n",
        "    * 임베딩 벡터와 포지셔널 인코딩의 덧셈은 사실 임베딩 벡터가 모여 만들어진 '문장 벡터 행렬'과 포지셔널 인코딩 행렬의 덧셈 연산을 통해 이루어짐\n",
        "      * pos: 입력 문장에서의 임베딩 벡터의 위치\n",
        "      * i: 임베딩 벡터 내의 차원의 인덱스 의미\n",
        "        * 임베딩 벡터 내의 각 차원의 인덱스가 짝수면 사인 함수의 값, 홀수면 코사인 함수의 값\n",
        "      * d model: 트랜스포머의 모든 층의 출력 차원을 의미하는 트랜스포머의 하이퍼파라미터. 앞으로 보게 될 트랜스포머의 각종 구조에서 d model의 값이 계속해서 등장하는 이유. 임베딩 벡터 또한 d model의 차원을 가짐.\n",
        "  * 임베딩 벡터에 포지셔널 인코딩값을 더하면 같은 단어라고 하더라도 문장 내의 위치에 따라서 트랜스포머의 입력으로 들어가는 임베딩 벡터의 값이 달라짐. 결국 트랜스포머의 입력은 순서 정보가 고려된 임베딩 벡터."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AnMC_gJsrYP"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "  \n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "  \n",
        "    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    angle_rads = np.zeros(angle_rads.shape)\n",
        "    angle_rads[:, 0::2] = sines\n",
        "    angle_rads[:, 1::2] = cosines\n",
        "    pos_encoding = tf.constant(angle_rads)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "    print(pos_encoding.shape)\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "tPTL3_QUAz8P",
        "outputId": "457a7650-64ef-431e-a053-71139b6a6e08"
      },
      "source": [
        "# 50 x 128의 크기를 가지는 포지셔널 인코딩 행렬을 시각화하여 어떤 형태를 가지는지 확인\n",
        "# 입력 문장의 단어가 50개이면서, 각 단어가 128차원의 임베딩 벡터를 가질 때 사용할 수 있는 행렬\n",
        "\n",
        "# 문장의 길이 50, 임베딩 벡터의 차원 128\n",
        "sample_pos_encoding = PositionalEncoding(50, 128)\n",
        "\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 128))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 50, 128)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPX5xunZBT-m"
      },
      "source": [
        "### 5. Attention\n",
        "* 셀프 어텐션은 인코더에서 이루어짐. 본질적으로 Query, Key, Value가 동일한 경우.\n",
        "* 인코더-디코더 어텐션에서는 Query가 디코더의 벡터인 반면, Key와 Value가 인코더의 벡터이므로 셀프 어텐션이라고 부르지 않음\n",
        "  * Query, Key 등이 같다는 것은 벡터의 값이 같다는 것이 아니라 벡터의 출처가 같다는 의미\n",
        "    - 인코더의 셀프 어텐션: Query = Key = Value\n",
        "    - 디코더의 마스크드 셀프 어텐션: Query = Key = Value\n",
        "    - 디코더의 인코더-디코더 어텐션: Query : 디코더 벡터 / Key = Value  : 인코더 벡터\n",
        "\n",
        "### 6. Enoder\n",
        "* 하이퍼파라미터인 num_layers 개수의 인코더 층을 쌓음\n",
        "* 논문에서는 총 6개의 인코더 층을 사용\n",
        "* 하나의 인코더 층은 총 2개의 서브층(sublayer)로 나뉘어짐: **셀프 어텐션과 피드 포워드 신경망**\n",
        "* 멀티 헤드 셀프 어텐션: 셀프 어텐션을 병렬적으로 사용\n",
        "* 포지션 와이즈 피드 포워드 신경망: 우리가 알고있는 일반적인 피드 포워드 신경망\n",
        "\n",
        "### 7. 인코더의 셀프 어텐션\n",
        "#### 1) 셀프 어텐션의 의미와 이점\n",
        "* 어텐션 함수는 주어진 Query에 대해서 모든 Key와의 유사도를 각각 구함. 그리고 구해낸 이 유사도를 가중치로 하여 키와 맵핑되어 있는 각각의 Value에 반영. 그리고 유사도가 반영된 Value를 모두 가중합하여 리턴.\n",
        "* 셀프 어텐션은 어텐션을 자기 자신에게 수행한다는 의미. 앞서 배운 seq2seq에서 어텐션을 사용할 경우의 Q, K, V의 정의 다시 생각\n",
        "  * Q = Query : t 시점의 디코더 셀에서의 은닉 상태\n",
        "  * K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
        "  * V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
        "* 그런데 사실 t 시점이라는 것은 계속 변화하면서 반복적으로 쿼리를 수행하므로 결국 전체 시점에 대해서 일반화 가능\n",
        "  * Q = Querys : 모든 시점의 디코더 셀에서의 은닉 상태들\n",
        "  * K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
        "  * V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
        "* 기존에는 디코더 셀의 은닉 상태가 Q이고 인코더 셀의 은닉 상태가 K라는 점에서 Q와 K가 서로 다른 값을 가지고 있었음. 그런데 셀프 어텐션에서는 Q, K, V가 전부 동일.\n",
        "  * Q, K, V : 입력 문장의 모든 단어 벡터들\n",
        "\n",
        "#### 2) Q, K, V 벡터 얻기\n",
        "\n",
        "#### 3) Scaled dot-product Attention\n",
        "* Q, K, V 벡터를 얻었다면 지금부터는 기존에 배운 어텐션 메커니즘과 동일. 각 Q 벡터는 모든 K 벡터에 대해서 어텐션 스코어를 구하고, 어텐션 분포를 구한 뒤에 이를 사용하여 모든 V 벡터를 가중합하여 어텐션 값 또는 컨텍스트 벡터를 구하게 됨. 그리고 이를 모든 Q 벡터에 대해서 반복\n",
        "* 트랜스포머에서는 어텐션 챕터에서 사용했던 내적만을 사용하는 어텐션 함수가 아니라 여기에 특정값으로 나눠준 어텐션 함수(아래)를 사용. 이러한 함수를 스케일드 닷-프로덕트 어텐션이라고 함\n",
        "  > score(q, k) = q·k/root(n)\n",
        "* ... 어텐션 스코어에 소프트맥스 함수를 사용하여 어텐션 분포(Attention Distribution)을 구하고, 각 V벡터와 가중합하여 어텐션 값(Attention Value)를 구함. 이를 단어 I에 대한 어텐션 값 또는 단어 I에 대한 컨텍스트 벡터(context vector)라고도 부름\n",
        "\n",
        "#### 4) 행렬 연산으로 일괄 처리하기\n",
        "* 사실 각 단어에 대한 Q, K, V 벡터를 구하고 스케일드 닷-프로덕트 어텐션을 수행하였던 위의 과정들은 벡터 연산이 아니라 행렬 연산을 사용하면 일괄 계산이 가능. 지금까지 벡터 연산으로 설명하였던 이유는 이해를 돕기 위한 과정이고, 실제로는 행렬 연산으로 구현됨\n",
        "  * 각 단어 벡터마다 일일히 가중치 행렬을 곱하는 것이 아니라 **문장 행렬**에 가중치 행렬을 곱하여 Q 행렬, K 행렬, V 행렬을 구함\n",
        "  * 이렇게 어텐션 스코어 행렬 구했으면 남은 것은 어텐션 분포를 구하고, 이를 사용하여 모든 단어에 대한 어텐션 값을 구하는 일\n",
        "  * 이는 간단하게 어텐션 스코어 행렬에 소프트맥스 함수를 사용하고, V 행렬을 곱하는 것으로 해결\n",
        "\n",
        "#### 5) 스케일드 닷-프로덕트 어텐션 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91LxRoFjBLRe"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
        "\n",
        "  # Q와 K의 곱. 어텐션 스코어 행렬.\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 스케일링\n",
        "  # dk의 루트값으로 나눠준다\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣음\n",
        "  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 됨\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행\n",
        "  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnzzbFPzJ9Rm"
      },
      "source": [
        "* Q 행렬과 K 행렬을 전치한 행렬 곱하기\n",
        "* 소프트맥스 함수를 사용하여 어텐션 분포 행렬을 얻은 뒤에 V 행렬과 곱함\n",
        "* 코드에서 mask가 사용되는 if문은 아직 배우지 않은 내용으로 지금은 무시하고 넘어감\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMWh0gXqJ3mi"
      },
      "source": [
        "# scaled_dot_product_attention 함수가 정상 작동하는지 테스트\n",
        "# 우선 temp_q, temp_k, temp_v라는 임의의 Query, Key, Value 행렬을 만들고\n",
        "# 이를 scaled_dot_product_attention 함수에 입력으로 넣어 함수가 리턴하는 값을 출력\n",
        "\n",
        "# 임의의 Query, Key, Value인 Q, K, V 행렬 생성\n",
        "np.set_printoptions(suppress=True)\n",
        "temp_k = tf.constant([[10,0,0],\n",
        "                      [0,10,0],\n",
        "                      [0,0,10],\n",
        "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
        "\n",
        "temp_v = tf.constant([[   1,0],\n",
        "                      [  10,0],\n",
        "                      [ 100,5],\n",
        "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
        "                      \n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zN-i-RpKhDY",
        "outputId": "aeea18fb-67a2-498e-fae3-3067a14113a6"
      },
      "source": [
        "# 여기서 주목할 점은 Query에 해당하는 temp_q의 값 [0, 10, 0]은 \n",
        "# Key에 해당하는 temp_K의 두번째 값 [0, 10, 0]과 일치한다는 점\n",
        "# 어텐션 분포와 어텐션 값은 과연 어떤 값이 나올까\n",
        "\n",
        "# 함수 실행\n",
        "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
        "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
        "print(temp_out) # 어텐션 값"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
            "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPypVgKXK45F",
        "outputId": "f2c533bf-06b0-4b02-be6a-3f2d513c7e5a"
      },
      "source": [
        "# Query의 값은 Key의 세번째 갑소가 네번째 값 두 개의 값과 모두 유사하다는 의미에서\n",
        "# 어텐션 분포는 [0, 0, 0.5, 0.5]의 값을 가짐\n",
        "# 결과적으로 나오는 값 [550, 5.5]는 Value의 세번째 값 [100,5]에 0.5를 곱한 값과\n",
        "# [1000,6]dp 0.5를 곱한 값의 원소별 합\n",
        "# 이번에는 하나가 아닌 3개의 Query의 값을 함수의 입력으로 사용\n",
        "\n",
        "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
        "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
        "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
        "print(temp_out) #어텐션 ㄱ밧"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.  0.  0.5 0.5]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[550.    5.5]\n",
            " [ 10.    0. ]\n",
            " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVrbR86ZPAG8"
      },
      "source": [
        "#### 6) Multi-head Attention\n",
        "* 앞서 배운 어텐션에서는 d model의 차원을 가진 단어 벡터를 num_heads로 나눈 차원을 가지는 Q, K, V 벡터로 바꾸고 어텐션을 수행. \n",
        "* 논문 기준으로는 512의 차원이 각 단어 벡터를 8로 나누어 64차원의 Q, K, V 벡터로 바꾸어서 어텐션을 수행한 셈인데, 이제 num_heads의 의미와 왜 d model의 차원을 가진 단어 벡터를 가지고 어텐션을 하지 않고 차원을 축소시킨 벡터로 어텐션을 수행하였는지 이해해보기\n",
        "* 트랜스포머 연구진은 한 번의 어텐션을 하는 것보다 여러 번의 어텐션을 병렬로 사용하는 것이 더 효과적이라고 판단. 그래서 d model의 차원을 num_heads개로 나누어 d model / num_heads의 차원을 가지는 Q, K, V에 대해서 num_heads 개의 병렬 어텐션 수행. 논문에서는 8.\n",
        "  * 이때 각각의 어텐션 값 행렬을 어텐션 헤드라고 부름. 이때 가중치 행렬 W Q, W K, W V의 값은 8개의 어텐션 헤드마다 전부 다름\n",
        "#### Q. 병렬 어텐션으로 얻을 수 있는 효과?\n",
        "  * 머리가 여러 개이기 때문에 여러 시점에서 상대방을 볼 수 있음\n",
        "  * 어텐션을 병렬로 수행하여 다른 시각으로 정보들을 수집\n",
        "\n",
        "\n",
        "* 병렬 어텐션을 모두 수행하였다면 모든 어텐션 헤드를 연결(concatenate)함  \n",
        "* 트랜스포머는 다수의 인코더를 쌓은 형태인데 인코더에서의 입력의 크기가 출력에서도 동일 크기로 계속 유지되어야만 다음 인코더에서도 다시 입력이 될 수 있기 때문"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtWWxYVbT1ga"
      },
      "source": [
        "#### 7) 멀티 헤드 어텐션 구현하기\n",
        "* 크게 두 종류의 가중치 행렬\n",
        "1. Q, K, V 행렬을 만들기 위한 가중치 행렬인 **WQ, WK, WV 행렬**\n",
        "2. 바로 어텐션 헤드들을 연결(concatenate) 후에 곱해주는 **WO 행렬**\n",
        "  * 가중치 행렬을 곱하는 것을 구현 상에서는 입력을 밀집층(Dense layer)를 지나게 하므로서 구현\n",
        "  * 케라스 코드 상으로 지금까지 줄기차게 사용해왔던 Dense()에 해당\n",
        "  > Dense(units)\n",
        "\n",
        "* 크게 다섯 가지 파트로 구성\n",
        "1. WQ, WK, WV에 해당하는 d_model 크기의 밀집층(Dense layer)를 지나게 함\n",
        "2. 지정된 헤드 수(num_heads)만큼 나눈다(split)\n",
        "3. 스케일드 닷 프로덕트 어텐션\n",
        "4. 나눠졌던 헤드들을 연결(concatenate)한다\n",
        "5. WO에 해당하는 밀집층을 지나게 한다\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12pjbmGHLKmo"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    # d_model을 num_heads로 나눈 값\n",
        "    # 논문 기준: 64\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    # WQ, WK, WV에 해당하는 밀집층의 정의\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    # WO에 해당하는 밀집층 정의\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self_depth))\n",
        "    return tf.transpose(inputs, perm=[0, 1, 2, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
        "    # q: (batch_size, query의 문장 길이, d_model)\n",
        "    # k: (batch_size, key의 문장 길이, d_model)\n",
        "    # v: (batch_size, value의 문장 길이, d_model)\n",
        "    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 2. 헤드 나누기\n",
        "    # q : (batch_size, num_heads, query 문장 길이, d_model/num_heads)\n",
        "    # k: (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "    # v: (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 3. scaled dot product attention\n",
        "    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
        "    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 4. 헤드 연결(concatenate) 하기\n",
        "    # (batch_size, query의 문장 길이, d_model)\n",
        "    concat_attention = tf.reshape(scaled_attention, batch_size, -1, self.d_model))\n",
        "\n",
        "    # 5. WO에 해당하는 밀집층 지나기\n",
        "    # (batch_size, query의 문장 길이, d_model)\n",
        "    outputs = self.dense(concat_attention) \n",
        "\n",
        "    return outputs   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgIahi72ivdA"
      },
      "source": [
        "#### 8) 패딩 마스크 Padding mask\n",
        "* scaled dot product attention 함수 내부를 보면 mask라는 값을 인자로 받아서, 이 mask값에다가 -1e9라는 아주 작은 음수값을 곱한 후 어텐션 스코어 행렬을 더해줌. 이 연산의 정체는?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psTnv87Ji5w3"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  중략..\n",
        "  logits += (mask * -1e9) # 어텐션 스코어 행렬인 logits에 mask*-1e9 값을 더해주고 있다\n",
        "  중략.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VprZiosWjD0i"
      },
      "source": [
        "* 이는 입력 문장에 <PAD> 토큰이 있을 경우 어텐션에서 사실상 제외하기 위한 연산. \n",
        "* <PAD>는 실질적인 의미를 가진 단어가 아니라서 트랜스포머에서는 Key의 경우에 <PAD> 토큰이 존재한다면 이에 대해서는 유사도를 구하지 않도록 마스킹(Masking)을 해주기로 함\n",
        "  * 마스킹: 어텐션에서 제외하기 위해 값을 가린다는 의미\n",
        "* 어텐션 스코어 행렬에서 행에 해당하는 문장은 Query, 열에 해다아는 문장은 Key\n",
        "  * Key에 <PAD>가 있는 경우에는 해당 열 전체를 마스킹\n",
        "  * How? 어텐션 스코어 행렬의 마스킹 위치에 **매우 작은 음수값**을 넣어주는 것\n",
        "* 현재 어텐션 스코어 함수는 소프트맥스 함수를 지나지 않은 상태.\n",
        "  * 어텐션 스코어 함수는 소프트맥스 함수를 지나고, 그 후 value 행렬과 곱해지게 됨\n",
        "  * 그런데 현대 마스킹 위치에 매우 작은 음수 값이 들어가 있으므로 어텐션 스코어 행렬이 소프트맥스 함수를 지난 후에는 해당 위치의 값은 0에 굉장히 가까운 값이 되어 단어 간 유사도를 구하는 일에 <PAD> 토큰이 반영되지 않게 됨\n",
        "* 패딩 마스크 구현 방법: 입력된 정수 시퀀스에서 패딩 토큰의 인덱스인지, 아닌지를 판별하는 함수를 구현하는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCxlR5h52btC"
      },
      "source": [
        "# 정수 시퀀스에서 0인 경우에는 1로 변환, 그렇지 않은 경우에는 0으로 변환\n",
        "\n",
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, key의 문장 길이)\n",
        "  return mask[: , tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW3ZFkdq2qtk"
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cFJu0C7206G"
      },
      "source": [
        "* 위 벡터를 통해서 1의 값을 가진 위치의 열을 어텐션 스코어 행렬에서 마스킹하는 용도로 사용할 수 있음\n",
        "* 위 벡터를 스케일드 닷 프로덕트 어텐션의 인자로 전달하면, 스케일드 닷 프로덕트 어텐션에서는 위 벡터에다가 매우 작은 음수값인 -1e9를 곱하고, 이를 행렬에 더해주어 해당 열을 전부 마스킹하게 되는 것\n",
        "* 첫번째 서브층인 멀티 헤드 어텐션을 구현함. 앞서 인코더는 두 개의 서브 서브층(subplayer)로 나뉘어진다고 언급한 적이 있는데, 이제 두번째 서브층인 **포지션-와이드 피드 포워드 신경망**에 대해서 알아봄"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFY7Tupz3ZK0"
      },
      "source": [
        "### 8. 포지션-와이즈 피드 포워드 신경망(Position-wise FFNN)\n",
        "* FFNN은 사실 인코더와 디코더에서 공통적으로 가지고 있는 서브층. 쉽게 말하면 완전 연결 FFNN.\n",
        "  > FFNN(x) = MAX(0, xW1 + b1)W2 + b2\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDNptNRQ3QHj"
      },
      "source": [
        "# 다음의 코드는 인코더와 디코더 내부에서 사용할 예정입니다.\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwqlUGZa1o61"
      },
      "source": [
        "### 9. 잔차 연결과 층 정규화\n",
        "* 두 개의 서브층을 가진 인코더에 추가적으로 사용하는 기법이 바로 Add and Norm\n",
        "  * Residual connection and layer normalization\n",
        "#### 1) 잔차 연결(Residual connection)\n",
        "* F(x) : 트랜스포머에서는 서브층에 해당\n",
        "  * 잔차 연결은 서브층의 입력과 출력을 더하는 것\n",
        "  * 트래스포머의 서브층의 입력과 출력은 동일한 차원을 갖고 있으므로, 서브층의 입력과 서브층의 출력은 덧셈 연산을 할 수 있음. 이것이 바로 인코더 그림에서 각 화살표가 서브층이 입력에서 출력으로 향하도록 그려졌던 이유\n",
        "  * 잔차 연결은 컴퓨터 비전 분야에서 주로 사용되는 모델의 학습을 돕는 기법\n",
        "> x + Subplayer(x)\n",
        "  * 가령, 서브층이 멀티 헤드 어텐션이었다면 잔차 연결 연산은 다음과 같음\n",
        "  > H(x) = x + Multi - head Attention(x)\n",
        "#### 2) 층 정규화(Layer Normalization)\n",
        "* 잔차 연결을 거친 결과는 이어서 층 정규화 과정을 거치게 됨. 잔차 연결의 입력을 x, 잔차 연결과 층 정규화 두 가지 연산을 모두 수행한 후의 결과 행렬을 LN\n",
        "* 잔차 연결 후 층 정규화 연산을 수식으로 표현하자면 다음과 같음\n",
        "  > LN =  LayerNorm(x + Subplayer(x))\n",
        "* 층 정규화: **텐서의 마지막 차원**에 대해서 평균과 분산을 구하고, 이를 가지고 어떤 수식을 통해 값을 정규화하여 학습을 도움. 텐서의 마지막 차원 = 트랜스포머에서는 d model의 차원\n",
        "* 층 정규화 수행 후 벡터 xi는 ln i라는 벡터로 정규화가 됨\n",
        "  > ln i = LayerNorm(x i)\n",
        "* 층 정규화의 수식\n",
        "  * 1. 평균과 분산을 통한 정규화\n",
        "  * 2. 감마와 벡터 도입\n",
        "### 10. 인코더 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy4iNfSD1msR"
      },
      "source": [
        "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 인코더는 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs, 'key':inputs, 'value':inputs, # Q = K = V\n",
        "          'mask': padding_mask # 패딩 마스크 사용\n",
        "      })\n",
        "\n",
        "  # 드로아웃 + 잔차 연결과 층 정규화\n",
        "  attention = tf.keras.layers.Dropout(tate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "  \n",
        "  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  outputs = tf.keras.layrs.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxSE-TkWMGz9"
      },
      "source": [
        "* 인코더의 입력으로 들어가는 문장에 패딩이 있을 수 있으므로, 어텐션 시 패딩 토큰을 제외하도록 패딩 마스크 사용\n",
        "  * MultiHeadAttention 함수의 mask의 인자값으로 padding_mask가 들어가는 이유\n",
        "* 인코더는 두 개의 서브층으로 이루어짐. 멀티 헤드 어텐션과 피드 포워드 신경망\n",
        "  * 각 서브층 이후에는 드롭 아웃, 잔차 연결과 층 정규화 수행\n",
        "* 위 코드는 하나의 인코더 층을 구현하는 코드. 실제 트랜스포머는 num_layers 개수만큼 인코더 층을 사용하므로 이를 여러 번 쌓는 코드 별도 구현 필요\n",
        "### 11. 인코더 쌓기\n",
        "* num_layers 만큼 쌓고, 마지막 인코더 층에서 얻는 (seq_len, d_model) 크기의 행렬을 디코더로 보내주므로서 트랜스포머 인코더의 인코딩 연산이 끝나게 됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHpOXmzIMYC5"
      },
      "source": [
        "def encoder(vocab_size, num_layers, dff, d_model, num_heads, dropout, name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 인코더는 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 포지셔널 인코딩 + 드롭아웃\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # 인코더를 num_layers개 쌓기\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads, \n",
        "                            dropout = dropout, name=\"encoder_layer_{}\".format(i), \n",
        "                            )([outputs, padding_mask])\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq01-wCZPmOW"
      },
      "source": [
        "### 12. 인코더에서 디코더로(From Encoder To Decoder)\n",
        "* num_layers 만큼의 층 연산을 순차적으로 한 후에 마지막 층의 인코더의 출력을 디코더에게 전달\n",
        "* 디코더 또한 총 num_layers만큼의 연산을 하는데, 이때마다 인코더가 보낸 출력을 각 디코더 층 연산에 사용\n",
        "### 13. 디코더의 첫번째 서브층: 셀프 어텐션과 룩-어헤드 마스크\n",
        "* 디코더: 인코더와 동일하게 임베딩 층과 포지셔널 인코딩을 거친 후의 문장 행렬이 입력됨\n",
        "* 트랜스포머 또한 seq2seq와 마찬가지로 **교사 강요(Teacher Forcing)**을 사용하여 훈련되므로 학습 과정에서 디코더는 번역할 문장에 해당되는 <sos> je suis étudiant 의 문장 행렬을 한 번에 입력받음\n",
        "* 디코더는 이 문장 행렬로부터 각 시점의 단어를 예측하도록 훈련됨\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5Lq6eeeUSod"
      },
      "source": [
        "* 문제가 있음: seq2seq의 디코더에 사용되는 RNN 계열의 신경망은 **입력 단어를 매 시점마다 순차적으로 받으므로 다음 단어 예측에 현재 시점 이전에 입력된 단어들만 참고** 가능\n",
        "* 반면, 트랜스포머는 문장 행렬로 입력을 한 번에 받음\n",
        "  * 현재 시점의 단어를 예측하고자 할 때, 입력 문장 핼렬로부터 미래 시점의 단어까지도 참고할 수 있는 현상 발생\n",
        "  * ex. suis를 예측해야 하는 시점. seq2seq 디코더라면 현재까지 디코더로 입력된 단어는 <sos>와 je뿐. 반면, 트랜스포머는 이미 문장 행렬로 <sos> je suis etudiant를 입력\n",
        "  * 이를 위해 트랜스포머의 디코더에서는 현재 시점의 예측에서 현재 시점보다 미래에 있는 단어들을 참고하지 못하도록 **룩-어헤드 마스크(look-ahead mask)**를 도입. 직역하면 '미리보기에 대한 마스크'라고 할 수 있음\n",
        "    * 룩-어헤드 마스크는 디코더의 첫번째 서브층에서 이루어짐. \n",
        "    * 디코더의 첫번째 서브층인 멀티 헤드 셀프 어텐션 층은 인코더의 첫번째 서브층인 멀티 헤드 셀프 어텐션 층과 동일한 연산을 수행\n",
        "    * **오직 다른 점: 어텐션 스코어 행렬에서 마스킹을 적용한다는 점**만 다름\n",
        "    * 셀프 어텐션을 통해 어텐션 스코어 행렬을 얻고, 이제 자기 자신보다 미래에 있는 단어들은 참고하지 모사도록 다음과 같이 마스킹\n",
        "    * 룩 어헤드 마스크 구현: 패딩 마스크와 마찬가지로 앞서 구현한 스케일드 닷 프로덕트 어텐션 함수에 mask라는 인자 전달\n",
        "      * 패딩 마스킹 써야하는 경우에도 스케일드 닷 프로덕트 어텐션 함수에 패딩 마스크를 전달하고, 룩-어헤드 마스킹을 써야하는 경우에는 스케일드 닷 프로덕트 어텐션 함수에 룩-어헤드 마스크 전달"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQxu2nn2Plmo"
      },
      "source": [
        "# 스케일드 닷 프로덕트 어텐션 함수를 다시 복습\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  ...중략...\n",
        "  logits += (mask * -1e9) # 어텐션 스코어 행렬인 logits에 mask*-1e9 값을 더해주고 있음\n",
        "  ...중략..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEcvJCPSW-Oy"
      },
      "source": [
        "* 트랜스포머에는 총 세 가지 어텐션이 존재\n",
        "  * 모두 **멀티 헤드 어텐션**을 수행\n",
        "  * 멀티 헤드 어텐션 함수 내부에서 **스케일드 닷 프로덕트 어텐션 함수**를 호출하는 데 각 어텐션 시 함수에 전달하는 **마스킹**은 다음과 같음\n",
        "    * 1. 인코더의 셀프 어텐션: 패딩 마스크를 전달\n",
        "    * 2. 디코더의 첫번째 서브층인 *마스크드 셀프 어텐션*: 룩-어헤드 마스크를 전달 <-- 지금 배우고 있음\n",
        "    * 3. 디코더의 두번째 서브층인 *인코더-디코더 어텐션*: 패딩 마스크를 전달\n",
        "* 룩-어헤드 마스크를 한다고 해서 패딩 마스크가 불필요한 것이 아니므로 *룩-어헤드 마스크는 패딩 마스크를 포함하도록 구현*\n",
        "* 룩-어헤드 마스크를 구현하는 방법은 패딩 마스크 때와 마찬가지로 마스킹을 하고자 하는 위치에는 1을, 마스킹을 하지 않는 위치에는 0을 리턴\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3v-e22naAay"
      },
      "source": [
        "# 디코더의 첫번째 서브층(subplayer)에서 미래 토큰을 Mask하는 함수\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4qg35N1aXKC"
      },
      "source": [
        "* 임의의 정수 시퀀스 입력을 넣어서 결과를 봅시다. 패딩 마스크를 테스트 하기위해 세번째 위치에 정수 0을 넣었음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ6qKZpOacz6"
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3GHtj0Xah7n"
      },
      "source": [
        "### 14. 디코더의 두번째 서브층: 인코더-디코더 어텐션\n",
        "* 디코더의 두번째 서브층에 대해서 이해해보기\n",
        "  * 멀티 헤드 어텐션을 수행하다는 점에서 이전의 어텐션들(인코더와 디코더의 첫번째 서브층)과 같지만, **셀프 어텐션은 아님**\n",
        "* 셀프 어텐션은 Query, Key, Value가 같은 경우를 말하는데, **인코더-디코더 어텐션은 Query가 디코더인 행렬인 반면, Key와 Value는 인코더 행렬이기 때문**\n",
        "  * 인코더의 첫번째 서브층 : Query = Key = Value\n",
        "  * 디코더의 첫번째 서브층 : Query = Key = Value\n",
        "  * 디코더의 두번째 서브층 : Query : 디코더 행렬 / Key = Value : 인코더 행렬\n",
        "* 디코더의 두 번째 서브층을 확대해보면, 다음과 같이 인코더로부터 두 개의 화살표가 그려져 있음\n",
        "  * 두 개의 화살표는 각각 Key와 Value를 의미하며, 이는 인코더의 마지막 층에서 온 행렬로부터 얻음\n",
        "  * 반면, Query는 디코더의 첫번째 서브층의 결과 행렬로부터 얻는다는 점이 다름\n",
        "  * Query가 디코더 행렬, Key가 인코더 행렬일 때, 어텐션 스코어 행렬을 구하는 과정은 다음과 같음\n",
        "* 멀티 헤드 어텐션을 수행하는 과정은 다른 어텐션들과 같음\n",
        "### 15. 디코더 구현하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VYMefdner-B"
      },
      "source": [
        "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Inputs(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "\n",
        "  # 룩어헤드 마스크(첫번째 서브층)\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\"\n",
        "  )\n",
        "\n",
        "  # 패딩 마스크(두번째 서브층)\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention=1\")(inputs={\n",
        "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
        "      })\n",
        "  \n",
        "  # 잔차 연결과 층 정규화\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1+inputs)\n",
        "    \n",
        "  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
        "  attention2 = MultiHeadAttnetion(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q!= K = V\n",
        "          'mask': padding_mask # 패딩 마스크\n",
        "      })\n",
        "  \n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.kayers.LayerNormatlization(epsilon=1e-6)(\n",
        "      attention2 + attention1)\n",
        "  \n",
        "  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJLAYccjevl0"
      },
      "source": [
        "* 디코더는 총 세 개의 서브층\n",
        "  * 첫 번째와 두 번째 서브층 모두 멀티 헤드 어텐션이지만, 첫 번째 서브층은 mask의 인자값으로 look_ahead_mask가 들어가는 반면, 두 번째 서브층은 mask의 인자값으로 padding_mask가 들어가는 것을 확인\n",
        "  * 이는 첫번째 서브층은 마스크드 셀프 어텐션을 수행하기 때문\n",
        "  * 세 개의 서브층 모두 서브층 연산 후에는 드롭 아웃, 잔차 연결, 층 정규화가 수행되는 것을 확인\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgIxPEZxfNcx"
      },
      "source": [
        "### 16. 디코더 쌓기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGR5S9OlfMar"
      },
      "source": [
        "def decoder(vocab_size, num_layers, dff, d_model, num_heads, dropout, name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None, ), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "\n",
        "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 포지셔널 인코딩 + 드롭아웃\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings = tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # 디코더를 num_layers개 쌓기\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "                            dropout=dropout, num='decoder_layer_{}'.format(i), \n",
        "                            )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "        outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nrqZAjdgZjj"
      },
      "source": [
        "### 17. 트랜스포머 구현하기\n",
        "* 지금까지 구현한 인코더와 디코더 함수를 조합하여 트랜스포머를 조립할 차례\n",
        "* 인코더의 출력은 디코더에서 인코더-디코더 어텐션에서 사용되기 위해 디코더로 전달\n",
        "* 그리도 디코더 끝단에는 다중 클래스 분류 문제를 풀 수 있도록 vocab_size 만큼의 뉴런을 가지는 신경망 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv-b3DongmNj"
      },
      "source": [
        "def transformer(vocab_size, num_layers, dff, d_model, num_heads, dropout, name=\"transformer\"):\n",
        "\n",
        "  # 인코더의 입력\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 디코더의 입력\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더의 패딩 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  \n",
        "  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
        "  look_ahead_mmask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1, None, None),\n",
        "      name = 'look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 디코더의 패딩 마스크(두번째 서브층)\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
        "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
        "\n",
        "  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
        "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 다음 단어 예측을 위한 출력층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ-4ldgkhKHl"
      },
      "source": [
        "### 18. 트랜스포머 하이퍼파라미터 정하기\n",
        "*임의로 9000의 단어 집합의 크기\n",
        "* 단어 집합의 크기로부터 룩업 테이블을 수행할 임베딩 테이블과 포지셔널 인코딩 행렬의 행의 크기 결정 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si20PQ2ihkxm"
      },
      "source": [
        "small_transformer = transformer(\n",
        "  vocab_size = 9000,\n",
        "  num_layers = 4,\n",
        "  dff = 512,\n",
        "  d_model = 128,\n",
        "  num_heads = 4,\n",
        "  dropout = 0.3,\n",
        "  name = \"small_transformer\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    small_transformer, to_file = 'small_transformer.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9KWh4bGhkBW"
      },
      "source": [
        "### 19. 손실 함수 정의하기\n",
        "* 다중 크래스 분류 문제를 풀 예정이므로 크로스 엔트로피 함수를 손실 함수로 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DePVErPLh0Y1"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH -1))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=Ture, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTLjvdUriNQL"
      },
      "source": [
        "### 20. 학습률\n",
        "* 트랜스포머의 경우 학습률(learning rate)은 고정된 값을 유지하는 것이 아니라, 학습 경과에 따라 변화도록 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlSlKRp_iTqd"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearingRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "  \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "    \n",
        "    return tf.math.rsqurt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxkYbfvli3P9"
      },
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(20000, dtype=tf.flaot32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabe(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}