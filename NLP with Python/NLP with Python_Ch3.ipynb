{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Processing Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 Accessing Text from the Web and fro Disk\n",
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n",
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176967"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization: Break up the string into words and punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(raw)\n",
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257085"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment',\n",
       " ',',\n",
       " 'by']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text = nltk.Text(tokens)\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'CHAPTER',\n",
       " 'I',\n",
       " 'On',\n",
       " 'an',\n",
       " 'exceptionally',\n",
       " 'hot',\n",
       " 'evening',\n",
       " 'early',\n",
       " 'in',\n",
       " 'July',\n",
       " 'a',\n",
       " 'young',\n",
       " 'man',\n",
       " 'came',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'garret',\n",
       " 'in',\n",
       " 'which',\n",
       " 'he',\n",
       " 'lodged',\n",
       " 'in',\n",
       " 'S.',\n",
       " 'Place',\n",
       " 'and',\n",
       " 'walked',\n",
       " 'slowly',\n",
       " ',',\n",
       " 'as',\n",
       " 'though',\n",
       " 'in',\n",
       " 'hesitation',\n",
       " ',',\n",
       " 'towards',\n",
       " 'K.',\n",
       " 'bridge']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1024:1062]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Ilya Petrovitch; Project\n",
      "Gutenberg; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5336"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find(\"PART I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reverse find\n",
    "raw.rfind(\"End of Project Gutenberg's Crime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = raw[5336:1157743]\n",
    "raw.find(\"PART I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dealing with HTML\n",
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = request.urlopen(url).read().decode('utf8')\n",
    "html[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BBC',\n",
       " 'NEWS',\n",
       " '|',\n",
       " 'Health',\n",
       " '|',\n",
       " 'Blondes',\n",
       " \"'to\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'in',\n",
       " '200',\n",
       " \"years'\",\n",
       " 'NEWS',\n",
       " 'SPORT',\n",
       " 'WEATHER',\n",
       " 'WORLD',\n",
       " 'SERVICE',\n",
       " 'A-Z',\n",
       " 'INDEX',\n",
       " 'SEARCH',\n",
       " 'You',\n",
       " 'are',\n",
       " 'in',\n",
       " ':',\n",
       " 'Health',\n",
       " 'News',\n",
       " 'Front',\n",
       " 'Page',\n",
       " 'Africa',\n",
       " 'Americas',\n",
       " 'Asia-Pacific',\n",
       " 'Europe',\n",
       " 'Middle',\n",
       " 'East',\n",
       " 'South',\n",
       " 'Asia',\n",
       " 'UK',\n",
       " 'Business',\n",
       " 'Entertainment',\n",
       " 'Science/Nature',\n",
       " 'Technology',\n",
       " 'Health',\n",
       " 'Medical',\n",
       " 'notes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Talking',\n",
       " 'Point',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Country',\n",
       " 'Profiles',\n",
       " 'In',\n",
       " 'Depth',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Programmes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'SERVICES',\n",
       " 'Daily',\n",
       " 'E-mail',\n",
       " 'News',\n",
       " 'Ticker',\n",
       " 'Mobile/PDAs',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Text',\n",
       " 'Only',\n",
       " 'Feedback',\n",
       " 'Help',\n",
       " 'EDITIONS',\n",
       " 'Change',\n",
       " 'to',\n",
       " 'UK',\n",
       " 'Friday',\n",
       " ',',\n",
       " '27',\n",
       " 'September',\n",
       " ',',\n",
       " '2002',\n",
       " ',',\n",
       " '11:51',\n",
       " 'GMT',\n",
       " '12:51',\n",
       " 'UK',\n",
       " 'Blondes',\n",
       " \"'to\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'in',\n",
       " '200',\n",
       " \"years'\",\n",
       " 'Scientists',\n",
       " 'believe',\n",
       " 'the',\n",
       " 'last',\n",
       " 'blondes',\n",
       " 'will',\n",
       " 'be',\n",
       " 'in',\n",
       " 'Finland',\n",
       " 'The',\n",
       " 'last',\n",
       " 'natural',\n",
       " 'blondes',\n",
       " 'will',\n",
       " 'die',\n",
       " 'out',\n",
       " 'within',\n",
       " '200',\n",
       " 'years',\n",
       " ',',\n",
       " 'scientists',\n",
       " 'believe',\n",
       " '.',\n",
       " 'A',\n",
       " 'study',\n",
       " 'by',\n",
       " 'experts',\n",
       " 'in',\n",
       " 'Germany',\n",
       " 'suggests',\n",
       " 'people',\n",
       " 'with',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " 'are',\n",
       " 'an',\n",
       " 'endangered',\n",
       " 'species',\n",
       " 'and',\n",
       " 'will',\n",
       " 'become',\n",
       " 'extinct',\n",
       " 'by',\n",
       " '2202',\n",
       " '.',\n",
       " 'Researchers',\n",
       " 'predict',\n",
       " 'the',\n",
       " 'last',\n",
       " 'truly',\n",
       " 'natural',\n",
       " 'blonde',\n",
       " 'will',\n",
       " 'be',\n",
       " 'born',\n",
       " 'in',\n",
       " 'Finland',\n",
       " '-',\n",
       " 'the',\n",
       " 'country',\n",
       " 'with',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'proportion',\n",
       " 'of',\n",
       " 'blondes',\n",
       " '.',\n",
       " 'The',\n",
       " 'frequency',\n",
       " 'of',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'drop',\n",
       " 'but',\n",
       " 'they',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " 'Prof',\n",
       " 'Jonathan',\n",
       " 'Rees',\n",
       " ',',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'But',\n",
       " 'they',\n",
       " 'say',\n",
       " 'too',\n",
       " 'few',\n",
       " 'people',\n",
       " 'now',\n",
       " 'carry',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'for',\n",
       " 'blondes',\n",
       " 'to',\n",
       " 'last',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'next',\n",
       " 'two',\n",
       " 'centuries',\n",
       " '.',\n",
       " 'The',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'that',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " 'is',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'a',\n",
       " 'recessive',\n",
       " 'gene',\n",
       " '.',\n",
       " 'In',\n",
       " 'order',\n",
       " 'for',\n",
       " 'a',\n",
       " 'child',\n",
       " 'to',\n",
       " 'have',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " ',',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'on',\n",
       " 'both',\n",
       " 'sides',\n",
       " 'of',\n",
       " 'the',\n",
       " 'family',\n",
       " 'in',\n",
       " 'the',\n",
       " 'grandparents',\n",
       " \"'\",\n",
       " 'generation',\n",
       " '.',\n",
       " 'Dyed',\n",
       " 'rivals',\n",
       " 'The',\n",
       " 'researchers',\n",
       " 'also',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'so-called',\n",
       " 'bottle',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'be',\n",
       " 'to',\n",
       " 'blame',\n",
       " 'for',\n",
       " 'the',\n",
       " 'demise',\n",
       " 'of',\n",
       " 'their',\n",
       " 'natural',\n",
       " 'rivals',\n",
       " '.',\n",
       " 'They',\n",
       " 'suggest',\n",
       " 'that',\n",
       " 'dyed-blondes',\n",
       " 'are',\n",
       " 'more',\n",
       " 'attractive',\n",
       " 'to',\n",
       " 'men',\n",
       " 'who',\n",
       " 'choose',\n",
       " 'them',\n",
       " 'as',\n",
       " 'partners',\n",
       " 'over',\n",
       " 'true',\n",
       " 'blondes',\n",
       " '.',\n",
       " 'Bottle-blondes',\n",
       " 'like',\n",
       " 'Ann',\n",
       " 'Widdecombe',\n",
       " 'may',\n",
       " 'be',\n",
       " 'to',\n",
       " 'blame',\n",
       " 'But',\n",
       " 'Jonathan',\n",
       " 'Rees',\n",
       " ',',\n",
       " 'professor',\n",
       " 'of',\n",
       " 'dermatology',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'said',\n",
       " 'it',\n",
       " 'was',\n",
       " 'unlikely',\n",
       " 'blondes',\n",
       " 'would',\n",
       " 'die',\n",
       " 'out',\n",
       " 'completely',\n",
       " '.',\n",
       " '``',\n",
       " 'Genes',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'unless',\n",
       " 'there',\n",
       " 'is',\n",
       " 'a',\n",
       " 'disadvantage',\n",
       " 'of',\n",
       " 'having',\n",
       " 'that',\n",
       " 'gene',\n",
       " 'or',\n",
       " 'by',\n",
       " 'chance',\n",
       " '.',\n",
       " 'They',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " ',',\n",
       " \"''\",\n",
       " 'he',\n",
       " 'told',\n",
       " 'BBC',\n",
       " 'News',\n",
       " 'Online',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'only',\n",
       " 'reason',\n",
       " 'blondes',\n",
       " 'would',\n",
       " 'disappear',\n",
       " 'is',\n",
       " 'if',\n",
       " 'having',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'was',\n",
       " 'a',\n",
       " 'disadvantage',\n",
       " 'and',\n",
       " 'I',\n",
       " 'do',\n",
       " 'not',\n",
       " 'think',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'case',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'frequency',\n",
       " 'of',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'drop',\n",
       " 'but',\n",
       " 'they',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " '.',\n",
       " \"''\",\n",
       " 'See',\n",
       " 'also',\n",
       " ':',\n",
       " '28',\n",
       " 'Mar',\n",
       " '01',\n",
       " '|',\n",
       " 'Education',\n",
       " 'What',\n",
       " 'is',\n",
       " 'it',\n",
       " 'about',\n",
       " 'blondes',\n",
       " '?',\n",
       " '09',\n",
       " 'Apr',\n",
       " '99',\n",
       " '|',\n",
       " 'Health',\n",
       " 'Platinum',\n",
       " 'blondes',\n",
       " 'are',\n",
       " 'labelled',\n",
       " 'as',\n",
       " 'dumb',\n",
       " '17',\n",
       " 'Apr',\n",
       " '02',\n",
       " '|',\n",
       " 'Health',\n",
       " 'Hair',\n",
       " 'dye',\n",
       " 'cancer',\n",
       " 'alert',\n",
       " 'Internet',\n",
       " 'links',\n",
       " ':',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'The',\n",
       " 'BBC',\n",
       " 'is',\n",
       " 'not',\n",
       " 'responsible',\n",
       " 'for',\n",
       " 'the',\n",
       " 'content',\n",
       " 'of',\n",
       " 'external',\n",
       " 'internet',\n",
       " 'sites',\n",
       " 'Top',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'now',\n",
       " ':',\n",
       " 'Heart',\n",
       " 'risk',\n",
       " 'link',\n",
       " 'to',\n",
       " 'big',\n",
       " 'families',\n",
       " 'Back',\n",
       " 'pain',\n",
       " 'drug',\n",
       " \"'may\",\n",
       " 'aid',\n",
       " \"diabetics'\",\n",
       " 'Congo',\n",
       " 'Ebola',\n",
       " 'outbreak',\n",
       " 'confirmed',\n",
       " 'Vegetables',\n",
       " 'ward',\n",
       " 'off',\n",
       " \"Alzheimer's\",\n",
       " 'Polio',\n",
       " 'campaign',\n",
       " 'launched',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'Gene',\n",
       " 'defect',\n",
       " 'explains',\n",
       " 'high',\n",
       " 'blood',\n",
       " 'pressure',\n",
       " 'Botox',\n",
       " \"'may\",\n",
       " 'cause',\n",
       " 'new',\n",
       " \"wrinkles'\",\n",
       " 'Alien',\n",
       " \"'abductees\",\n",
       " \"'\",\n",
       " 'show',\n",
       " 'real',\n",
       " 'symptoms',\n",
       " 'Links',\n",
       " 'to',\n",
       " 'more',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'are',\n",
       " 'at',\n",
       " 'the',\n",
       " 'foot',\n",
       " 'of',\n",
       " 'the',\n",
       " 'page',\n",
       " '.',\n",
       " 'E-mail',\n",
       " 'this',\n",
       " 'story',\n",
       " 'to',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'Links',\n",
       " 'to',\n",
       " 'more',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'In',\n",
       " 'This',\n",
       " 'Section',\n",
       " 'Heart',\n",
       " 'risk',\n",
       " 'link',\n",
       " 'to',\n",
       " 'big',\n",
       " 'families',\n",
       " 'Back',\n",
       " 'pain',\n",
       " 'drug',\n",
       " \"'may\",\n",
       " 'aid',\n",
       " \"diabetics'\",\n",
       " 'Congo',\n",
       " 'Ebola',\n",
       " 'outbreak',\n",
       " 'confirmed',\n",
       " 'Vegetables',\n",
       " 'ward',\n",
       " 'off',\n",
       " \"Alzheimer's\",\n",
       " 'Polio',\n",
       " 'campaign',\n",
       " 'launched',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'Gene',\n",
       " 'defect',\n",
       " 'explains',\n",
       " 'high',\n",
       " 'blood',\n",
       " 'pressure',\n",
       " 'Botox',\n",
       " \"'may\",\n",
       " 'cause',\n",
       " 'new',\n",
       " \"wrinkles'\",\n",
       " 'Alien',\n",
       " \"'abductees\",\n",
       " \"'\",\n",
       " 'show',\n",
       " 'real',\n",
       " 'symptoms',\n",
       " 'How',\n",
       " 'sperm',\n",
       " 'wriggle',\n",
       " 'Bollywood',\n",
       " 'told',\n",
       " 'to',\n",
       " 'stub',\n",
       " 'it',\n",
       " 'out',\n",
       " 'Fears',\n",
       " 'over',\n",
       " 'tuna',\n",
       " 'health',\n",
       " 'risk',\n",
       " 'to',\n",
       " 'babies',\n",
       " 'Public',\n",
       " 'can',\n",
       " 'be',\n",
       " 'taught',\n",
       " 'to',\n",
       " 'spot',\n",
       " 'strokes',\n",
       " '^^',\n",
       " 'Back',\n",
       " 'to',\n",
       " 'top',\n",
       " 'News',\n",
       " 'Front',\n",
       " 'Page',\n",
       " '|',\n",
       " 'Africa',\n",
       " '|',\n",
       " 'Americas',\n",
       " '|',\n",
       " 'Asia-Pacific',\n",
       " '|',\n",
       " 'Europe',\n",
       " '|',\n",
       " 'Middle',\n",
       " 'East',\n",
       " '|',\n",
       " 'South',\n",
       " 'Asia',\n",
       " '|',\n",
       " 'UK',\n",
       " '|',\n",
       " 'Business',\n",
       " '|',\n",
       " 'Entertainment',\n",
       " '|',\n",
       " 'Science/Nature',\n",
       " '|',\n",
       " 'Technology',\n",
       " '|',\n",
       " 'Health',\n",
       " '|',\n",
       " 'Talking',\n",
       " 'Point',\n",
       " '|',\n",
       " 'Country',\n",
       " 'Profiles',\n",
       " '|',\n",
       " 'In',\n",
       " 'Depth',\n",
       " '|',\n",
       " 'Programmes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'Sport',\n",
       " '>',\n",
       " '>',\n",
       " '|',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'Weather',\n",
       " '>',\n",
       " '>',\n",
       " '|',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'World',\n",
       " 'Service',\n",
       " '>',\n",
       " '>',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '©',\n",
       " 'MMIII',\n",
       " '|',\n",
       " 'News',\n",
       " 'Sources',\n",
       " '|',\n",
       " 'Privacy']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get text ouf HTML\n",
    "from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup(html, 'html.parser').get_text()\n",
    "tokens = word_tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n"
     ]
    }
   ],
   "source": [
    "tokens = tokens[110:390]\n",
    "text = nltk.Text(tokens)\n",
    "text.concordance('gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Language Log'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing Search Engine Results\n",
    "# Processing RSS Feeds\n",
    "# Universal Feed Parser\n",
    "import feedparser\n",
    "llog = feedparser.parse(\"http://languagelog.ldc.upenn.edu/nll/?feed=atom\")\n",
    "llog['feed']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llog.entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Garden of Morning Calm'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = llog.entries[2]\n",
    "post.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p style=\"text-align: center;\">[This is a guest post by S. Robert Rams'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = post.content[0].value\n",
    "content[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'guest',\n",
       " 'post',\n",
       " 'by',\n",
       " 'S.',\n",
       " 'Robert',\n",
       " 'Ramsey',\n",
       " ']',\n",
       " 'You',\n",
       " '’',\n",
       " 've',\n",
       " 'probably',\n",
       " 'heard',\n",
       " 'Korea',\n",
       " 'referred',\n",
       " 'to',\n",
       " 'as',\n",
       " 'the',\n",
       " '“',\n",
       " 'Land',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Morning',\n",
       " 'Calm.',\n",
       " '”',\n",
       " 'That',\n",
       " '’',\n",
       " 's',\n",
       " 'a',\n",
       " 'nickname',\n",
       " 'for',\n",
       " 'Korea',\n",
       " 'that',\n",
       " '’',\n",
       " 's',\n",
       " 'been',\n",
       " 'used',\n",
       " 'in',\n",
       " 'the',\n",
       " 'West',\n",
       " 'at',\n",
       " 'least',\n",
       " 'since',\n",
       " 'the',\n",
       " '19th',\n",
       " 'century',\n",
       " '.',\n",
       " 'And',\n",
       " 'perhaps',\n",
       " 'because',\n",
       " 'Koreans',\n",
       " 'agree',\n",
       " 'that',\n",
       " '“',\n",
       " 'Morning',\n",
       " 'Calm',\n",
       " '”',\n",
       " 'sounds',\n",
       " 'mystical',\n",
       " 'and',\n",
       " 'romantic',\n",
       " ',',\n",
       " 'it',\n",
       " '’',\n",
       " 's',\n",
       " 'been',\n",
       " 'picked',\n",
       " 'up',\n",
       " 'lately—often',\n",
       " 'for',\n",
       " 'commercial',\n",
       " 'purposes—in',\n",
       " 'South',\n",
       " 'Korea',\n",
       " ',',\n",
       " 'too',\n",
       " '.',\n",
       " 'Korean',\n",
       " 'Airlines',\n",
       " ',',\n",
       " 'for',\n",
       " 'example',\n",
       " ',',\n",
       " 'has',\n",
       " 'frequent',\n",
       " 'flier',\n",
       " 'perks',\n",
       " 'for',\n",
       " 'members',\n",
       " 'of',\n",
       " 'its',\n",
       " '“',\n",
       " 'Morning',\n",
       " 'Calm',\n",
       " 'Club.',\n",
       " '”',\n",
       " 'In',\n",
       " '1996',\n",
       " ',',\n",
       " 'an',\n",
       " 'arboretum',\n",
       " 'east',\n",
       " 'of',\n",
       " 'Seoul',\n",
       " 'was',\n",
       " 'given',\n",
       " 'the',\n",
       " 'name',\n",
       " ',',\n",
       " '“',\n",
       " 'Garden',\n",
       " 'of',\n",
       " 'Morning',\n",
       " 'Calm.',\n",
       " '”',\n",
       " 'But',\n",
       " 'the',\n",
       " 'nickname',\n",
       " 'is',\n",
       " 'a',\n",
       " 'chimera',\n",
       " ',',\n",
       " 'the',\n",
       " 'result',\n",
       " 'of',\n",
       " 'a',\n",
       " 'mistake—and',\n",
       " 'probably',\n",
       " 'one',\n",
       " 'made',\n",
       " 'by',\n",
       " 'some',\n",
       " 'starry-eyed',\n",
       " 'Westerner',\n",
       " 'infatuated',\n",
       " 'by',\n",
       " 'the',\n",
       " 'mysterious',\n",
       " 'Orient',\n",
       " '.',\n",
       " '‘',\n",
       " 'Morning',\n",
       " 'Calm',\n",
       " '’',\n",
       " 'is',\n",
       " 'a',\n",
       " 'mistranslation',\n",
       " 'of',\n",
       " 'an',\n",
       " 'ancient',\n",
       " 'name',\n",
       " 'for',\n",
       " 'Korea',\n",
       " ',',\n",
       " 'a',\n",
       " 'name',\n",
       " 'known',\n",
       " 'only',\n",
       " 'from',\n",
       " 'ancient',\n",
       " 'Chinese',\n",
       " 'records',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " '1st',\n",
       " 'century',\n",
       " 'B.C.',\n",
       " ',',\n",
       " 'when',\n",
       " 'Chinese',\n",
       " 'ethnographers',\n",
       " 'were',\n",
       " 'exploring',\n",
       " 'the',\n",
       " 'Korean',\n",
       " 'peninsula',\n",
       " ',',\n",
       " 'they',\n",
       " 'heard',\n",
       " 'a',\n",
       " 'name',\n",
       " 'that',\n",
       " 'local',\n",
       " 'people',\n",
       " 'were',\n",
       " 'using',\n",
       " '.',\n",
       " 'The',\n",
       " 'Chinese',\n",
       " 'visitors',\n",
       " 'didn',\n",
       " '’',\n",
       " 't',\n",
       " 'know',\n",
       " 'who',\n",
       " 'those',\n",
       " 'exotic',\n",
       " 'local',\n",
       " 'people',\n",
       " 'were',\n",
       " ',',\n",
       " 'or',\n",
       " 'what',\n",
       " 'language',\n",
       " 'they',\n",
       " 'were',\n",
       " 'speaking',\n",
       " ',',\n",
       " 'much',\n",
       " 'less',\n",
       " 'what',\n",
       " 'the',\n",
       " 'word',\n",
       " 'meant',\n",
       " '.',\n",
       " 'As',\n",
       " 'ethnographers',\n",
       " ',',\n",
       " 'they',\n",
       " 'simply',\n",
       " 'recorded',\n",
       " 'the',\n",
       " 'word',\n",
       " 'they',\n",
       " 'heard',\n",
       " 'by',\n",
       " 'using',\n",
       " 'the',\n",
       " 'sounds',\n",
       " 'of',\n",
       " 'their',\n",
       " 'own',\n",
       " 'Chinese',\n",
       " 'characters',\n",
       " 'as',\n",
       " 'phonetic',\n",
       " 'notations—just',\n",
       " 'the',\n",
       " 'way',\n",
       " 'Chinese',\n",
       " 'speakers',\n",
       " 'transcribe',\n",
       " 'foreign',\n",
       " 'words',\n",
       " 'even',\n",
       " 'today',\n",
       " '.',\n",
       " 'The',\n",
       " 'characters',\n",
       " 'they',\n",
       " 'transcribed',\n",
       " 'the',\n",
       " 'name',\n",
       " 'with',\n",
       " '朝鮮',\n",
       " 'had',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'meanings',\n",
       " '.',\n",
       " 'Since',\n",
       " 'the',\n",
       " 'Chinese',\n",
       " 'were',\n",
       " 'using',\n",
       " 'the',\n",
       " 'characters',\n",
       " 'only',\n",
       " 'to',\n",
       " 'represent',\n",
       " 'sounds',\n",
       " ',',\n",
       " 'we',\n",
       " 'have',\n",
       " 'no',\n",
       " 'way',\n",
       " 'to',\n",
       " 'know',\n",
       " 'from',\n",
       " 'those',\n",
       " 'characters',\n",
       " 'what',\n",
       " 'the',\n",
       " 'mysterious',\n",
       " ',',\n",
       " 'ancient',\n",
       " 'name',\n",
       " 'ever',\n",
       " 'meant',\n",
       " '.',\n",
       " 'Besides',\n",
       " ',',\n",
       " 'the',\n",
       " 'two',\n",
       " 'characters',\n",
       " 'they',\n",
       " 'used',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'mean',\n",
       " '‘',\n",
       " 'Morning',\n",
       " 'Calm',\n",
       " '’',\n",
       " 'anyway',\n",
       " '!',\n",
       " 'In',\n",
       " 'the',\n",
       " 'Chinese-language',\n",
       " 'reading',\n",
       " 'of',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'Korea',\n",
       " '(',\n",
       " 'Cháoxiăn',\n",
       " ')',\n",
       " ',',\n",
       " 'the',\n",
       " 'first',\n",
       " 'character',\n",
       " 'can',\n",
       " '’',\n",
       " 't',\n",
       " 'mean',\n",
       " '‘',\n",
       " 'morning',\n",
       " '’',\n",
       " '(',\n",
       " 'the',\n",
       " 'reading',\n",
       " 'can',\n",
       " 'only',\n",
       " 'be',\n",
       " 'associated',\n",
       " 'with',\n",
       " '‘',\n",
       " 'tide',\n",
       " '’',\n",
       " 'or',\n",
       " '‘',\n",
       " 'court',\n",
       " '’',\n",
       " ')',\n",
       " '.',\n",
       " 'The',\n",
       " 'second',\n",
       " 'character',\n",
       " 'is',\n",
       " 'even',\n",
       " 'farther',\n",
       " 'away',\n",
       " '.',\n",
       " 'It',\n",
       " 'means',\n",
       " '‘',\n",
       " 'rare',\n",
       " ',',\n",
       " 'few',\n",
       " ',',\n",
       " 'seldom',\n",
       " '’',\n",
       " ';',\n",
       " 'and',\n",
       " 'never',\n",
       " '‘',\n",
       " 'calm',\n",
       " '’',\n",
       " '.',\n",
       " '[',\n",
       " 'The',\n",
       " 'readings',\n",
       " 'given',\n",
       " 'here',\n",
       " 'are',\n",
       " 'of',\n",
       " 'course',\n",
       " 'those',\n",
       " 'of',\n",
       " 'modern',\n",
       " 'Mandarin',\n",
       " ',',\n",
       " 'but',\n",
       " 'the',\n",
       " 'phonological',\n",
       " 'distinctions',\n",
       " 'they',\n",
       " 'represent',\n",
       " 'are',\n",
       " 'reflected',\n",
       " 'in',\n",
       " 'early',\n",
       " 'riming',\n",
       " 'dictionaries',\n",
       " '.',\n",
       " ']',\n",
       " 'Nevertheless',\n",
       " ',',\n",
       " 'despite',\n",
       " 'the',\n",
       " 'mystery',\n",
       " ',',\n",
       " 'that',\n",
       " 'most',\n",
       " 'ancient',\n",
       " 'of',\n",
       " 'Korean',\n",
       " 'names',\n",
       " 'still',\n",
       " 'endures',\n",
       " 'today',\n",
       " ',',\n",
       " 'preserved',\n",
       " 'through',\n",
       " 'the',\n",
       " 'Korean-style',\n",
       " 'readings',\n",
       " 'of',\n",
       " 'the',\n",
       " 'characters',\n",
       " '.',\n",
       " 'Thus',\n",
       " ',',\n",
       " '“',\n",
       " '조선',\n",
       " '”',\n",
       " '(',\n",
       " '“',\n",
       " 'Choson',\n",
       " '”',\n",
       " ')',\n",
       " 'is',\n",
       " 'now',\n",
       " 'the',\n",
       " 'North',\n",
       " 'Korean',\n",
       " 'name',\n",
       " 'of',\n",
       " 'the',\n",
       " 'country',\n",
       " ';',\n",
       " 'and',\n",
       " ',',\n",
       " 'as',\n",
       " 'a',\n",
       " 'traditional',\n",
       " 'name',\n",
       " ',',\n",
       " 'it',\n",
       " '’',\n",
       " 's',\n",
       " 'used',\n",
       " 'in',\n",
       " 'South',\n",
       " 'Korea',\n",
       " 'as',\n",
       " 'well',\n",
       " '.',\n",
       " 'Afterword',\n",
       " 'The',\n",
       " 'whole',\n",
       " 'business',\n",
       " 'is',\n",
       " 'just',\n",
       " 'another',\n",
       " 'instance',\n",
       " 'of',\n",
       " 'how',\n",
       " 'the',\n",
       " 'old',\n",
       " 'mythology',\n",
       " 'about',\n",
       " 'Chinese',\n",
       " 'characters',\n",
       " 'invariably',\n",
       " 'leads',\n",
       " 'people',\n",
       " 'down',\n",
       " 'the',\n",
       " 'garden',\n",
       " 'path',\n",
       " '!',\n",
       " 'Even',\n",
       " 'so',\n",
       " ',',\n",
       " 'no',\n",
       " 'matter',\n",
       " 'how',\n",
       " 'bogus',\n",
       " 'it',\n",
       " 'may',\n",
       " 'be',\n",
       " ',',\n",
       " 'Koreans',\n",
       " 'obsess',\n",
       " 'over',\n",
       " 'that',\n",
       " \"'morning\",\n",
       " 'calm',\n",
       " \"'\",\n",
       " 'nonsense',\n",
       " '.',\n",
       " 'Heck',\n",
       " ',',\n",
       " 'we',\n",
       " 'have',\n",
       " 'no',\n",
       " 'idea',\n",
       " 'if',\n",
       " 'what',\n",
       " 'those',\n",
       " 'Chinese',\n",
       " 'explorers',\n",
       " 'heard',\n",
       " 'was',\n",
       " 'a',\n",
       " 'language',\n",
       " 'ancestral',\n",
       " 'to',\n",
       " 'modern',\n",
       " 'Korean',\n",
       " ',',\n",
       " 'anyway',\n",
       " '!',\n",
       " '(',\n",
       " 'It',\n",
       " 'sure',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'been',\n",
       " 'something',\n",
       " 'that',\n",
       " 'should',\n",
       " 'be',\n",
       " 'called',\n",
       " '``',\n",
       " 'Korean',\n",
       " \"''\",\n",
       " 'at',\n",
       " 'that',\n",
       " 'early',\n",
       " 'time',\n",
       " '.',\n",
       " ')',\n",
       " 'In',\n",
       " 'any',\n",
       " 'case',\n",
       " ',',\n",
       " 'in',\n",
       " 'later',\n",
       " 'eras',\n",
       " 'Koreans',\n",
       " \"'\",\n",
       " 'traditional',\n",
       " 'mythology',\n",
       " 'picked',\n",
       " 'up',\n",
       " 'on',\n",
       " 'what',\n",
       " 'was',\n",
       " 'recorded',\n",
       " 'in',\n",
       " 'those',\n",
       " 'Chinese',\n",
       " 'annals',\n",
       " ',',\n",
       " 'saying',\n",
       " 'that',\n",
       " 'the',\n",
       " 'ancestor',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Korean',\n",
       " 'people',\n",
       " ',',\n",
       " '``',\n",
       " 'Dangun',\n",
       " \"''\",\n",
       " '(',\n",
       " 'you',\n",
       " 'know',\n",
       " ',',\n",
       " 'the',\n",
       " 'guy',\n",
       " 'who',\n",
       " 'was',\n",
       " 'sired',\n",
       " 'by',\n",
       " 'a',\n",
       " 'god',\n",
       " 'and',\n",
       " 'born',\n",
       " 'from',\n",
       " 'a',\n",
       " 'bear',\n",
       " ')',\n",
       " 'founded',\n",
       " 'Joseon',\n",
       " '(',\n",
       " 'now',\n",
       " 'known',\n",
       " 'as',\n",
       " \"'Old\",\n",
       " \"'\",\n",
       " 'Joseon',\n",
       " '고조선',\n",
       " ',',\n",
       " 'since',\n",
       " \"'Joseon\",\n",
       " \"'\",\n",
       " 'was',\n",
       " 'the',\n",
       " 'name',\n",
       " 'chosen',\n",
       " 'by',\n",
       " 'the',\n",
       " 'last',\n",
       " 'royal',\n",
       " 'dynasty',\n",
       " 'for',\n",
       " 'their',\n",
       " 'state',\n",
       " ')',\n",
       " '.',\n",
       " 'And',\n",
       " ',',\n",
       " 'I',\n",
       " 'mean',\n",
       " ',',\n",
       " 'Koreans',\n",
       " 'still',\n",
       " 'look',\n",
       " 'everywhere',\n",
       " ',',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'find',\n",
       " 'some',\n",
       " 'ancient',\n",
       " 'word',\n",
       " 'from',\n",
       " 'Korean',\n",
       " 'or',\n",
       " 'Altaic–or',\n",
       " 'anywhere',\n",
       " '!',\n",
       " '–for',\n",
       " \"'morning\",\n",
       " \"'\",\n",
       " 'that',\n",
       " 'might',\n",
       " 'fit',\n",
       " ',',\n",
       " 'not',\n",
       " 'realizing',\n",
       " 'that',\n",
       " 'the',\n",
       " 'Chinese',\n",
       " 'reading',\n",
       " 'of',\n",
       " '朝鮮',\n",
       " 'shows',\n",
       " 'it',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'be',\n",
       " 'about',\n",
       " \"'morning\",\n",
       " \"'\",\n",
       " 'or',\n",
       " \"'calm\",\n",
       " \"'\",\n",
       " '.',\n",
       " 'To',\n",
       " 'add',\n",
       " 'to',\n",
       " 'Koreans',\n",
       " \"'\",\n",
       " 'discomfort',\n",
       " ',',\n",
       " 'some',\n",
       " 'wags',\n",
       " 'have',\n",
       " 'also',\n",
       " 'pointed',\n",
       " 'out',\n",
       " 'that',\n",
       " 'the',\n",
       " 'Western',\n",
       " 'interpretation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'name',\n",
       " 'as',\n",
       " \"'Land\",\n",
       " 'of',\n",
       " 'the',\n",
       " 'Morning',\n",
       " 'Calm',\n",
       " \"'\",\n",
       " 'was',\n",
       " 'almost',\n",
       " 'certainly',\n",
       " 'created',\n",
       " 'to',\n",
       " 'parallel',\n",
       " 'the',\n",
       " 'sobriquet',\n",
       " \"'Land\",\n",
       " 'of',\n",
       " 'the',\n",
       " 'Rising',\n",
       " 'Sun',\n",
       " \"'\",\n",
       " 'used',\n",
       " 'when',\n",
       " 'they',\n",
       " 'were',\n",
       " 'referring',\n",
       " 'to',\n",
       " 'Japan',\n",
       " '.',\n",
       " 'That',\n",
       " 'idea',\n",
       " 'particularly',\n",
       " 'galls',\n",
       " 'Koreans',\n",
       " ',',\n",
       " 'of',\n",
       " 'course',\n",
       " '.',\n",
       " 'Selected',\n",
       " 'readings',\n",
       " \"''\",\n",
       " 'Cho-Sen',\n",
       " 'Garden',\n",
       " \"''\",\n",
       " '(',\n",
       " '2/5/13',\n",
       " ')',\n",
       " \"''\",\n",
       " 'No',\n",
       " 'Japanese',\n",
       " ',',\n",
       " 'South',\n",
       " 'Koreans',\n",
       " ',',\n",
       " 'or',\n",
       " 'dogs',\n",
       " \"''\",\n",
       " '(',\n",
       " '3/8/17',\n",
       " ')',\n",
       " \"''\",\n",
       " 'From',\n",
       " 'the',\n",
       " 'British',\n",
       " 'royal',\n",
       " 'big',\n",
       " 'breast',\n",
       " 'secret',\n",
       " 'bookcase',\n",
       " \"''\",\n",
       " '(',\n",
       " '5/30/12',\n",
       " ')',\n",
       " '—',\n",
       " 'especially',\n",
       " 'in',\n",
       " 'this',\n",
       " 'comment']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = BeautifulSoup(content, 'html.parser').get_text()\n",
    "word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Local Files\n",
    "f = open('document.txt')\n",
    "raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('.')\n",
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also read a file one line at a time by using for loop\n",
    "f = open('document.txt', 'rU')\n",
    "for line in f:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "path = nltk.data.find('corpora/gutenberg/melville-moby_dick.txt')\n",
    "raw = open(path, 'rU').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some text: On an exceptionally hot evening early in July\n"
     ]
    }
   ],
   "source": [
    "# Extracting Text from PDF, MSWord and other Binary Formats\n",
    "# Capturing User Input\n",
    "s = input(\"Enter some text: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You typed 8 words.\n"
     ]
    }
   ],
   "source": [
    "print(\"You typed\", len(word_tokenize(s)), \"words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2 Strings: Text Processing at the Lowest Level\n",
    "# Basic operations with strings\n",
    "monty = 'Monty Python'\n",
    "monty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Monty Python's Flying Circus\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circus = \"Monty Python's Flying Circus\"\n",
    "circus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-b5a5bc20944b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-38-b5a5bc20944b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    circus = 'Monty Python's Flying Circus'\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "circus = 'Monty Python's Flying Circus'\n",
    "circus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a Summer's day?Thou are more lovely and more temperate:\n"
     ]
    }
   ],
   "source": [
    "couplet = \"Shall I compare thee to a Summer's day?\"\\\n",
    "          \"Thou are more lovely and more temperate:\"\n",
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rough winds do shake the darling buds of May,And Summer's lease hath all too short a date:\n"
     ]
    }
   ],
   "source": [
    "couplet=(\"Rough winds do shake the darling buds of May,\"\n",
    "        \"And Summer's lease hath all too short a date:\")\n",
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a Summer's day?\n",
      "Thou are more lovely and more temperate:\n"
     ]
    }
   ],
   "source": [
    "couplet = \"\"\"Shall I compare thee to a Summer's day?\n",
    "Thou are more lovely and more temperate:\"\"\"\n",
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rough winds do shake the darling buds of May,\n",
      "And Summer's lease hath all too short a date:\n"
     ]
    }
   ],
   "source": [
    "couplet = '''Rough winds do shake the darling buds of May,\n",
    "And Summer's lease hath all too short a date:'''\n",
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'veryveryvery'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'very' + 'very' + 'very'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'veryveryvery'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'very' * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty Python\n"
     ]
    }
   ],
   "source": [
    "# Printing Strings\n",
    "print(monty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
