{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "colab_04-06_Sonar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTey5pt8BVx6"
      },
      "source": [
        "# **13장 과적합 피하기**\n",
        "\n",
        "1988년 존스홉킨스대학교의 세즈노프스키 교수는 2년 전 힌튼 교수가 발표한 역전파 알고리즘에 관심을 가지고 있었습니다. 그는 은닉층과 역전파가 얼마나 큰 효과가 있는지를 직접 실험해보고 싶었습니다. 광석과 일반 돌을 가져다 놓고 음파 탐지기를 쏜 후 그 결과를 데이터로 정리합니다. 오차 역전파 알고리즘을 사용한 신경망이 과연 얼마나 광석과 돌을 구분하는데 효과적인지 알아보기 위해서입니다.\n",
        "\n",
        "\n",
        "**과적합 피하기 위해서 train set과 test set으로 나누어서 진행합니다**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "H0q6n2JyDRv3",
        "outputId": "3182823e-9f60-4991-a1b8-1e3f25c05f3a"
      },
      "source": [
        "# 데이터 입력\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "my_data = 'sonar.csv'\n",
        "\n",
        "#본문에 맞는 텐서플로 버전을 선택합니다.\n",
        "!pip install -q tensorflow-gpu==1.15.0\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ebe6b066-e81e-4712-8eba-e136a1e93723\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ebe6b066-e81e-4712-8eba-e136a1e93723\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sonar.csv to sonar.csv\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 40kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 512kB 46.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 47.9MB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pstznxFBDU4R",
        "outputId": "fddbce33-63e0-4c28-d6ee-3ccc29d3b88a"
      },
      "source": [
        "# seed 값 설정\n",
        "numpy.random.seed(3)\n",
        "tf.compat.v1.set_random_seed(3)\n",
        "\n",
        "#데이터 적용\n",
        "df = pd.read_csv(my_data, header=None)\n",
        "\n",
        "# 데이터 개괄 보기\n",
        "print(df.info())\n",
        "\n",
        "# 데이터의 일부분 미리 보기\n",
        "print(df.head())\n",
        "\n",
        "#feature set은 61개, 데이터는 508개 밖에 없음\n",
        "#feature set에 비해 데이터수가 적음"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208 entries, 0 to 207\n",
            "Data columns (total 61 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       208 non-null    float64\n",
            " 1   1       208 non-null    float64\n",
            " 2   2       208 non-null    float64\n",
            " 3   3       208 non-null    float64\n",
            " 4   4       208 non-null    float64\n",
            " 5   5       208 non-null    float64\n",
            " 6   6       208 non-null    float64\n",
            " 7   7       208 non-null    float64\n",
            " 8   8       208 non-null    float64\n",
            " 9   9       208 non-null    float64\n",
            " 10  10      208 non-null    float64\n",
            " 11  11      208 non-null    float64\n",
            " 12  12      208 non-null    float64\n",
            " 13  13      208 non-null    float64\n",
            " 14  14      208 non-null    float64\n",
            " 15  15      208 non-null    float64\n",
            " 16  16      208 non-null    float64\n",
            " 17  17      208 non-null    float64\n",
            " 18  18      208 non-null    float64\n",
            " 19  19      208 non-null    float64\n",
            " 20  20      208 non-null    float64\n",
            " 21  21      208 non-null    float64\n",
            " 22  22      208 non-null    float64\n",
            " 23  23      208 non-null    float64\n",
            " 24  24      208 non-null    float64\n",
            " 25  25      208 non-null    float64\n",
            " 26  26      208 non-null    float64\n",
            " 27  27      208 non-null    float64\n",
            " 28  28      208 non-null    float64\n",
            " 29  29      208 non-null    float64\n",
            " 30  30      208 non-null    float64\n",
            " 31  31      208 non-null    float64\n",
            " 32  32      208 non-null    float64\n",
            " 33  33      208 non-null    float64\n",
            " 34  34      208 non-null    float64\n",
            " 35  35      208 non-null    float64\n",
            " 36  36      208 non-null    float64\n",
            " 37  37      208 non-null    float64\n",
            " 38  38      208 non-null    float64\n",
            " 39  39      208 non-null    float64\n",
            " 40  40      208 non-null    float64\n",
            " 41  41      208 non-null    float64\n",
            " 42  42      208 non-null    float64\n",
            " 43  43      208 non-null    float64\n",
            " 44  44      208 non-null    float64\n",
            " 45  45      208 non-null    float64\n",
            " 46  46      208 non-null    float64\n",
            " 47  47      208 non-null    float64\n",
            " 48  48      208 non-null    float64\n",
            " 49  49      208 non-null    float64\n",
            " 50  50      208 non-null    float64\n",
            " 51  51      208 non-null    float64\n",
            " 52  52      208 non-null    float64\n",
            " 53  53      208 non-null    float64\n",
            " 54  54      208 non-null    float64\n",
            " 55  55      208 non-null    float64\n",
            " 56  56      208 non-null    float64\n",
            " 57  57      208 non-null    float64\n",
            " 58  58      208 non-null    float64\n",
            " 59  59      208 non-null    float64\n",
            " 60  60      208 non-null    object \n",
            "dtypes: float64(60), object(1)\n",
            "memory usage: 99.2+ KB\n",
            "None\n",
            "       0       1       2       3       4   ...      56      57      58      59  60\n",
            "0  0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n",
            "1  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n",
            "2  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n",
            "3  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n",
            "4  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n",
            "\n",
            "[5 rows x 61 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SufbNi89pEHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87311c2a-3a6e-4b6c-f1db-af6faf3a03ed"
      },
      "source": [
        "dataset = df.values\n",
        "X = dataset[:,0:60]\n",
        "#X = numpy.asarray(X).astype(numpy, float32) #keras가 아닌 tensorflow.keras로 실행 시에 추가해야 하는 코드. 현재로서는 없어도 실행됨. \n",
        "Y_obj = dataset[:,60]\n",
        "\n",
        "# 문자열 변환\n",
        "e = LabelEncoder()\n",
        "e.fit(Y_obj)\n",
        "Y = e.transform(Y_obj)\n",
        "\n",
        "# 모델 설정\n",
        "model = Sequential()\n",
        "model.add(Dense(24,  input_dim=60, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='mean_squared_error',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# 모델 실행\n",
        "model.fit(X, Y, epochs=200, batch_size=5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 208 samples\n",
            "Epoch 1/200\n",
            "208/208 [==============================] - 0s 2ms/sample - loss: 0.2509 - acc: 0.5385\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 0s 345us/sample - loss: 0.2358 - acc: 0.6346\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 0s 280us/sample - loss: 0.2254 - acc: 0.6923\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 0s 288us/sample - loss: 0.2134 - acc: 0.7452\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 0s 292us/sample - loss: 0.2055 - acc: 0.7308\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 0s 247us/sample - loss: 0.1961 - acc: 0.7500\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 0s 311us/sample - loss: 0.1866 - acc: 0.7885\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 0s 290us/sample - loss: 0.1751 - acc: 0.8317\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 0s 294us/sample - loss: 0.1763 - acc: 0.7788\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 0s 343us/sample - loss: 0.1651 - acc: 0.7837\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 0s 268us/sample - loss: 0.1573 - acc: 0.8365\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 0s 324us/sample - loss: 0.1509 - acc: 0.8029\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 0s 322us/sample - loss: 0.1559 - acc: 0.7788\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 0s 274us/sample - loss: 0.1481 - acc: 0.8029\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 0s 279us/sample - loss: 0.1400 - acc: 0.8269\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 0s 284us/sample - loss: 0.1367 - acc: 0.8125\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 0s 304us/sample - loss: 0.1319 - acc: 0.8317\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 0s 249us/sample - loss: 0.1261 - acc: 0.8413\n",
            "Epoch 19/200\n",
            "208/208 [==============================] - 0s 269us/sample - loss: 0.1301 - acc: 0.8173\n",
            "Epoch 20/200\n",
            "208/208 [==============================] - 0s 269us/sample - loss: 0.1259 - acc: 0.8269\n",
            "Epoch 21/200\n",
            "208/208 [==============================] - 0s 331us/sample - loss: 0.1218 - acc: 0.8365\n",
            "Epoch 22/200\n",
            "208/208 [==============================] - 0s 343us/sample - loss: 0.1183 - acc: 0.8462\n",
            "Epoch 23/200\n",
            "208/208 [==============================] - 0s 306us/sample - loss: 0.1160 - acc: 0.8654\n",
            "Epoch 24/200\n",
            "208/208 [==============================] - 0s 299us/sample - loss: 0.1191 - acc: 0.8558\n",
            "Epoch 25/200\n",
            "208/208 [==============================] - 0s 356us/sample - loss: 0.1139 - acc: 0.8606\n",
            "Epoch 26/200\n",
            "208/208 [==============================] - 0s 326us/sample - loss: 0.1087 - acc: 0.8654\n",
            "Epoch 27/200\n",
            "208/208 [==============================] - 0s 316us/sample - loss: 0.1081 - acc: 0.8654\n",
            "Epoch 28/200\n",
            "208/208 [==============================] - 0s 307us/sample - loss: 0.1082 - acc: 0.8654\n",
            "Epoch 29/200\n",
            "208/208 [==============================] - 0s 312us/sample - loss: 0.1036 - acc: 0.8702\n",
            "Epoch 30/200\n",
            "208/208 [==============================] - 0s 320us/sample - loss: 0.1029 - acc: 0.8702\n",
            "Epoch 31/200\n",
            "208/208 [==============================] - 0s 349us/sample - loss: 0.0965 - acc: 0.8942\n",
            "Epoch 32/200\n",
            "208/208 [==============================] - 0s 273us/sample - loss: 0.1023 - acc: 0.8606\n",
            "Epoch 33/200\n",
            "208/208 [==============================] - 0s 309us/sample - loss: 0.0941 - acc: 0.9135\n",
            "Epoch 34/200\n",
            "208/208 [==============================] - 0s 356us/sample - loss: 0.0975 - acc: 0.8750\n",
            "Epoch 35/200\n",
            "208/208 [==============================] - 0s 321us/sample - loss: 0.0883 - acc: 0.8990\n",
            "Epoch 36/200\n",
            "208/208 [==============================] - 0s 320us/sample - loss: 0.0846 - acc: 0.9135\n",
            "Epoch 37/200\n",
            "208/208 [==============================] - 0s 315us/sample - loss: 0.0853 - acc: 0.9038\n",
            "Epoch 38/200\n",
            "208/208 [==============================] - 0s 355us/sample - loss: 0.0849 - acc: 0.9038\n",
            "Epoch 39/200\n",
            "208/208 [==============================] - 0s 319us/sample - loss: 0.0839 - acc: 0.9135\n",
            "Epoch 40/200\n",
            "208/208 [==============================] - 0s 339us/sample - loss: 0.0801 - acc: 0.9038\n",
            "Epoch 41/200\n",
            "208/208 [==============================] - 0s 301us/sample - loss: 0.0784 - acc: 0.9135\n",
            "Epoch 42/200\n",
            "208/208 [==============================] - 0s 300us/sample - loss: 0.0895 - acc: 0.8846\n",
            "Epoch 43/200\n",
            "208/208 [==============================] - 0s 293us/sample - loss: 0.0778 - acc: 0.9135\n",
            "Epoch 44/200\n",
            "208/208 [==============================] - 0s 306us/sample - loss: 0.0759 - acc: 0.9183\n",
            "Epoch 45/200\n",
            "208/208 [==============================] - 0s 336us/sample - loss: 0.0694 - acc: 0.9327\n",
            "Epoch 46/200\n",
            "208/208 [==============================] - 0s 381us/sample - loss: 0.0692 - acc: 0.9327\n",
            "Epoch 47/200\n",
            "208/208 [==============================] - 0s 298us/sample - loss: 0.0734 - acc: 0.9135\n",
            "Epoch 48/200\n",
            "208/208 [==============================] - 0s 285us/sample - loss: 0.0683 - acc: 0.9279\n",
            "Epoch 49/200\n",
            "208/208 [==============================] - 0s 288us/sample - loss: 0.0621 - acc: 0.9519\n",
            "Epoch 50/200\n",
            "208/208 [==============================] - 0s 338us/sample - loss: 0.0672 - acc: 0.9231\n",
            "Epoch 51/200\n",
            "208/208 [==============================] - 0s 323us/sample - loss: 0.0594 - acc: 0.9471\n",
            "Epoch 52/200\n",
            "208/208 [==============================] - 0s 344us/sample - loss: 0.0593 - acc: 0.9519\n",
            "Epoch 53/200\n",
            "208/208 [==============================] - 0s 317us/sample - loss: 0.0596 - acc: 0.9279\n",
            "Epoch 54/200\n",
            "208/208 [==============================] - 0s 416us/sample - loss: 0.0568 - acc: 0.9519\n",
            "Epoch 55/200\n",
            "208/208 [==============================] - 0s 327us/sample - loss: 0.0574 - acc: 0.9423\n",
            "Epoch 56/200\n",
            "208/208 [==============================] - 0s 276us/sample - loss: 0.0565 - acc: 0.9375\n",
            "Epoch 57/200\n",
            "208/208 [==============================] - 0s 279us/sample - loss: 0.0553 - acc: 0.9471\n",
            "Epoch 58/200\n",
            "208/208 [==============================] - 0s 286us/sample - loss: 0.0491 - acc: 0.9567\n",
            "Epoch 59/200\n",
            "208/208 [==============================] - 0s 328us/sample - loss: 0.0527 - acc: 0.9375\n",
            "Epoch 60/200\n",
            "208/208 [==============================] - 0s 296us/sample - loss: 0.0490 - acc: 0.9519\n",
            "Epoch 61/200\n",
            "208/208 [==============================] - 0s 247us/sample - loss: 0.0487 - acc: 0.9471\n",
            "Epoch 62/200\n",
            "208/208 [==============================] - 0s 248us/sample - loss: 0.0516 - acc: 0.9423\n",
            "Epoch 63/200\n",
            "208/208 [==============================] - 0s 305us/sample - loss: 0.0447 - acc: 0.9615\n",
            "Epoch 64/200\n",
            "208/208 [==============================] - 0s 362us/sample - loss: 0.0460 - acc: 0.9615\n",
            "Epoch 65/200\n",
            "208/208 [==============================] - 0s 312us/sample - loss: 0.0415 - acc: 0.9663\n",
            "Epoch 66/200\n",
            "208/208 [==============================] - 0s 292us/sample - loss: 0.0413 - acc: 0.9663\n",
            "Epoch 67/200\n",
            "208/208 [==============================] - 0s 255us/sample - loss: 0.0373 - acc: 0.9663\n",
            "Epoch 68/200\n",
            "208/208 [==============================] - 0s 305us/sample - loss: 0.0415 - acc: 0.9615\n",
            "Epoch 69/200\n",
            "208/208 [==============================] - 0s 348us/sample - loss: 0.0384 - acc: 0.9663\n",
            "Epoch 70/200\n",
            "208/208 [==============================] - 0s 317us/sample - loss: 0.0396 - acc: 0.9663\n",
            "Epoch 71/200\n",
            "208/208 [==============================] - 0s 294us/sample - loss: 0.0338 - acc: 0.9808\n",
            "Epoch 72/200\n",
            "208/208 [==============================] - 0s 310us/sample - loss: 0.0330 - acc: 0.9760\n",
            "Epoch 73/200\n",
            "208/208 [==============================] - 0s 280us/sample - loss: 0.0330 - acc: 0.9808\n",
            "Epoch 74/200\n",
            "208/208 [==============================] - 0s 270us/sample - loss: 0.0334 - acc: 0.9760\n",
            "Epoch 75/200\n",
            "208/208 [==============================] - 0s 362us/sample - loss: 0.0320 - acc: 0.9760\n",
            "Epoch 76/200\n",
            "208/208 [==============================] - 0s 329us/sample - loss: 0.0313 - acc: 0.9760\n",
            "Epoch 77/200\n",
            "208/208 [==============================] - 0s 313us/sample - loss: 0.0301 - acc: 0.9808\n",
            "Epoch 78/200\n",
            "208/208 [==============================] - 0s 269us/sample - loss: 0.0287 - acc: 0.9856\n",
            "Epoch 79/200\n",
            "208/208 [==============================] - 0s 272us/sample - loss: 0.0307 - acc: 0.9856\n",
            "Epoch 80/200\n",
            "208/208 [==============================] - 0s 292us/sample - loss: 0.0268 - acc: 0.9808\n",
            "Epoch 81/200\n",
            "208/208 [==============================] - 0s 348us/sample - loss: 0.0269 - acc: 0.9808\n",
            "Epoch 82/200\n",
            "208/208 [==============================] - 0s 314us/sample - loss: 0.0300 - acc: 0.9760\n",
            "Epoch 83/200\n",
            "208/208 [==============================] - 0s 281us/sample - loss: 0.0253 - acc: 0.9808\n",
            "Epoch 84/200\n",
            "208/208 [==============================] - 0s 309us/sample - loss: 0.0280 - acc: 0.9760\n",
            "Epoch 85/200\n",
            "208/208 [==============================] - 0s 303us/sample - loss: 0.0257 - acc: 0.9856\n",
            "Epoch 86/200\n",
            "208/208 [==============================] - 0s 352us/sample - loss: 0.0230 - acc: 0.9808\n",
            "Epoch 87/200\n",
            "208/208 [==============================] - 0s 278us/sample - loss: 0.0216 - acc: 0.9856\n",
            "Epoch 88/200\n",
            "208/208 [==============================] - 0s 280us/sample - loss: 0.0224 - acc: 0.9856\n",
            "Epoch 89/200\n",
            "208/208 [==============================] - 0s 285us/sample - loss: 0.0227 - acc: 0.9856\n",
            "Epoch 90/200\n",
            "208/208 [==============================] - 0s 289us/sample - loss: 0.0200 - acc: 0.9856\n",
            "Epoch 91/200\n",
            "208/208 [==============================] - 0s 336us/sample - loss: 0.0200 - acc: 0.9856\n",
            "Epoch 92/200\n",
            "208/208 [==============================] - 0s 308us/sample - loss: 0.0197 - acc: 0.9808\n",
            "Epoch 93/200\n",
            "208/208 [==============================] - 0s 300us/sample - loss: 0.0229 - acc: 0.9856\n",
            "Epoch 94/200\n",
            "208/208 [==============================] - 0s 267us/sample - loss: 0.0203 - acc: 0.9904\n",
            "Epoch 95/200\n",
            "208/208 [==============================] - 0s 309us/sample - loss: 0.0200 - acc: 0.9808\n",
            "Epoch 96/200\n",
            "208/208 [==============================] - 0s 293us/sample - loss: 0.0202 - acc: 0.9904\n",
            "Epoch 97/200\n",
            "208/208 [==============================] - 0s 256us/sample - loss: 0.0175 - acc: 0.9904\n",
            "Epoch 98/200\n",
            "208/208 [==============================] - 0s 296us/sample - loss: 0.0178 - acc: 0.9856\n",
            "Epoch 99/200\n",
            "208/208 [==============================] - 0s 327us/sample - loss: 0.0180 - acc: 0.9904\n",
            "Epoch 100/200\n",
            "208/208 [==============================] - 0s 342us/sample - loss: 0.0186 - acc: 0.9856\n",
            "Epoch 101/200\n",
            "208/208 [==============================] - 0s 299us/sample - loss: 0.0177 - acc: 0.9856\n",
            "Epoch 102/200\n",
            "208/208 [==============================] - 0s 289us/sample - loss: 0.0233 - acc: 0.9808\n",
            "Epoch 103/200\n",
            "208/208 [==============================] - 0s 313us/sample - loss: 0.0236 - acc: 0.9808\n",
            "Epoch 104/200\n",
            "208/208 [==============================] - 0s 336us/sample - loss: 0.0191 - acc: 0.9856\n",
            "Epoch 105/200\n",
            "208/208 [==============================] - 0s 305us/sample - loss: 0.0174 - acc: 0.9856\n",
            "Epoch 106/200\n",
            "208/208 [==============================] - 0s 311us/sample - loss: 0.0145 - acc: 0.9904\n",
            "Epoch 107/200\n",
            "208/208 [==============================] - 0s 311us/sample - loss: 0.0143 - acc: 0.9904\n",
            "Epoch 108/200\n",
            "208/208 [==============================] - 0s 315us/sample - loss: 0.0160 - acc: 0.9904\n",
            "Epoch 109/200\n",
            "208/208 [==============================] - 0s 257us/sample - loss: 0.0145 - acc: 0.9904\n",
            "Epoch 110/200\n",
            "208/208 [==============================] - 0s 320us/sample - loss: 0.0138 - acc: 0.9904\n",
            "Epoch 111/200\n",
            "208/208 [==============================] - 0s 333us/sample - loss: 0.0132 - acc: 0.9904\n",
            "Epoch 112/200\n",
            "208/208 [==============================] - 0s 280us/sample - loss: 0.0132 - acc: 0.9904\n",
            "Epoch 113/200\n",
            "208/208 [==============================] - 0s 330us/sample - loss: 0.0124 - acc: 0.9904\n",
            "Epoch 114/200\n",
            "208/208 [==============================] - 0s 314us/sample - loss: 0.0135 - acc: 0.9904\n",
            "Epoch 115/200\n",
            "208/208 [==============================] - 0s 331us/sample - loss: 0.0132 - acc: 0.9904\n",
            "Epoch 116/200\n",
            "208/208 [==============================] - 0s 304us/sample - loss: 0.0121 - acc: 0.9904\n",
            "Epoch 117/200\n",
            "208/208 [==============================] - 0s 328us/sample - loss: 0.0116 - acc: 0.9904\n",
            "Epoch 118/200\n",
            "208/208 [==============================] - 0s 316us/sample - loss: 0.0114 - acc: 0.9904\n",
            "Epoch 119/200\n",
            "208/208 [==============================] - 0s 293us/sample - loss: 0.0119 - acc: 0.9904\n",
            "Epoch 120/200\n",
            "208/208 [==============================] - 0s 315us/sample - loss: 0.0106 - acc: 0.9904\n",
            "Epoch 121/200\n",
            "208/208 [==============================] - 0s 319us/sample - loss: 0.0131 - acc: 0.9904\n",
            "Epoch 122/200\n",
            "208/208 [==============================] - 0s 315us/sample - loss: 0.0125 - acc: 0.9808\n",
            "Epoch 123/200\n",
            "208/208 [==============================] - 0s 296us/sample - loss: 0.0106 - acc: 0.9952\n",
            "Epoch 124/200\n",
            "208/208 [==============================] - 0s 289us/sample - loss: 0.0100 - acc: 0.9952\n",
            "Epoch 125/200\n",
            "208/208 [==============================] - 0s 373us/sample - loss: 0.0116 - acc: 0.9904\n",
            "Epoch 126/200\n",
            "208/208 [==============================] - 0s 319us/sample - loss: 0.0084 - acc: 0.9952\n",
            "Epoch 127/200\n",
            "208/208 [==============================] - 0s 322us/sample - loss: 0.0088 - acc: 0.9904\n",
            "Epoch 128/200\n",
            "208/208 [==============================] - 0s 346us/sample - loss: 0.0075 - acc: 0.9952\n",
            "Epoch 129/200\n",
            "208/208 [==============================] - 0s 323us/sample - loss: 0.0072 - acc: 0.9904\n",
            "Epoch 130/200\n",
            "208/208 [==============================] - 0s 402us/sample - loss: 0.0086 - acc: 0.9904\n",
            "Epoch 131/200\n",
            "208/208 [==============================] - 0s 317us/sample - loss: 0.0053 - acc: 1.0000\n",
            "Epoch 132/200\n",
            "208/208 [==============================] - 0s 324us/sample - loss: 0.0065 - acc: 0.9952\n",
            "Epoch 133/200\n",
            "208/208 [==============================] - 0s 349us/sample - loss: 0.0050 - acc: 1.0000\n",
            "Epoch 134/200\n",
            "208/208 [==============================] - 0s 332us/sample - loss: 0.0046 - acc: 1.0000\n",
            "Epoch 135/200\n",
            "208/208 [==============================] - 0s 310us/sample - loss: 0.0045 - acc: 1.0000\n",
            "Epoch 136/200\n",
            "208/208 [==============================] - 0s 302us/sample - loss: 0.0040 - acc: 1.0000\n",
            "Epoch 137/200\n",
            "208/208 [==============================] - 0s 324us/sample - loss: 0.0067 - acc: 0.9952\n",
            "Epoch 138/200\n",
            "208/208 [==============================] - 0s 310us/sample - loss: 0.0045 - acc: 1.0000\n",
            "Epoch 139/200\n",
            "208/208 [==============================] - 0s 280us/sample - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 140/200\n",
            "208/208 [==============================] - 0s 288us/sample - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 141/200\n",
            "208/208 [==============================] - 0s 352us/sample - loss: 0.0029 - acc: 1.0000\n",
            "Epoch 142/200\n",
            "208/208 [==============================] - 0s 372us/sample - loss: 0.0040 - acc: 1.0000\n",
            "Epoch 143/200\n",
            "208/208 [==============================] - 0s 318us/sample - loss: 0.0029 - acc: 1.0000\n",
            "Epoch 144/200\n",
            "208/208 [==============================] - 0s 317us/sample - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 145/200\n",
            "208/208 [==============================] - 0s 436us/sample - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 146/200\n",
            "208/208 [==============================] - 0s 340us/sample - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 147/200\n",
            "208/208 [==============================] - 0s 344us/sample - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 148/200\n",
            "208/208 [==============================] - 0s 304us/sample - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 149/200\n",
            "208/208 [==============================] - 0s 319us/sample - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 150/200\n",
            "208/208 [==============================] - 0s 321us/sample - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 151/200\n",
            "208/208 [==============================] - 0s 338us/sample - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 152/200\n",
            "208/208 [==============================] - 0s 321us/sample - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 153/200\n",
            "208/208 [==============================] - 0s 318us/sample - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 154/200\n",
            "208/208 [==============================] - 0s 304us/sample - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 155/200\n",
            "208/208 [==============================] - 0s 294us/sample - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 156/200\n",
            "208/208 [==============================] - 0s 368us/sample - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 157/200\n",
            "208/208 [==============================] - 0s 299us/sample - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 158/200\n",
            "208/208 [==============================] - 0s 306us/sample - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 159/200\n",
            "208/208 [==============================] - 0s 323us/sample - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 160/200\n",
            "208/208 [==============================] - 0s 292us/sample - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 161/200\n",
            "208/208 [==============================] - 0s 301us/sample - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 162/200\n",
            "208/208 [==============================] - 0s 358us/sample - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 163/200\n",
            "208/208 [==============================] - 0s 302us/sample - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 164/200\n",
            "208/208 [==============================] - 0s 289us/sample - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 165/200\n",
            "208/208 [==============================] - 0s 358us/sample - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 166/200\n",
            "208/208 [==============================] - 0s 319us/sample - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 167/200\n",
            "208/208 [==============================] - 0s 299us/sample - loss: 8.7023e-04 - acc: 1.0000\n",
            "Epoch 168/200\n",
            "208/208 [==============================] - 0s 351us/sample - loss: 8.9527e-04 - acc: 1.0000\n",
            "Epoch 169/200\n",
            "208/208 [==============================] - 0s 311us/sample - loss: 9.4730e-04 - acc: 1.0000\n",
            "Epoch 170/200\n",
            "208/208 [==============================] - 0s 315us/sample - loss: 8.5487e-04 - acc: 1.0000\n",
            "Epoch 171/200\n",
            "208/208 [==============================] - 0s 349us/sample - loss: 8.4950e-04 - acc: 1.0000\n",
            "Epoch 172/200\n",
            "208/208 [==============================] - 0s 329us/sample - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 173/200\n",
            "208/208 [==============================] - 0s 324us/sample - loss: 7.6031e-04 - acc: 1.0000\n",
            "Epoch 174/200\n",
            "208/208 [==============================] - 0s 348us/sample - loss: 8.6548e-04 - acc: 1.0000\n",
            "Epoch 175/200\n",
            "208/208 [==============================] - 0s 318us/sample - loss: 7.1589e-04 - acc: 1.0000\n",
            "Epoch 176/200\n",
            "208/208 [==============================] - 0s 337us/sample - loss: 7.1884e-04 - acc: 1.0000\n",
            "Epoch 177/200\n",
            "208/208 [==============================] - 0s 319us/sample - loss: 7.0337e-04 - acc: 1.0000\n",
            "Epoch 178/200\n",
            "208/208 [==============================] - 0s 306us/sample - loss: 6.9923e-04 - acc: 1.0000\n",
            "Epoch 179/200\n",
            "208/208 [==============================] - 0s 303us/sample - loss: 5.8963e-04 - acc: 1.0000\n",
            "Epoch 180/200\n",
            "208/208 [==============================] - 0s 342us/sample - loss: 6.6113e-04 - acc: 1.0000\n",
            "Epoch 181/200\n",
            "208/208 [==============================] - 0s 299us/sample - loss: 5.8240e-04 - acc: 1.0000\n",
            "Epoch 182/200\n",
            "208/208 [==============================] - 0s 301us/sample - loss: 6.2879e-04 - acc: 1.0000\n",
            "Epoch 183/200\n",
            "208/208 [==============================] - 0s 326us/sample - loss: 5.7094e-04 - acc: 1.0000\n",
            "Epoch 184/200\n",
            "208/208 [==============================] - 0s 353us/sample - loss: 6.1297e-04 - acc: 1.0000\n",
            "Epoch 185/200\n",
            "208/208 [==============================] - 0s 333us/sample - loss: 6.0915e-04 - acc: 1.0000\n",
            "Epoch 186/200\n",
            "208/208 [==============================] - 0s 320us/sample - loss: 5.2304e-04 - acc: 1.0000\n",
            "Epoch 187/200\n",
            "208/208 [==============================] - 0s 384us/sample - loss: 5.0005e-04 - acc: 1.0000\n",
            "Epoch 188/200\n",
            "208/208 [==============================] - 0s 343us/sample - loss: 4.8228e-04 - acc: 1.0000\n",
            "Epoch 189/200\n",
            "208/208 [==============================] - 0s 350us/sample - loss: 4.5970e-04 - acc: 1.0000\n",
            "Epoch 190/200\n",
            "208/208 [==============================] - 0s 331us/sample - loss: 4.9441e-04 - acc: 1.0000\n",
            "Epoch 191/200\n",
            "208/208 [==============================] - 0s 296us/sample - loss: 4.0810e-04 - acc: 1.0000\n",
            "Epoch 192/200\n",
            "208/208 [==============================] - 0s 312us/sample - loss: 4.3271e-04 - acc: 1.0000\n",
            "Epoch 193/200\n",
            "208/208 [==============================] - 0s 357us/sample - loss: 3.9537e-04 - acc: 1.0000\n",
            "Epoch 194/200\n",
            "208/208 [==============================] - 0s 321us/sample - loss: 3.8518e-04 - acc: 1.0000\n",
            "Epoch 195/200\n",
            "208/208 [==============================] - 0s 317us/sample - loss: 4.8138e-04 - acc: 1.0000\n",
            "Epoch 196/200\n",
            "208/208 [==============================] - 0s 371us/sample - loss: 3.7448e-04 - acc: 1.0000\n",
            "Epoch 197/200\n",
            "208/208 [==============================] - 0s 322us/sample - loss: 3.5967e-04 - acc: 1.0000\n",
            "Epoch 198/200\n",
            "208/208 [==============================] - 0s 346us/sample - loss: 3.5557e-04 - acc: 1.0000\n",
            "Epoch 199/200\n",
            "208/208 [==============================] - 0s 329us/sample - loss: 3.2636e-04 - acc: 1.0000\n",
            "Epoch 200/200\n",
            "208/208 [==============================] - 0s 311us/sample - loss: 3.6842e-04 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f48c37c3470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QUdaTnHEdwZ"
      },
      "source": [
        "과적합은 층이 너무 많거나 변수가 복잡해서 발생하기도 하고 테스트셋과 학습셋이 중복될 때 생기기도 합니다.\n",
        "\n",
        "딥러닝은 학습 단계에서 입력층, 은닉층, 출력층의 노드들에 상당히 많은 변수들이 투입됩니다.\n",
        "\n",
        "그래서 딥러닝을 진행하는 동안 과적합에 빠지지 않게 늘 주의해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G2OQ3tCEeDT",
        "outputId": "06bddac4-3b9d-458a-b837-408150ebd4d1"
      },
      "source": [
        "# 결과 출력\n",
        "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "208/208 [==============================] - 0s 146us/sample - loss: 3.2455e-04 - acc: 1.0000\n",
            "\n",
            " Accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP43WzG_nYFT"
      },
      "source": [
        "accuracy가 지나치게 높게 나옵니다. 즉, 오버피팅이 일어납니다.\n",
        "\n",
        "새로운 데이터에 대해서 적용하면 accuracy가 지금보다는 낮게 나올 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M79sjplKc6iG",
        "outputId": "4ff44e40-f40b-4f61-b414-935c1982c9ac"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 24)                1464      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                250       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,725\n",
            "Trainable params: 1,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl3D68oZFD03"
      },
      "source": [
        "과적합을 방지하려면 학습을 하는 데이터셋과 이를 테스트할 데이터셋을 완전히 구분한 다음 학습과 동시에 테스트를 병행하며 진행하는 것이 한 방법입니다. \n",
        "\n",
        "데이터셋이 총 100개의 샘플로 이루어져 있다면 다음과 같이 두 개의 셋으로 나눕니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJENT2PSFf2C"
      },
      "source": [
        "70개 샘플은 학습셋, 30개 샘플은 테스트셋"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K25sb8juFgGY"
      },
      "source": [
        "\n",
        "신경망을 만들어 70개의 샘플로 학습을 진행한 후 이 학습의 결과를 저장합니다. 이렇게 저장한 파일을 '**모델**'이라고 부릅니다. 모델은 다른 셋에 적용할 경우 학습 단계에서 각인되었던 그대로 다시 수행합니다. 나머지 30개의 샘플로 실험해서 정확도를 살펴보면 학습이 얼마나 잘 되어있는지를 알 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhXVoYEXc8AI",
        "outputId": "94b32f84-4563-4201-a5c4-4e5113f5f051"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# seed 값 설정\n",
        "seed = 0\n",
        "numpy.random.seed(seed)\n",
        "tf.compat.v1.set_random_seed(3)\n",
        "\n",
        "# 학습 셋과 테스트 셋의 구분\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed) #테스트셋 비율을 30%로 잡음\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(24,  input_dim=60, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=130, batch_size=5)\n",
        "\n",
        "# 테스트셋에 모델 적용\n",
        "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 145 samples\n",
            "Epoch 1/130\n",
            "145/145 [==============================] - 0s 615us/sample - loss: 0.2712 - acc: 0.5241\n",
            "Epoch 2/130\n",
            "145/145 [==============================] - 0s 283us/sample - loss: 0.2405 - acc: 0.6414\n",
            "Epoch 3/130\n",
            "145/145 [==============================] - 0s 286us/sample - loss: 0.2331 - acc: 0.6276\n",
            "Epoch 4/130\n",
            "145/145 [==============================] - 0s 286us/sample - loss: 0.2237 - acc: 0.6621\n",
            "Epoch 5/130\n",
            "145/145 [==============================] - 0s 295us/sample - loss: 0.2154 - acc: 0.7241\n",
            "Epoch 6/130\n",
            "145/145 [==============================] - 0s 275us/sample - loss: 0.2062 - acc: 0.7517\n",
            "Epoch 7/130\n",
            "145/145 [==============================] - 0s 272us/sample - loss: 0.1959 - acc: 0.7517\n",
            "Epoch 8/130\n",
            "145/145 [==============================] - 0s 287us/sample - loss: 0.1883 - acc: 0.7586\n",
            "Epoch 9/130\n",
            "145/145 [==============================] - 0s 285us/sample - loss: 0.1804 - acc: 0.7655\n",
            "Epoch 10/130\n",
            "145/145 [==============================] - 0s 308us/sample - loss: 0.1746 - acc: 0.8000\n",
            "Epoch 11/130\n",
            "145/145 [==============================] - 0s 295us/sample - loss: 0.1653 - acc: 0.7517\n",
            "Epoch 12/130\n",
            "145/145 [==============================] - 0s 303us/sample - loss: 0.1628 - acc: 0.7931\n",
            "Epoch 13/130\n",
            "145/145 [==============================] - 0s 277us/sample - loss: 0.1572 - acc: 0.8069\n",
            "Epoch 14/130\n",
            "145/145 [==============================] - 0s 266us/sample - loss: 0.1479 - acc: 0.8069\n",
            "Epoch 15/130\n",
            "145/145 [==============================] - 0s 273us/sample - loss: 0.1480 - acc: 0.8345\n",
            "Epoch 16/130\n",
            "145/145 [==============================] - 0s 265us/sample - loss: 0.1393 - acc: 0.8552\n",
            "Epoch 17/130\n",
            "145/145 [==============================] - 0s 272us/sample - loss: 0.1397 - acc: 0.8276\n",
            "Epoch 18/130\n",
            "145/145 [==============================] - 0s 282us/sample - loss: 0.1318 - acc: 0.8759\n",
            "Epoch 19/130\n",
            "145/145 [==============================] - 0s 281us/sample - loss: 0.1270 - acc: 0.8552\n",
            "Epoch 20/130\n",
            "145/145 [==============================] - 0s 287us/sample - loss: 0.1310 - acc: 0.8345\n",
            "Epoch 21/130\n",
            "145/145 [==============================] - 0s 276us/sample - loss: 0.1233 - acc: 0.8552\n",
            "Epoch 22/130\n",
            "145/145 [==============================] - 0s 286us/sample - loss: 0.1202 - acc: 0.8621\n",
            "Epoch 23/130\n",
            "145/145 [==============================] - 0s 268us/sample - loss: 0.1192 - acc: 0.8690\n",
            "Epoch 24/130\n",
            "145/145 [==============================] - 0s 264us/sample - loss: 0.1138 - acc: 0.8759\n",
            "Epoch 25/130\n",
            "145/145 [==============================] - 0s 296us/sample - loss: 0.1131 - acc: 0.8621\n",
            "Epoch 26/130\n",
            "145/145 [==============================] - 0s 286us/sample - loss: 0.1082 - acc: 0.8828\n",
            "Epoch 27/130\n",
            "145/145 [==============================] - 0s 292us/sample - loss: 0.1090 - acc: 0.8897\n",
            "Epoch 28/130\n",
            "145/145 [==============================] - 0s 291us/sample - loss: 0.1068 - acc: 0.8621\n",
            "Epoch 29/130\n",
            "145/145 [==============================] - 0s 292us/sample - loss: 0.1018 - acc: 0.8828\n",
            "Epoch 30/130\n",
            "145/145 [==============================] - 0s 313us/sample - loss: 0.0970 - acc: 0.8828\n",
            "Epoch 31/130\n",
            "145/145 [==============================] - 0s 283us/sample - loss: 0.0960 - acc: 0.8897\n",
            "Epoch 32/130\n",
            "145/145 [==============================] - 0s 286us/sample - loss: 0.0967 - acc: 0.8966\n",
            "Epoch 33/130\n",
            "145/145 [==============================] - 0s 276us/sample - loss: 0.0902 - acc: 0.9034\n",
            "Epoch 34/130\n",
            "145/145 [==============================] - 0s 269us/sample - loss: 0.0931 - acc: 0.8897\n",
            "Epoch 35/130\n",
            "145/145 [==============================] - 0s 268us/sample - loss: 0.0910 - acc: 0.8759\n",
            "Epoch 36/130\n",
            "145/145 [==============================] - 0s 320us/sample - loss: 0.0924 - acc: 0.8897\n",
            "Epoch 37/130\n",
            "145/145 [==============================] - 0s 318us/sample - loss: 0.0959 - acc: 0.8621\n",
            "Epoch 38/130\n",
            "145/145 [==============================] - 0s 352us/sample - loss: 0.0826 - acc: 0.9034\n",
            "Epoch 39/130\n",
            "145/145 [==============================] - 0s 333us/sample - loss: 0.0788 - acc: 0.9241\n",
            "Epoch 40/130\n",
            "145/145 [==============================] - 0s 258us/sample - loss: 0.0807 - acc: 0.9103\n",
            "Epoch 41/130\n",
            "145/145 [==============================] - 0s 300us/sample - loss: 0.0762 - acc: 0.9379\n",
            "Epoch 42/130\n",
            "145/145 [==============================] - 0s 309us/sample - loss: 0.0780 - acc: 0.9103\n",
            "Epoch 43/130\n",
            "145/145 [==============================] - 0s 314us/sample - loss: 0.0731 - acc: 0.9172\n",
            "Epoch 44/130\n",
            "145/145 [==============================] - 0s 286us/sample - loss: 0.0731 - acc: 0.9241\n",
            "Epoch 45/130\n",
            "145/145 [==============================] - 0s 286us/sample - loss: 0.0708 - acc: 0.9172\n",
            "Epoch 46/130\n",
            "145/145 [==============================] - 0s 273us/sample - loss: 0.0690 - acc: 0.9517\n",
            "Epoch 47/130\n",
            "145/145 [==============================] - 0s 272us/sample - loss: 0.0774 - acc: 0.9034\n",
            "Epoch 48/130\n",
            "145/145 [==============================] - 0s 274us/sample - loss: 0.0672 - acc: 0.9310\n",
            "Epoch 49/130\n",
            "145/145 [==============================] - 0s 287us/sample - loss: 0.0641 - acc: 0.9379\n",
            "Epoch 50/130\n",
            "145/145 [==============================] - 0s 283us/sample - loss: 0.0607 - acc: 0.9448\n",
            "Epoch 51/130\n",
            "145/145 [==============================] - 0s 293us/sample - loss: 0.0599 - acc: 0.9448\n",
            "Epoch 52/130\n",
            "145/145 [==============================] - 0s 276us/sample - loss: 0.0592 - acc: 0.9379\n",
            "Epoch 53/130\n",
            "145/145 [==============================] - 0s 263us/sample - loss: 0.0597 - acc: 0.9517\n",
            "Epoch 54/130\n",
            "145/145 [==============================] - 0s 266us/sample - loss: 0.0592 - acc: 0.9241\n",
            "Epoch 55/130\n",
            "145/145 [==============================] - 0s 312us/sample - loss: 0.0555 - acc: 0.9517\n",
            "Epoch 56/130\n",
            "145/145 [==============================] - 0s 354us/sample - loss: 0.0575 - acc: 0.9448\n",
            "Epoch 57/130\n",
            "145/145 [==============================] - 0s 289us/sample - loss: 0.0501 - acc: 0.9517\n",
            "Epoch 58/130\n",
            "145/145 [==============================] - 0s 283us/sample - loss: 0.0531 - acc: 0.9379\n",
            "Epoch 59/130\n",
            "145/145 [==============================] - 0s 319us/sample - loss: 0.0468 - acc: 0.9655\n",
            "Epoch 60/130\n",
            "145/145 [==============================] - 0s 335us/sample - loss: 0.0462 - acc: 0.9586\n",
            "Epoch 61/130\n",
            "145/145 [==============================] - 0s 290us/sample - loss: 0.0466 - acc: 0.9586\n",
            "Epoch 62/130\n",
            "145/145 [==============================] - 0s 289us/sample - loss: 0.0438 - acc: 0.9586\n",
            "Epoch 63/130\n",
            "145/145 [==============================] - 0s 345us/sample - loss: 0.0427 - acc: 0.9655\n",
            "Epoch 64/130\n",
            "145/145 [==============================] - 0s 315us/sample - loss: 0.0391 - acc: 0.9724\n",
            "Epoch 65/130\n",
            "145/145 [==============================] - 0s 355us/sample - loss: 0.0403 - acc: 0.9724\n",
            "Epoch 66/130\n",
            "145/145 [==============================] - 0s 270us/sample - loss: 0.0401 - acc: 0.9655\n",
            "Epoch 67/130\n",
            "145/145 [==============================] - 0s 260us/sample - loss: 0.0365 - acc: 0.9793\n",
            "Epoch 68/130\n",
            "145/145 [==============================] - 0s 273us/sample - loss: 0.0362 - acc: 0.9724\n",
            "Epoch 69/130\n",
            "145/145 [==============================] - 0s 332us/sample - loss: 0.0397 - acc: 0.9586\n",
            "Epoch 70/130\n",
            "145/145 [==============================] - 0s 271us/sample - loss: 0.0374 - acc: 0.9655\n",
            "Epoch 71/130\n",
            "145/145 [==============================] - 0s 277us/sample - loss: 0.0307 - acc: 0.9793\n",
            "Epoch 72/130\n",
            "145/145 [==============================] - 0s 264us/sample - loss: 0.0365 - acc: 0.9655\n",
            "Epoch 73/130\n",
            "145/145 [==============================] - 0s 284us/sample - loss: 0.0366 - acc: 0.9655\n",
            "Epoch 74/130\n",
            "145/145 [==============================] - 0s 277us/sample - loss: 0.0333 - acc: 0.9655\n",
            "Epoch 75/130\n",
            "145/145 [==============================] - 0s 291us/sample - loss: 0.0345 - acc: 0.9724\n",
            "Epoch 76/130\n",
            "145/145 [==============================] - 0s 460us/sample - loss: 0.0273 - acc: 0.9724\n",
            "Epoch 77/130\n",
            "145/145 [==============================] - 0s 298us/sample - loss: 0.0268 - acc: 0.9793\n",
            "Epoch 78/130\n",
            "145/145 [==============================] - 0s 268us/sample - loss: 0.0272 - acc: 0.9862\n",
            "Epoch 79/130\n",
            "145/145 [==============================] - 0s 272us/sample - loss: 0.0245 - acc: 0.9931\n",
            "Epoch 80/130\n",
            "145/145 [==============================] - 0s 278us/sample - loss: 0.0311 - acc: 0.9655\n",
            "Epoch 81/130\n",
            "145/145 [==============================] - 0s 274us/sample - loss: 0.0245 - acc: 0.9862\n",
            "Epoch 82/130\n",
            "145/145 [==============================] - 0s 299us/sample - loss: 0.0235 - acc: 0.9931\n",
            "Epoch 83/130\n",
            "145/145 [==============================] - 0s 291us/sample - loss: 0.0226 - acc: 0.9862\n",
            "Epoch 84/130\n",
            "145/145 [==============================] - 0s 261us/sample - loss: 0.0208 - acc: 0.9931\n",
            "Epoch 85/130\n",
            "145/145 [==============================] - 0s 267us/sample - loss: 0.0210 - acc: 0.9931\n",
            "Epoch 86/130\n",
            "145/145 [==============================] - 0s 269us/sample - loss: 0.0210 - acc: 0.9931\n",
            "Epoch 87/130\n",
            "145/145 [==============================] - 0s 280us/sample - loss: 0.0194 - acc: 0.9931\n",
            "Epoch 88/130\n",
            "145/145 [==============================] - 0s 299us/sample - loss: 0.0187 - acc: 0.9931\n",
            "Epoch 89/130\n",
            "145/145 [==============================] - 0s 332us/sample - loss: 0.0212 - acc: 0.9931\n",
            "Epoch 90/130\n",
            "145/145 [==============================] - 0s 304us/sample - loss: 0.0187 - acc: 0.9931\n",
            "Epoch 91/130\n",
            "145/145 [==============================] - 0s 310us/sample - loss: 0.0196 - acc: 0.9931\n",
            "Epoch 92/130\n",
            "145/145 [==============================] - 0s 279us/sample - loss: 0.0192 - acc: 0.9931\n",
            "Epoch 93/130\n",
            "145/145 [==============================] - 0s 250us/sample - loss: 0.0171 - acc: 0.9931\n",
            "Epoch 94/130\n",
            "145/145 [==============================] - 0s 270us/sample - loss: 0.0195 - acc: 0.9931\n",
            "Epoch 95/130\n",
            "145/145 [==============================] - 0s 274us/sample - loss: 0.0197 - acc: 0.9862\n",
            "Epoch 96/130\n",
            "145/145 [==============================] - 0s 284us/sample - loss: 0.0150 - acc: 0.9931\n",
            "Epoch 97/130\n",
            "145/145 [==============================] - 0s 286us/sample - loss: 0.0147 - acc: 0.9931\n",
            "Epoch 98/130\n",
            "145/145 [==============================] - 0s 345us/sample - loss: 0.0161 - acc: 0.9931\n",
            "Epoch 99/130\n",
            "145/145 [==============================] - 0s 330us/sample - loss: 0.0149 - acc: 0.9931\n",
            "Epoch 100/130\n",
            "145/145 [==============================] - 0s 324us/sample - loss: 0.0141 - acc: 0.9931\n",
            "Epoch 101/130\n",
            "145/145 [==============================] - 0s 336us/sample - loss: 0.0131 - acc: 0.9931\n",
            "Epoch 102/130\n",
            "145/145 [==============================] - 0s 299us/sample - loss: 0.0135 - acc: 0.9931\n",
            "Epoch 103/130\n",
            "145/145 [==============================] - 0s 315us/sample - loss: 0.0129 - acc: 0.9931\n",
            "Epoch 104/130\n",
            "145/145 [==============================] - 0s 280us/sample - loss: 0.0132 - acc: 0.9931\n",
            "Epoch 105/130\n",
            "145/145 [==============================] - 0s 361us/sample - loss: 0.0121 - acc: 0.9931\n",
            "Epoch 106/130\n",
            "145/145 [==============================] - 0s 346us/sample - loss: 0.0127 - acc: 0.9931\n",
            "Epoch 107/130\n",
            "145/145 [==============================] - 0s 287us/sample - loss: 0.0115 - acc: 0.9931\n",
            "Epoch 108/130\n",
            "145/145 [==============================] - 0s 349us/sample - loss: 0.0112 - acc: 0.9931\n",
            "Epoch 109/130\n",
            "145/145 [==============================] - 0s 323us/sample - loss: 0.0112 - acc: 0.9931\n",
            "Epoch 110/130\n",
            "145/145 [==============================] - 0s 329us/sample - loss: 0.0104 - acc: 0.9931\n",
            "Epoch 111/130\n",
            "145/145 [==============================] - 0s 315us/sample - loss: 0.0114 - acc: 0.9931\n",
            "Epoch 112/130\n",
            "145/145 [==============================] - 0s 285us/sample - loss: 0.0102 - acc: 0.9931\n",
            "Epoch 113/130\n",
            "145/145 [==============================] - 0s 322us/sample - loss: 0.0100 - acc: 0.9931\n",
            "Epoch 114/130\n",
            "145/145 [==============================] - 0s 278us/sample - loss: 0.0089 - acc: 0.9931\n",
            "Epoch 115/130\n",
            "145/145 [==============================] - 0s 290us/sample - loss: 0.0082 - acc: 0.9931\n",
            "Epoch 116/130\n",
            "145/145 [==============================] - 0s 316us/sample - loss: 0.0077 - acc: 0.9931\n",
            "Epoch 117/130\n",
            "145/145 [==============================] - 0s 331us/sample - loss: 0.0078 - acc: 1.0000\n",
            "Epoch 118/130\n",
            "145/145 [==============================] - 0s 371us/sample - loss: 0.0066 - acc: 1.0000\n",
            "Epoch 119/130\n",
            "145/145 [==============================] - 0s 315us/sample - loss: 0.0070 - acc: 0.9931\n",
            "Epoch 120/130\n",
            "145/145 [==============================] - 0s 326us/sample - loss: 0.0064 - acc: 1.0000\n",
            "Epoch 121/130\n",
            "145/145 [==============================] - 0s 354us/sample - loss: 0.0060 - acc: 1.0000\n",
            "Epoch 122/130\n",
            "145/145 [==============================] - 0s 359us/sample - loss: 0.0060 - acc: 0.9931\n",
            "Epoch 123/130\n",
            "145/145 [==============================] - 0s 309us/sample - loss: 0.0052 - acc: 1.0000\n",
            "Epoch 124/130\n",
            "145/145 [==============================] - 0s 282us/sample - loss: 0.0053 - acc: 1.0000\n",
            "Epoch 125/130\n",
            "145/145 [==============================] - 0s 307us/sample - loss: 0.0057 - acc: 1.0000\n",
            "Epoch 126/130\n",
            "145/145 [==============================] - 0s 317us/sample - loss: 0.0066 - acc: 1.0000\n",
            "Epoch 127/130\n",
            "145/145 [==============================] - 0s 297us/sample - loss: 0.0044 - acc: 1.0000\n",
            "Epoch 128/130\n",
            "145/145 [==============================] - 0s 327us/sample - loss: 0.0047 - acc: 1.0000\n",
            "Epoch 129/130\n",
            "145/145 [==============================] - 0s 434us/sample - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 130/130\n",
            "145/145 [==============================] - 0s 310us/sample - loss: 0.0043 - acc: 1.0000\n",
            "63/63 [==============================] - 0s 359us/sample - loss: 0.1403 - acc: 0.8254\n",
            "\n",
            " Test Accuracy: 0.8254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7KmZyuZn8CI"
      },
      "source": [
        "Accuracy가 0.8254로 낮아진 것을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgQeoukzGda7"
      },
      "source": [
        "학습이 계속 되면 학습셋에서의 정확도는 계속 올라가지만 테스트셋에서는 과적합이 발생합니다.\n",
        "\n",
        "테스트 에러가 커지는 순간 과적합이 발생하므로 그 전에 학습을 멈춰야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOXLSNt1Gczx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "a2c31043-5d4b-4942-bce0-5f2b12051c52"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, \"myModel.png\", show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 24)                1464      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                250       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,725\n",
            "Trainable params: 1,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7NFmEv-sjH6"
      },
      "source": [
        "###**모델 저장** \n",
        "학습이 끝난 후 테스트해본 결과가 만족스러울 때 이를 모델로 저장하여 새로운 데이터에 사용할 수 있습니다. 앞서 학습한 결과를 모델로 저장하려면 다음과 같이 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QM0Wz6MoTvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18082574-568c-4fe6-ab4a-3a34e18d366a"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('my_model.h5')  # 모델을 컴퓨터에 저장\n",
        "\n",
        "del model       # 테스트를 위해 메모리 내의 모델을 삭제\n",
        "model = load_model('my_model.h5') # 모델을 새로 불러옴\n",
        "\n",
        "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))  # 불러온 모델로 테스트 실행"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "63/63 [==============================] - 0s 522us/sample - loss: 0.1403 - acc: 0.8254\n",
            "\n",
            " Test Accuracy: 0.8254\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}